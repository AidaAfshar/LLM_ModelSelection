wandb: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.
wandb: Appending key for api.wandb.ai to your netrc file: /usr4/ec890/aafshar/.netrc
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 02-26 15:54:16 [vllm_utils.py:702] Unsloth: Patching vLLM v1 graph capture
==((====))==  Unsloth 2026.1.3: Fast Llama patching. Transformers: 4.56.2. vLLM: 0.11.2.
   \\   /|    NVIDIA A100-PCIE-40GB. Num GPUs = 1. Max memory: 39.494 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.9.0+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.5.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post1. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: vLLM loading unsloth/Llama-3.2-3B-Instruct with actual GPU utilization = 88.8%
Unsloth: Your GPU has CUDA compute capability 8.0 with VRAM = 39.49 GB.
Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 1024. Num Sequences = 96.
Unsloth: vLLM's KV Cache can use up to 28.9 GB. Also swap space = 6 GB.
Unsloth: Not an error, but `use_cudagraph` is not supported in vLLM.config.CompilationConfig. Skipping.
WARNING 02-26 15:54:18 [compilation.py:610] Level is deprecated and will be removed in the next release,either 0.12.0 or 0.11.2 whichever is soonest.Use mode instead.If both level and mode are given,only mode will be used.
WARNING 02-26 15:54:18 [compilation.py:699] The 'use_inductor' flag is deprecated and will be removed in the next release (v0.12.0). Please use the 'backend' option instead.
/projectnb/modselrl/aafshar/.conda/envs/modselfm/lib/python3.10/site-packages/pydantic/type_adapter.py:605: UserWarning: Pydantic serializer warnings:
  PydanticSerializationUnexpectedValue(Expected `enum` - serialized value may not be as expected [field_name='mode', input_value=3, input_type=int])
  return self.serializer.to_python(
Unsloth: Not an error, but `device` is not supported in vLLM. Skipping.
INFO 02-26 15:54:18 [utils.py:253] non-default args: {'dtype': torch.bfloat16, 'seed': 0, 'max_model_len': 1024, 'enable_prefix_caching': True, 'swap_space': 6, 'gpu_memory_utilization': 0.8879645227196157, 'max_num_batched_tokens': 8192, 'max_num_seqs': 96, 'max_logprobs': 0, 'disable_log_stats': True, 'enable_lora': True, 'max_lora_rank': 64, 'enable_chunked_prefill': True, 'compilation_config': {'level': 3, 'mode': 3, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': [], 'splitting_ops': None, 'compile_mm_encoder': False, 'use_inductor': True, 'compile_sizes': None, 'inductor_compile_config': {'epilogue_fusion': True, 'max_autotune': False, 'shape_padding': True, 'trace.enabled': False, 'triton.cudagraphs': False, 'debug': False, 'dce': True, 'memory_planning': True, 'coordinate_descent_tuning': False, 'trace.graph_diagram': False, 'compile_threads': 32, 'group_fusion': True, 'disable_progress': False, 'verbose_progress': True, 'triton.multi_kernel': 0, 'triton.use_block_ptr': True, 'triton.enable_persistent_tma_matmul': True, 'triton.autotune_at_compile_time': False, 'triton.cooperative_reductions': False, 'cuda.compile_opt_level': '-O2', 'cuda.enable_cuda_lto': True, 'combo_kernels': False, 'benchmark_combo_kernel': True, 'combo_kernel_foreach_dynamic_shapes': True, 'enable_auto_functionalized_v2': False}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': None, 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': None, 'local_cache_dir': None}, 'model': 'unsloth/Llama-3.2-3B-Instruct'}
INFO 02-26 15:54:18 [model.py:631] Resolved architecture: LlamaForCausalLM
INFO 02-26 15:54:18 [model.py:1745] Using max model len 1024
INFO 02-26 15:54:20 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
/projectnb/modselrl/aafshar/.conda/envs/modselfm/lib/python3.10/site-packages/pydantic/type_adapter.py:605: UserWarning: Pydantic serializer warnings:
  PydanticSerializationUnexpectedValue(Expected `enum` - serialized value may not be as expected [field_name='mode', input_value=3, input_type=int])
  return self.serializer.to_python(
INFO 02-26 15:54:21 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='unsloth/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='unsloth/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1024, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Llama-3.2-3B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': 3, 'mode': 3, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': True, 'compile_sizes': [], 'inductor_compile_config': {'epilogue_fusion': True, 'max_autotune': False, 'shape_padding': True, 'trace.enabled': False, 'triton.cudagraphs': False, 'debug': False, 'dce': True, 'memory_planning': True, 'coordinate_descent_tuning': False, 'trace.graph_diagram': False, 'compile_threads': 32, 'group_fusion': True, 'disable_progress': False, 'verbose_progress': True, 'triton.multi_kernel': 0, 'triton.use_block_ptr': True, 'triton.enable_persistent_tma_matmul': True, 'triton.autotune_at_compile_time': False, 'triton.cooperative_reductions': False, 'cuda.compile_opt_level': '-O2', 'cuda.enable_cuda_lto': True, 'combo_kernels': False, 'benchmark_combo_kernel': True, 'combo_kernel_foreach_dynamic_shapes': True, 'enable_auto_functionalized_v2': False}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 192, 'local_cache_dir': None}
INFO 02-26 15:54:21 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://192.168.21.7:36799 backend=nccl
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
INFO 02-26 15:54:21 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
INFO 02-26 15:54:22 [topk_topp_sampler.py:36] Using FlashInfer for top-p & top-k sampling.
INFO 02-26 15:54:22 [gpu_model_runner.py:3259] Starting to load model unsloth/Llama-3.2-3B-Instruct...
/projectnb/modselrl/aafshar/.conda/envs/modselfm/lib/python3.10/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.
We recommend installing via `pip install torch-c-dlpack-ext`
  warnings.warn(
INFO 02-26 15:54:51 [cuda.py:377] Using AttentionBackendEnum.FLASHINFER backend.
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.67s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:07<00:00,  3.90s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:07<00:00,  3.56s/it]

INFO 02-26 15:54:59 [default_loader.py:314] Loading weights took 7.28 seconds
INFO 02-26 15:54:59 [punica_selector.py:20] Using PunicaWrapperGPU.
INFO 02-26 15:54:59 [gpu_model_runner.py:3338] Model loading took 6.2476 GiB memory and 36.481247 seconds
INFO 02-26 15:55:19 [backends.py:631] Using cache directory: /usr4/ec890/aafshar/.cache/vllm/torch_compile_cache/82d0bd2f55/rank_0_0/backbone for vLLM's torch.compile
INFO 02-26 15:55:19 [backends.py:647] Dynamo bytecode transform time: 18.39 s
INFO 02-26 15:55:23 [backends.py:210] Directly load the compiled graph(s) for dynamic shape from the cache, took 3.628 s
INFO 02-26 15:55:26 [monitor.py:34] torch.compile takes 22.02 s in total
INFO 02-26 15:55:28 [gpu_worker.py:359] Available KV cache memory: 28.12 GiB
INFO 02-26 15:55:29 [kv_cache_utils.py:1229] GPU KV cache size: 263,296 tokens
INFO 02-26 15:55:29 [kv_cache_utils.py:1234] Maximum concurrency for 1,024 tokens per request: 257.12x
INFO 02-26 15:55:29 [kernel_warmup.py:65] Warming up FlashInfer attention.
INFO 02-26 15:55:30 [vllm_utils.py:707] Unsloth: Running patched vLLM v1 `capture_model`.
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/54 [00:00<?, ?it/s]WARNING 02-26 15:55:30 [utils.py:250] Using default LoRA kernel configs
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|â–         | 1/54 [00:01<01:12,  1.37s/it]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|â–Œ         | 3/54 [00:02<00:37,  1.37it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|â–‰         | 5/54 [00:02<00:19,  2.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|â–ˆâ–Ž        | 7/54 [00:02<00:12,  3.86it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|â–ˆâ–‹        | 9/54 [00:02<00:08,  5.27it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|â–ˆâ–ˆ        | 11/54 [00:02<00:06,  6.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|â–ˆâ–ˆâ–       | 13/54 [00:03<00:05,  7.98it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|â–ˆâ–ˆâ–Š       | 15/54 [00:03<00:04,  9.13it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:03<00:03, 10.08it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:03<00:05,  6.83it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:04<00:05,  5.80it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 23/54 [00:04<00:04,  7.00it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:04<00:03,  8.17it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:04<00:02,  9.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 29/54 [00:05<00:02, 10.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:05<00:02, 10.93it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:05<00:01, 11.49it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:05<00:01, 11.99it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:05<00:01, 12.37it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [00:05<00:01, 12.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [00:05<00:01, 12.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [00:06<00:00, 12.95it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 45/54 [00:06<00:00, 13.06it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [00:06<00:00, 13.11it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [00:06<00:00, 11.45it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [00:06<00:00, 11.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [00:07<00:00,  4.37it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:07<00:00,  6.80it/s]
Capturing CUDA graphs (decode, FULL):   0%|          | 0/30 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   3%|â–Ž         | 1/30 [00:00<00:04,  6.97it/s]Capturing CUDA graphs (decode, FULL):  10%|â–ˆ         | 3/30 [00:00<00:02, 10.45it/s]Capturing CUDA graphs (decode, FULL):  17%|â–ˆâ–‹        | 5/30 [00:00<00:02, 11.52it/s]Capturing CUDA graphs (decode, FULL):  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:00<00:01, 12.04it/s]Capturing CUDA graphs (decode, FULL):  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:00<00:01, 12.35it/s]Capturing CUDA graphs (decode, FULL):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:00<00:01, 12.46it/s]Capturing CUDA graphs (decode, FULL):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:01<00:01, 12.59it/s]Capturing CUDA graphs (decode, FULL):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:01<00:01, 12.69it/s]Capturing CUDA graphs (decode, FULL):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:01<00:01, 12.71it/s]Capturing CUDA graphs (decode, FULL):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:01<00:00, 12.78it/s]Capturing CUDA graphs (decode, FULL):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:01<00:00, 12.82it/s]Capturing CUDA graphs (decode, FULL):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:01<00:00, 12.84it/s]Capturing CUDA graphs (decode, FULL):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:02<00:00, 12.78it/s]Capturing CUDA graphs (decode, FULL):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:02<00:00, 12.81it/s]Capturing CUDA graphs (decode, FULL):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:02<00:00, 12.81it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:02<00:00, 12.60it/s]
INFO 02-26 15:55:40 [gpu_model_runner.py:4244] Graph capturing finished in 10 secs, took 0.70 GiB
INFO 02-26 15:55:40 [vllm_utils.py:714] Unsloth: Patched vLLM v1 graph capture finished in 10 secs.
INFO 02-26 15:55:41 [core.py:250] init engine (profile, create kv cache, warmup model) took 41.77 seconds
INFO 02-26 15:55:42 [llm.py:352] Supported tasks: ('generate',)
Unsloth: Just some info: will skip parsing ['pre_feedforward_layernorm', 'norm1', 'attention_norm', 'post_attention_layernorm', 'post_layernorm', 'norm', 'layer_norm1', 'post_feedforward_layernorm', 'norm2', 'ffn_norm', 'input_layernorm', 'k_norm', 'q_norm', 'layer_norm2']
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 64.96it/s]
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at unsloth/Llama-3.2-3B-Instruct and are newly initialized: ['lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Unsloth 2026.1.3 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.
wandb: [wandb.login()] Loaded credentials for https://api.wandb.ai from /usr4/ec890/aafshar/.netrc.
wandb: Currently logged in as: aidaafshar to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_155551-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: Detected [huggingface_hub.inference, openai] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Performing substitution for additional_keys=set()
Unsloth: Just some info: will skip parsing ['pre_feedforward_layernorm', 'norm1', 'attention_norm', 'post_attention_layernorm', 'post_layernorm', 'norm', 'cross_attn_post_attention_layernorm', 'layer_norm1', 'post_feedforward_layernorm', 'norm2', 'ffn_norm', 'input_layernorm', 'k_norm', 'q_norm', 'layer_norm2', 'cross_attn_input_layernorm']
potentials:  [1. 1. 1. 1. 1.]
sampled base index:  0
potentials:  [1. 1. 1. 1. 1.]
sampled base index:  0
  0%|          | 0/10 [00:00<?, ?it/s]WARNING 02-26 15:55:55 [processor.py:246] vLLM has deprecated support for supporting different tokenizers for different LoRAs. By default, vLLM uses base model's tokenizer. If you are using a LoRA with its own tokenizer, consider specifying `--tokenizer [lora_path]` to use the LoRA tokenizer.
 10%|â–ˆ         | 1/10 [00:42<06:25, 42.84s/it]                                               10%|â–ˆ         | 1/10 [00:42<06:25, 42.84s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:50<02:57, 22.18s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:50<02:57, 22.18s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:54<01:37, 13.97s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:54<01:37, 13.97s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [01:00<01:03, 10.60s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [01:00<01:03, 10.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:12<00:55, 11.18s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:12<00:55, 11.18s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:24<00:46, 11.65s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:24<00:46, 11.65s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:37<00:35, 11.85s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:37<00:35, 11.85s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:49<00:23, 11.98s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:49<00:23, 11.98s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [02:01<00:12, 12.07s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [02:01<00:12, 12.07s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:13<00:00, 12.10s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:13<00:00, 12.10s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:15<00:00, 12.10s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:15<00:00, 13.56s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 10-10
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20260226_155551-wdqr6dku/logs
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_155812-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: WARNING Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.30593082308769226, 'learning_rate': 0.001, 'num_tokens': 2347.0, 'completions/mean_length': 420.75, 'completions/min_length': 322.0, 'completions/max_length': 592.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 420.75, 'completions/min_terminated_length': 322.0, 'completions/max_terminated_length': 592.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 1.8874585628509521, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 420.75, 'kl': 0.0006882376037538052, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.32237643003463745, 'learning_rate': 0.001, 'num_tokens': 3718.0, 'completions/mean_length': 217.75, 'completions/min_length': 124.0, 'completions/max_length': 405.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 217.75, 'completions/min_terminated_length': 124.0, 'completions/max_terminated_length': 405.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.75, 'reward_std': 1.658312439918518, 'frac_reward_zero_std': 0.0, 'completion_length': 217.75, 'kl': 0.10056501254439354, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 1.1283390522003174, 'learning_rate': 0.001, 'num_tokens': 4562.0, 'completions/mean_length': 88.0, 'completions/min_length': 50.0, 'completions/max_length': 168.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 88.0, 'completions/min_terminated_length': 50.0, 'completions/max_terminated_length': 168.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 2.7386128902435303, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.75, 'reward_std': 3.1224989891052246, 'frac_reward_zero_std': 0.0, 'completion_length': 88.0, 'kl': 0.5465127155184746, 'epoch': 0.0}
{'loss': 0.0007, 'grad_norm': 0.473143070936203, 'learning_rate': 0.001, 'num_tokens': 6004.0, 'completions/mean_length': 210.5, 'completions/min_length': 169.0, 'completions/max_length': 254.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 210.5, 'completions/min_terminated_length': 169.0, 'completions/max_terminated_length': 254.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 210.5, 'kl': 0.6898528449237347, 'epoch': 0.0}
{'loss': 0.0007, 'grad_norm': 1.0331916809082031, 'learning_rate': 0.001, 'num_tokens': 8394.0, 'completions/mean_length': 441.5, 'completions/min_length': 112.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 147.0, 'completions/min_terminated_length': 112.0, 'completions/max_terminated_length': 182.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 1.7320507764816284, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': -1.375, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 441.5, 'kl': 0.6972289681434631, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.25718963146209717, 'learning_rate': 0.001, 'num_tokens': 11850.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -3.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -3.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 736.0, 'kl': 0.23900969699025154, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0014422525418922305, 'learning_rate': 0.001, 'num_tokens': 15350.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.17373576760292053, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0012392959324643016, 'learning_rate': 0.001, 'num_tokens': 18858.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23875319212675095, 'epoch': 0.0}
{'loss': 0.0011, 'grad_norm': 0.01833532191812992, 'learning_rate': 0.001, 'num_tokens': 22326.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.067577302455902, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0019935970194637775, 'learning_rate': 0.001, 'num_tokens': 25694.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.18322113528847694, 'epoch': 0.0}
{'train_runtime': 135.6114, 'train_samples_per_second': 0.295, 'train_steps_per_second': 0.074, 'train_loss': 0.0003937227054848336, 'epoch': 0.0}
[EP 0000] 0 | reward_mean=-2.275 | 
*** stats:  {'episode_reward_mean': -2.275, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 1.0055728554725647, 'episode_reward_trajectory': [-2.125, 0.75, -0.75, 0.375, -1.375, -3.625, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.45, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.3, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -2.5, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.9198892533779144, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': -0.225, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.15, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.15, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -2.275
All rewards  -2.275
Cumulative rewards  [-2.275, 0, 0, 0, 0]
Num plays  [1, 0, 0, 0, 0]
Mean rewards  [-2.275, 0, 0, 0, 0]
Balancing probabilities  [1, 0, 0, 0, 0]
Mis-Specification Test [1, 0, 0, 0, 0]
potentials:  [2. 1. 1. 1. 1.]
sampled base index:  1
potentials:  [2. 1. 1. 1. 1.]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:10<01:33, 10.44s/it]                                               10%|â–ˆ         | 1/10 [00:10<01:33, 10.44s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:15<00:56,  7.04s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:15<00:56,  7.04s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:20<00:42,  6.09s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:20<00:42,  6.09s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:25<00:35,  5.84s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:25<00:35,  5.84s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:34<00:34,  6.88s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:34<00:34,  6.88s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:39<00:24,  6.18s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:39<00:24,  6.18s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:44<00:17,  5.95s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:44<00:17,  5.95s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:51<00:12,  6.17s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:51<00:12,  6.17s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:58<00:06,  6.63s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:58<00:06,  6.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:06<00:00,  6.83s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:06<00:00,  6.83s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:07<00:00,  6.83s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:07<00:00,  6.78s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 32-32
wandb: 
wandb: Run history:
wandb:      modelselection/base_0_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -2.275
wandb:               modelselection/learning_rate 0.001
wandb: modelselection/metalearner_episodic_reward -2.275
wandb:       modelselection/selected_base_learner 0
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_155812-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_155923-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.30593082308769226, 'learning_rate': 0.0001, 'num_tokens': 2347.0, 'completions/mean_length': 420.75, 'completions/min_length': 322.0, 'completions/max_length': 592.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 420.75, 'completions/min_terminated_length': 322.0, 'completions/max_terminated_length': 592.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 1.8874585628509521, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 420.75, 'kl': 0.0006882376037538052, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3475726544857025, 'learning_rate': 0.0001, 'num_tokens': 3612.0, 'completions/mean_length': 191.25, 'completions/min_length': 172.0, 'completions/max_length': 204.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 191.25, 'completions/min_terminated_length': 172.0, 'completions/max_terminated_length': 204.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 191.25, 'kl': 0.0007863152204663493, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5920584201812744, 'learning_rate': 0.0001, 'num_tokens': 4752.0, 'completions/mean_length': 162.0, 'completions/min_length': 112.0, 'completions/max_length': 225.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 162.0, 'completions/min_terminated_length': 112.0, 'completions/max_terminated_length': 225.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': -0.375, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 162.0, 'kl': 0.006486056954599917, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3294835388660431, 'learning_rate': 0.0001, 'num_tokens': 6247.0, 'completions/mean_length': 223.75, 'completions/min_length': 189.0, 'completions/max_length': 257.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 223.75, 'completions/min_terminated_length': 189.0, 'completions/max_terminated_length': 257.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.0, 'reward_std': 1.5811388492584229, 'frac_reward_zero_std': 0.0, 'completion_length': 223.75, 'kl': 0.016079652355983853, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.2775852382183075, 'learning_rate': 0.0001, 'num_tokens': 8200.0, 'completions/mean_length': 332.25, 'completions/min_length': 238.0, 'completions/max_length': 483.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 332.25, 'completions/min_terminated_length': 238.0, 'completions/max_terminated_length': 483.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.625, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 332.25, 'kl': 0.0126627710997127, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.38326799869537354, 'learning_rate': 0.0001, 'num_tokens': 9410.0, 'completions/mean_length': 174.5, 'completions/min_length': 136.0, 'completions/max_length': 214.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 174.5, 'completions/min_terminated_length': 136.0, 'completions/max_terminated_length': 214.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.0, 'reward_std': 1.5811388492584229, 'frac_reward_zero_std': 0.0, 'completion_length': 174.5, 'kl': 0.045353603549301624, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5044448375701904, 'learning_rate': 0.0001, 'num_tokens': 10754.0, 'completions/mean_length': 197.0, 'completions/min_length': 133.0, 'completions/max_length': 260.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 197.0, 'completions/min_terminated_length': 133.0, 'completions/max_terminated_length': 260.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': 0.25, 'reward_std': 0.28867512941360474, 'frac_reward_zero_std': 0.0, 'completion_length': 197.0, 'kl': 0.02366753714159131, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.42829442024230957, 'learning_rate': 0.0001, 'num_tokens': 12314.0, 'completions/mean_length': 249.0, 'completions/min_length': 169.0, 'completions/max_length': 343.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 249.0, 'completions/min_terminated_length': 169.0, 'completions/max_terminated_length': 343.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 1.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 249.0, 'kl': 0.10938005056232214, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.3280656933784485, 'learning_rate': 0.0001, 'num_tokens': 14144.0, 'completions/mean_length': 326.5, 'completions/min_length': 257.0, 'completions/max_length': 412.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 326.5, 'completions/min_terminated_length': 257.0, 'completions/max_terminated_length': 412.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': 0.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 326.5, 'kl': 0.3539519472979009, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.5105515122413635, 'learning_rate': 0.0001, 'num_tokens': 15689.0, 'completions/mean_length': 280.25, 'completions/min_length': 175.0, 'completions/max_length': 386.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 280.25, 'completions/min_terminated_length': 175.0, 'completions/max_terminated_length': 386.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 0.75, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 280.25, 'kl': 0.12337280344218016, 'epoch': 0.0}
{'train_runtime': 67.7734, 'train_samples_per_second': 0.59, 'train_steps_per_second': 0.148, 'train_loss': 6.923875771462918e-05, 'epoch': 0.0}
[EP 0001] 1 | reward_mean=-0.150 | 
*** stats:  {'episode_reward_mean': -0.15, 'episode_reward_last': 0.75, 'episode_reward_std_mean': 1.2878193020820619, 'episode_reward_trajectory': [-2.125, -1.125, -0.375, 0.0, -0.625, 0.0, 0.25, 1.25, 0.5, 0.75], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -0.4375, 'rewards/match_format_approximately/mean/last': 0.125, 'rewards/match_format_approximately/std/mean': 0.7568999171257019, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.2875, 'rewards/check_numbers/mean/last': 0.625, 'rewards/check_numbers/std/mean': 0.6698304057121277, 'rewards/check_numbers/std/last': 1.0307763814926147}
Curr reward  -0.15
All rewards  -2.425
Cumulative rewards  [-2.275, -0.15, 0, 0, 0]
Num plays  [1, 1, 0, 0, 0]
Mean rewards  [-2.275, -0.15, 0, 0, 0]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [1, 1, 0, 0, 0]
potentials:  [2. 2. 1. 1. 1.]
sampled base index:  2
potentials:  [2. 2. 1. 1. 1.]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:10<01:33, 10.43s/it]                                               10%|â–ˆ         | 1/10 [00:10<01:33, 10.43s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:15<00:56,  7.10s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:15<00:56,  7.10s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:46,  6.58s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:46,  6.58s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:27<00:39,  6.61s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:27<00:39,  6.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:36<00:37,  7.53s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:36<00:37,  7.53s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:41<00:25,  6.49s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:41<00:25,  6.49s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:46<00:17,  5.95s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:46<00:17,  5.95s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:51<00:11,  5.65s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:51<00:11,  5.65s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:56<00:05,  5.46s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:56<00:05,  5.46s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  5.93s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  5.93s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:05<00:00,  5.93s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:05<00:00,  6.50s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -2.275
wandb:      modelselection/base_1_episodic_reward -0.15
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -0.15
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_155923-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_160031-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.30593082308769226, 'learning_rate': 1e-05, 'num_tokens': 2347.0, 'completions/mean_length': 420.75, 'completions/min_length': 322.0, 'completions/max_length': 592.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 420.75, 'completions/min_terminated_length': 322.0, 'completions/max_terminated_length': 592.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 1.8874585628509521, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 420.75, 'kl': 0.0006882376037538052, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.38330355286598206, 'learning_rate': 1e-05, 'num_tokens': 3529.0, 'completions/mean_length': 170.5, 'completions/min_length': 120.0, 'completions/max_length': 216.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 170.5, 'completions/min_terminated_length': 120.0, 'completions/max_terminated_length': 216.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 170.5, 'kl': 0.00021391332666098606, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3987005949020386, 'learning_rate': 1e-05, 'num_tokens': 4956.0, 'completions/mean_length': 233.75, 'completions/min_length': 182.0, 'completions/max_length': 297.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 233.75, 'completions/min_terminated_length': 182.0, 'completions/max_terminated_length': 297.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.625, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 233.75, 'kl': 0.00025801026640692726, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3935107886791229, 'learning_rate': 1e-05, 'num_tokens': 6499.0, 'completions/mean_length': 235.75, 'completions/min_length': 155.0, 'completions/max_length': 342.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 235.75, 'completions/min_terminated_length': 155.0, 'completions/max_terminated_length': 342.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 235.75, 'kl': 0.00036691771310870536, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.27027544379234314, 'learning_rate': 1e-05, 'num_tokens': 8394.0, 'completions/mean_length': 317.75, 'completions/min_length': 248.0, 'completions/max_length': 508.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 317.75, 'completions/min_terminated_length': 248.0, 'completions/max_terminated_length': 508.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 317.75, 'kl': 0.0002964208324556239, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4613193869590759, 'learning_rate': 1e-05, 'num_tokens': 9529.0, 'completions/mean_length': 155.75, 'completions/min_length': 140.0, 'completions/max_length': 195.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 155.75, 'completions/min_terminated_length': 140.0, 'completions/max_terminated_length': 195.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 155.75, 'kl': 0.0009799900726648048, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.6108454465866089, 'learning_rate': 1e-05, 'num_tokens': 10747.0, 'completions/mean_length': 165.5, 'completions/min_length': 104.0, 'completions/max_length': 219.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 165.5, 'completions/min_terminated_length': 104.0, 'completions/max_terminated_length': 219.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.75, 'reward_std': 1.9364917278289795, 'frac_reward_zero_std': 0.0, 'completion_length': 165.5, 'kl': 0.0005114174273330718, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.28936588764190674, 'learning_rate': 1e-05, 'num_tokens': 12091.0, 'completions/mean_length': 195.0, 'completions/min_length': 155.0, 'completions/max_length': 230.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 195.0, 'completions/min_terminated_length': 155.0, 'completions/max_terminated_length': 230.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 195.0, 'kl': 0.0002943159743153956, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4633961021900177, 'learning_rate': 1e-05, 'num_tokens': 13399.0, 'completions/mean_length': 196.0, 'completions/min_length': 138.0, 'completions/max_length': 236.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 196.0, 'completions/min_terminated_length': 138.0, 'completions/max_terminated_length': 236.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.75, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 196.0, 'kl': 0.0009762924892129377, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.34350669384002686, 'learning_rate': 1e-05, 'num_tokens': 14789.0, 'completions/mean_length': 241.5, 'completions/min_length': 124.0, 'completions/max_length': 370.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 241.5, 'completions/min_terminated_length': 124.0, 'completions/max_terminated_length': 370.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.25, 'reward_std': 1.9364917278289795, 'frac_reward_zero_std': 0.0, 'completion_length': 241.5, 'kl': 0.0009372696549689863, 'epoch': 0.0}
{'train_runtime': 65.0359, 'train_samples_per_second': 0.615, 'train_steps_per_second': 0.154, 'train_loss': 5.558133125305175e-07, 'epoch': 0.0}
[EP 0002] 2 | reward_mean=-1.038 | 
*** stats:  {'episode_reward_mean': -1.0375, 'episode_reward_last': -0.25, 'episode_reward_std_mean': 1.217863345146179, 'episode_reward_trajectory': [-2.125, -1.375, -0.625, -1.125, -1.375, -0.75, -0.75, -0.25, -1.75, -0.25], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.225, 'rewards/match_format_approximately/mean/last': -1.0, 'rewards/match_format_approximately/std/mean': 0.931169331073761, 'rewards/match_format_approximately/std/last': 1.2247449159622192, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.1875, 'rewards/check_numbers/mean/last': 0.75, 'rewards/check_numbers/std/mean': 0.43480761647224425, 'rewards/check_numbers/std/last': 0.8660253882408142}
Curr reward  -1.0375
All rewards  -3.4625
Cumulative rewards  [-2.275, -0.15, -1.0375, 0, 0]
Num plays  [1, 1, 1, 0, 0]
Mean rewards  [-2.275, -0.15, -1.0375, 0, 0]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [1, 1, 1, 0, 0]
potentials:  [2. 2. 2. 1. 1.]
sampled base index:  3
potentials:  [2. 2. 2. 1. 1.]
sampled base index:  3
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:10<01:33, 10.42s/it]                                               10%|â–ˆ         | 1/10 [00:10<01:33, 10.42s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:16<01:03,  7.95s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:16<01:03,  7.95s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:22<00:50,  7.15s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:22<00:50,  7.15s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:29<00:40,  6.81s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:29<00:40,  6.81s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:40<00:42,  8.55s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:40<00:42,  8.55s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:44<00:28,  7.07s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:44<00:28,  7.07s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:50<00:19,  6.58s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:50<00:19,  6.58s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:55<00:12,  6.07s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:55<00:12,  6.07s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:07<00:08,  8.04s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:07<00:08,  8.04s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:13<00:00,  7.27s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:13<00:00,  7.27s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:15<00:00,  7.27s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:15<00:00,  7.51s/it]
wandb: uploading console lines 7-7; updating run metadata
wandb: uploading console lines 7-7
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -2.275
wandb:      modelselection/base_1_episodic_reward -0.15
wandb:      modelselection/base_2_episodic_reward -1.0375
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward -1.0375
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_160031-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_160151-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.30593082308769226, 'learning_rate': 1e-06, 'num_tokens': 2347.0, 'completions/mean_length': 420.75, 'completions/min_length': 322.0, 'completions/max_length': 592.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 420.75, 'completions/min_terminated_length': 322.0, 'completions/max_terminated_length': 592.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 1.8874585628509521, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 420.75, 'kl': 0.0006882376037538052, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.38529160618782043, 'learning_rate': 1e-06, 'num_tokens': 3638.0, 'completions/mean_length': 197.75, 'completions/min_length': 120.0, 'completions/max_length': 309.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 197.75, 'completions/min_terminated_length': 120.0, 'completions/max_terminated_length': 309.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 1.8874585628509521, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 197.75, 'kl': 0.00045408807272906415, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.48573288321495056, 'learning_rate': 1e-06, 'num_tokens': 4967.0, 'completions/mean_length': 209.25, 'completions/min_length': 153.0, 'completions/max_length': 308.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 209.25, 'completions/min_terminated_length': 153.0, 'completions/max_terminated_length': 308.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 209.25, 'kl': 0.0002970270434161648, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.2849650979042053, 'learning_rate': 1e-06, 'num_tokens': 6530.0, 'completions/mean_length': 240.75, 'completions/min_length': 206.0, 'completions/max_length': 314.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 240.75, 'completions/min_terminated_length': 206.0, 'completions/max_terminated_length': 314.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': -1.0, 'reward_std': 0.7071067690849304, 'frac_reward_zero_std': 0.0, 'completion_length': 240.75, 'kl': 0.0003373639119672589, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.30721554160118103, 'learning_rate': 1e-06, 'num_tokens': 8657.0, 'completions/mean_length': 375.75, 'completions/min_length': 251.0, 'completions/max_length': 679.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 375.75, 'completions/min_terminated_length': 251.0, 'completions/max_terminated_length': 679.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.5, 'reward_std': 0.7071067690849304, 'frac_reward_zero_std': 0.0, 'completion_length': 375.75, 'kl': 0.0002782250739983283, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4465947449207306, 'learning_rate': 1e-06, 'num_tokens': 9802.0, 'completions/mean_length': 158.25, 'completions/min_length': 136.0, 'completions/max_length': 174.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 158.25, 'completions/min_terminated_length': 136.0, 'completions/max_terminated_length': 174.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.375, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 158.25, 'kl': 0.0005434746999526396, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.36345309019088745, 'learning_rate': 1e-06, 'num_tokens': 11230.0, 'completions/mean_length': 218.0, 'completions/min_length': 155.0, 'completions/max_length': 268.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 218.0, 'completions/min_terminated_length': 155.0, 'completions/max_terminated_length': 268.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.0, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 218.0, 'kl': 0.0003643182062660344, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.36062541604042053, 'learning_rate': 1e-06, 'num_tokens': 12588.0, 'completions/mean_length': 198.5, 'completions/min_length': 163.0, 'completions/max_length': 226.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 198.5, 'completions/min_terminated_length': 163.0, 'completions/max_terminated_length': 226.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 198.5, 'kl': 0.0003475526718830224, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3860706686973572, 'learning_rate': 1e-06, 'num_tokens': 14616.0, 'completions/mean_length': 376.0, 'completions/min_length': 131.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 256.0, 'completions/min_terminated_length': 131.0, 'completions/max_terminated_length': 335.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 376.0, 'kl': 0.0003613238877733238, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3848315477371216, 'learning_rate': 1e-06, 'num_tokens': 15859.0, 'completions/mean_length': 204.75, 'completions/min_length': 177.0, 'completions/max_length': 264.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 204.75, 'completions/min_terminated_length': 177.0, 'completions/max_terminated_length': 264.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -1.625, 'reward_std': 0.6291528940200806, 'frac_reward_zero_std': 0.0, 'completion_length': 204.75, 'kl': 0.00031539524206891656, 'epoch': 0.0}
{'train_runtime': 75.0779, 'train_samples_per_second': 0.533, 'train_steps_per_second': 0.133, 'train_loss': 4.041939973831177e-07, 'epoch': 0.0}
[EP 0003] 3 | reward_mean=-1.375 | 
*** stats:  {'episode_reward_mean': -1.375, 'episode_reward_last': -1.625, 'episode_reward_std_mean': 1.0845194518566132, 'episode_reward_trajectory': [-2.125, -1.375, -1.375, -1.0, -1.5, -1.375, -1.0, -0.625, -1.75, -1.625], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.375, 'rewards/match_format_approximately/mean/last': -1.375, 'rewards/match_format_approximately/std/mean': 1.0006967902183532, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': -0.25, 'rewards/check_numbers/std/mean': 0.22886751294136048, 'rewards/check_numbers/std/last': 0.28867512941360474}
Curr reward  -1.375
All rewards  -4.8375
Cumulative rewards  [-2.275, -0.15, -1.0375, -1.375, 0]
Num plays  [1, 1, 1, 1, 0]
Mean rewards  [-2.275, -0.15, -1.0375, -1.375, 0]
Balancing probabilities  [0, 0, 0, 1, 0]
Mis-Specification Test [1, 1, 1, 1, 0]
potentials:  [2. 2. 2. 2. 1.]
sampled base index:  4
potentials:  [2. 2. 2. 2. 1.]
sampled base index:  4
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:10<01:33, 10.35s/it]                                               10%|â–ˆ         | 1/10 [00:10<01:33, 10.35s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:16<01:03,  7.93s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:16<01:03,  7.93s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:44,  6.38s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:44,  6.38s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:27<00:38,  6.42s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:27<00:38,  6.42s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:36<00:37,  7.45s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:36<00:37,  7.45s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:41<00:26,  6.54s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:41<00:26,  6.54s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:46<00:18,  6.05s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:46<00:18,  6.05s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:54<00:12,  6.46s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:54<00:12,  6.46s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:06<00:08,  8.33s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:06<00:08,  8.33s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:10<00:00,  7.06s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:10<00:00,  7.06s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:12<00:00,  7.06s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:12<00:00,  7.24s/it]
wandb: updating run metadata
wandb: uploading data
wandb: 
wandb: Run history:
wandb:      modelselection/base_3_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -2.275
wandb:      modelselection/base_1_episodic_reward -0.15
wandb:      modelselection/base_2_episodic_reward -1.0375
wandb:      modelselection/base_3_episodic_reward -1.375
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.375
wandb:       modelselection/selected_base_learner 3
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_160151-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_160338-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.30593082308769226, 'learning_rate': 1e-07, 'num_tokens': 2347.0, 'completions/mean_length': 420.75, 'completions/min_length': 322.0, 'completions/max_length': 592.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 420.75, 'completions/min_terminated_length': 322.0, 'completions/max_terminated_length': 592.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 1.8874585628509521, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 420.75, 'kl': 0.0006882376037538052, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3518277108669281, 'learning_rate': 1e-07, 'num_tokens': 3662.0, 'completions/mean_length': 203.75, 'completions/min_length': 120.0, 'completions/max_length': 315.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 203.75, 'completions/min_terminated_length': 120.0, 'completions/max_terminated_length': 315.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 203.75, 'kl': 0.0003052121992368484, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5119081139564514, 'learning_rate': 1e-07, 'num_tokens': 4841.0, 'completions/mean_length': 171.75, 'completions/min_length': 134.0, 'completions/max_length': 201.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 171.75, 'completions/min_terminated_length': 134.0, 'completions/max_terminated_length': 201.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 171.75, 'kl': 0.0003481975363683887, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.31586965918540955, 'learning_rate': 1e-07, 'num_tokens': 6609.0, 'completions/mean_length': 292.0, 'completions/min_length': 251.0, 'completions/max_length': 336.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 292.0, 'completions/min_terminated_length': 251.0, 'completions/max_terminated_length': 336.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -1.25, 'reward_std': 0.28867512941360474, 'frac_reward_zero_std': 0.0, 'completion_length': 292.0, 'kl': 0.000323728487273911, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.34788283705711365, 'learning_rate': 1e-07, 'num_tokens': 8793.0, 'completions/mean_length': 390.0, 'completions/min_length': 215.0, 'completions/max_length': 527.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 390.0, 'completions/min_terminated_length': 215.0, 'completions/max_terminated_length': 527.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.0, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 390.0, 'kl': 0.0002549286946305074, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.37235966324806213, 'learning_rate': 1e-07, 'num_tokens': 9934.0, 'completions/mean_length': 157.25, 'completions/min_length': 119.0, 'completions/max_length': 216.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 157.25, 'completions/min_terminated_length': 119.0, 'completions/max_terminated_length': 216.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': -0.875, 'reward_std': 0.9464846849441528, 'frac_reward_zero_std': 0.0, 'completion_length': 157.25, 'kl': 0.0004453938381629996, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5140470266342163, 'learning_rate': 1e-07, 'num_tokens': 11244.0, 'completions/mean_length': 188.5, 'completions/min_length': 140.0, 'completions/max_length': 235.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 188.5, 'completions/min_terminated_length': 140.0, 'completions/max_terminated_length': 235.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -1.5, 'reward_std': 1.4142135381698608, 'frac_reward_zero_std': 0.0, 'completion_length': 188.5, 'kl': 0.00045184065675130114, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.38095858693122864, 'learning_rate': 1e-07, 'num_tokens': 13070.0, 'completions/mean_length': 315.5, 'completions/min_length': 193.0, 'completions/max_length': 397.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 315.5, 'completions/min_terminated_length': 193.0, 'completions/max_terminated_length': 397.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 315.5, 'kl': 0.0005831865491927601, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.28016960620880127, 'learning_rate': 1e-07, 'num_tokens': 15007.0, 'completions/mean_length': 353.25, 'completions/min_length': 174.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 225.6666717529297, 'completions/min_terminated_length': 174.0, 'completions/max_terminated_length': 273.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.75, 'reward_std': 0.5, 'frac_reward_zero_std': 0.0, 'completion_length': 353.25, 'kl': 0.0003364408985362388, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5727348923683167, 'learning_rate': 1e-07, 'num_tokens': 16087.0, 'completions/mean_length': 164.0, 'completions/min_length': 146.0, 'completions/max_length': 183.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 164.0, 'completions/min_terminated_length': 146.0, 'completions/max_terminated_length': 183.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -1.625, 'reward_std': 0.6291528940200806, 'frac_reward_zero_std': 0.0, 'completion_length': 164.0, 'kl': 0.0003741555046872236, 'epoch': 0.0}
{'train_runtime': 72.4001, 'train_samples_per_second': 0.552, 'train_steps_per_second': 0.138, 'train_loss': 4.0273616832564583e-07, 'epoch': 0.0}
[EP 0004] 4 | reward_mean=-1.225 | 
*** stats:  {'episode_reward_mean': -1.225, 'episode_reward_last': -1.625, 'episode_reward_std_mean': 0.9590219557285309, 'episode_reward_trajectory': [-2.125, -1.0, -1.0, -1.25, -1.0, -0.875, -1.5, -1.125, -0.75, -1.625], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.225, 'rewards/match_format_approximately/mean/last': -1.375, 'rewards/match_format_approximately/std/mean': 0.7452973783016205, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': -0.25, 'rewards/check_numbers/std/mean': 0.36398603916168215, 'rewards/check_numbers/std/last': 0.28867512941360474}
Curr reward  -1.225
All rewards  -6.0625
Cumulative rewards  [-2.275, -0.15, -1.0375, -1.375, -1.225]
Num plays  [1, 1, 1, 1, 1]
Mean rewards  [-2.275, -0.15, -1.0375, -1.375, -1.225]
Balancing probabilities  [0, 0, 0, 0, 1]
Mis-Specification Test [1, 1, 1, 1, 1]
potentials:  [2. 2. 2. 2. 2.]
sampled base index:  0
potentials:  [2. 2. 2. 2. 2.]
sampled base index:  0
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:52, 12.46s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:52, 12.46s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.33s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.33s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:26, 12.29s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:26, 12.29s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.29s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.29s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.32s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.32s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.30s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.30s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.29s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.29s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.29s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.29s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.28s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.28s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.28s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.28s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.28s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.48s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_4_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -2.275
wandb:      modelselection/base_1_episodic_reward -0.15
wandb:      modelselection/base_2_episodic_reward -1.0375
wandb:      modelselection/base_3_episodic_reward -1.375
wandb:      modelselection/base_4_episodic_reward -1.225
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.225
wandb:       modelselection/selected_base_learner 4
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_160338-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_160547-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.0023205126635730267, 'learning_rate': 0.001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.22029944136738777, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0023753056302666664, 'learning_rate': 0.001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.24460076540708542, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.00087446701945737, 'learning_rate': 0.001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.220283892005682, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.0015132268890738487, 'learning_rate': 0.001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.39996638149023056, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0018338784575462341, 'learning_rate': 0.001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.266427356749773, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.003043483244255185, 'learning_rate': 0.001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.27206096425652504, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0007388261146843433, 'learning_rate': 0.001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.18212061189115047, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0011682884069159627, 'learning_rate': 0.001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.22504126653075218, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0011998791014775634, 'learning_rate': 0.001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.15307612158358097, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0012383854482322931, 'learning_rate': 0.001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.17788761481642723, 'epoch': 0.0}
{'train_runtime': 124.8322, 'train_samples_per_second': 0.32, 'train_steps_per_second': 0.08, 'train_loss': 0.0002361764505621977, 'epoch': 0.0}
[EP 0005] 0 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  -10.0625
Cumulative rewards  [-6.275, -0.15, -1.0375, -1.375, -1.225]
Num plays  [2, 1, 1, 1, 1]
Mean rewards  [-3.1375, -0.15, -1.0375, -1.375, -1.225]
Balancing probabilities  [1, 0, 0, 0, 0]
Mis-Specification Test [2, 1, 1, 1, 1]
potentials:  [5.65685425 2.         2.         2.         2.        ]
sampled base index:  1
potentials:  [5.65685425 2.         2.         2.         2.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:08<01:16,  8.47s/it]                                               10%|â–ˆ         | 1/10 [00:08<01:16,  8.47s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:19<01:18,  9.79s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:19<01:18,  9.79s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:24<00:54,  7.79s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:24<00:54,  7.79s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:36<00:57,  9.60s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:36<00:57,  9.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:49<00:53, 10.63s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:49<00:53, 10.63s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:54<00:35,  8.86s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:54<00:35,  8.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:04<00:26,  8.96s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:04<00:26,  8.96s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:10<00:16,  8.08s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:10<00:16,  8.08s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:22<00:09,  9.42s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:22<00:09,  9.42s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:32<00:00,  9.43s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:32<00:00,  9.43s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:33<00:00,  9.43s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:33<00:00,  9.38s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_0_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -0.15
wandb:      modelselection/base_2_episodic_reward -1.0375
wandb:      modelselection/base_3_episodic_reward -1.375
wandb:      modelselection/base_4_episodic_reward -1.225
wandb:               modelselection/learning_rate 0.001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 0
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_160547-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_160725-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.3254959285259247, 'learning_rate': 0.0001, 'num_tokens': 2239.0, 'completions/mean_length': 393.75, 'completions/min_length': 298.0, 'completions/max_length': 471.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 393.75, 'completions/min_terminated_length': 298.0, 'completions/max_terminated_length': 471.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': 0.25, 'reward_std': 1.2583057880401611, 'frac_reward_zero_std': 0.0, 'completion_length': 393.75, 'kl': 0.029168746434152126, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.3968994915485382, 'learning_rate': 0.0001, 'num_tokens': 4079.0, 'completions/mean_length': 335.0, 'completions/min_length': 209.0, 'completions/max_length': 620.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 335.0, 'completions/min_terminated_length': 209.0, 'completions/max_terminated_length': 620.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 335.0, 'kl': 0.11663823761045933, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.5301607251167297, 'learning_rate': 0.0001, 'num_tokens': 5492.0, 'completions/mean_length': 230.25, 'completions/min_length': 188.0, 'completions/max_length': 261.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 230.25, 'completions/min_terminated_length': 188.0, 'completions/max_terminated_length': 261.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 230.25, 'kl': 0.14085685461759567, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.2027246505022049, 'learning_rate': 0.0001, 'num_tokens': 7893.0, 'completions/mean_length': 450.25, 'completions/min_length': 222.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 355.0, 'completions/min_terminated_length': 222.0, 'completions/max_terminated_length': 444.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -0.125, 'reward_std': 0.6291528940200806, 'frac_reward_zero_std': 0.0, 'completion_length': 450.25, 'kl': 0.06187796965241432, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.25041040778160095, 'learning_rate': 0.0001, 'num_tokens': 10281.0, 'completions/mean_length': 441.0, 'completions/min_length': 302.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 342.66668701171875, 'completions/min_terminated_length': 302.0, 'completions/max_terminated_length': 363.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 0.0, 'reward_std': 1.8708287477493286, 'frac_reward_zero_std': 0.0, 'completion_length': 441.0, 'kl': 0.10139046749100089, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.38201841711997986, 'learning_rate': 0.0001, 'num_tokens': 11755.0, 'completions/mean_length': 240.5, 'completions/min_length': 218.0, 'completions/max_length': 261.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 240.5, 'completions/min_terminated_length': 218.0, 'completions/max_terminated_length': 261.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 1.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 240.5, 'kl': 0.10361002385616302, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.39215418696403503, 'learning_rate': 0.0001, 'num_tokens': 13820.0, 'completions/mean_length': 377.25, 'completions/min_length': 272.0, 'completions/max_length': 519.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 377.25, 'completions/min_terminated_length': 272.0, 'completions/max_terminated_length': 519.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 377.25, 'kl': 0.11054489202797413, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.32515019178390503, 'learning_rate': 0.0001, 'num_tokens': 15515.0, 'completions/mean_length': 282.75, 'completions/min_length': 253.0, 'completions/max_length': 313.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 282.75, 'completions/min_terminated_length': 253.0, 'completions/max_terminated_length': 313.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': 0.125, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 282.75, 'kl': 0.1410328121855855, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.2594306766986847, 'learning_rate': 0.0001, 'num_tokens': 17985.0, 'completions/mean_length': 486.5, 'completions/min_length': 395.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 403.3333435058594, 'completions/min_terminated_length': 395.0, 'completions/max_terminated_length': 414.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.375, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 486.5, 'kl': 0.09555607195943594, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.009518724866211414, 'learning_rate': 0.0001, 'num_tokens': 19745.0, 'completions/mean_length': 334.0, 'completions/min_length': 174.0, 'completions/max_length': 541.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 334.0, 'completions/min_terminated_length': 174.0, 'completions/max_terminated_length': 541.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 334.0, 'kl': 0.18483288027346134, 'epoch': 0.0}
{'train_runtime': 93.7632, 'train_samples_per_second': 0.427, 'train_steps_per_second': 0.107, 'train_loss': 0.00010854316351469607, 'epoch': 0.0}
[EP 0006] 1 | reward_mean=0.562 | 
*** stats:  {'episode_reward_mean': 0.5625, 'episode_reward_last': 0.0, 'episode_reward_std_mean': 0.9059789717197418, 'episode_reward_trajectory': [0.25, 1.125, 1.625, -0.125, 0.0, 1.25, 1.0, 0.125, 0.375, 0.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.275, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.36861406564712523, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.2875, 'rewards/check_numbers/mean/last': -0.5, 'rewards/check_numbers/std/mean': 0.7183463931083679, 'rewards/check_numbers/std/last': 0.0}
Curr reward  0.5625
All rewards  -9.5
Cumulative rewards  [-6.275, 0.4125, -1.0375, -1.375, -1.225]
Num plays  [2, 2, 1, 1, 1]
Mean rewards  [-3.1375, 0.20625, -1.0375, -1.375, -1.225]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [2, 2, 1, 1, 1]
potentials:  [5.65685425 5.65685425 2.         2.         2.        ]
sampled base index:  2
potentials:  [5.65685425 5.65685425 2.         2.         2.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:06,  7.42s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:06,  7.42s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:13<00:52,  6.56s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:13<00:52,  6.56s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:44,  6.29s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:44,  6.29s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:34,  5.80s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:34,  5.80s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:32<00:33,  6.71s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:32<00:33,  6.71s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:37<00:24,  6.07s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:37<00:24,  6.07s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:45<00:20,  6.76s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:45<00:20,  6.76s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:50<00:12,  6.17s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:50<00:12,  6.17s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:59<00:07,  7.09s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:59<00:07,  7.09s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:07<00:00,  7.16s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:07<00:00,  7.16s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:09<00:00,  7.16s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:09<00:00,  6.92s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.5625
wandb:      modelselection/base_2_episodic_reward -1.0375
wandb:      modelselection/base_3_episodic_reward -1.375
wandb:      modelselection/base_4_episodic_reward -1.225
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 0.5625
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_160725-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_160838-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.45122647285461426, 'learning_rate': 1e-05, 'num_tokens': 1814.0, 'completions/mean_length': 287.5, 'completions/min_length': 190.0, 'completions/max_length': 397.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 287.5, 'completions/min_terminated_length': 190.0, 'completions/max_terminated_length': 397.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 287.5, 'kl': 0.0012953518307767808, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 7.193363853730261e-05, 'learning_rate': 1e-05, 'num_tokens': 3187.0, 'completions/mean_length': 218.25, 'completions/min_length': 178.0, 'completions/max_length': 294.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 218.25, 'completions/min_terminated_length': 178.0, 'completions/max_terminated_length': 294.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 218.25, 'kl': 0.0008963258514995687, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.45276767015457153, 'learning_rate': 1e-05, 'num_tokens': 4626.0, 'completions/mean_length': 236.75, 'completions/min_length': 181.0, 'completions/max_length': 300.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 236.75, 'completions/min_terminated_length': 181.0, 'completions/max_terminated_length': 300.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.75, 'reward_std': 0.5, 'frac_reward_zero_std': 0.0, 'completion_length': 236.75, 'kl': 0.0010599005327094346, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4064219892024994, 'learning_rate': 1e-05, 'num_tokens': 6064.0, 'completions/mean_length': 209.5, 'completions/min_length': 191.0, 'completions/max_length': 236.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 209.5, 'completions/min_terminated_length': 191.0, 'completions/max_terminated_length': 236.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.125, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 209.5, 'kl': 0.0008895228384062648, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.2747879922389984, 'learning_rate': 1e-05, 'num_tokens': 7839.0, 'completions/mean_length': 287.75, 'completions/min_length': 220.0, 'completions/max_length': 455.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 287.75, 'completions/min_terminated_length': 220.0, 'completions/max_terminated_length': 455.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 287.75, 'kl': 0.0004745865080622025, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.7642797231674194, 'learning_rate': 1e-05, 'num_tokens': 8993.0, 'completions/mean_length': 160.5, 'completions/min_length': 131.0, 'completions/max_length': 219.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 160.5, 'completions/min_terminated_length': 131.0, 'completions/max_terminated_length': 219.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 160.5, 'kl': 0.004031849355669692, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4101291000843048, 'learning_rate': 1e-05, 'num_tokens': 10782.0, 'completions/mean_length': 308.25, 'completions/min_length': 158.0, 'completions/max_length': 453.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 308.25, 'completions/min_terminated_length': 158.0, 'completions/max_terminated_length': 453.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.75, 'reward_std': 1.3228756189346313, 'frac_reward_zero_std': 0.0, 'completion_length': 308.25, 'kl': 0.0009204937814502046, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4553873836994171, 'learning_rate': 1e-05, 'num_tokens': 12110.0, 'completions/mean_length': 191.0, 'completions/min_length': 135.0, 'completions/max_length': 226.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 191.0, 'completions/min_terminated_length': 135.0, 'completions/max_terminated_length': 226.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': -0.375, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 191.0, 'kl': 0.005332549684680998, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3096221387386322, 'learning_rate': 1e-05, 'num_tokens': 13993.0, 'completions/mean_length': 339.75, 'completions/min_length': 162.0, 'completions/max_length': 517.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 339.75, 'completions/min_terminated_length': 162.0, 'completions/max_terminated_length': 517.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': -0.875, 'reward_std': 1.973786473274231, 'frac_reward_zero_std': 0.0, 'completion_length': 339.75, 'kl': 0.001047275887685828, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4956560730934143, 'learning_rate': 1e-05, 'num_tokens': 15480.0, 'completions/mean_length': 265.75, 'completions/min_length': 207.0, 'completions/max_length': 391.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 265.75, 'completions/min_terminated_length': 207.0, 'completions/max_terminated_length': 391.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': -0.875, 'reward_std': 0.9464846849441528, 'frac_reward_zero_std': 0.0, 'completion_length': 265.75, 'kl': 0.03810938773676753, 'epoch': 0.0}
{'train_runtime': 69.16, 'train_samples_per_second': 0.578, 'train_steps_per_second': 0.145, 'train_loss': 5.401151497608225e-06, 'epoch': 0.0}
[EP 0007] 2 | reward_mean=-0.825 | 
*** stats:  {'episode_reward_mean': -0.825, 'episode_reward_last': -0.875, 'episode_reward_std_mean': 0.9576089203357696, 'episode_reward_trajectory': [-1.75, -1.0, -0.75, 0.125, -1.375, -0.625, -0.75, -0.375, -0.875, -0.875], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -0.9625, 'rewards/match_format_approximately/mean/last': -1.0, 'rewards/match_format_approximately/std/mean': 0.6526910960674286, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.1375, 'rewards/check_numbers/mean/last': 0.125, 'rewards/check_numbers/std/mean': 0.42897712588310244, 'rewards/check_numbers/std/last': 0.9464847445487976}
Curr reward  -0.825
All rewards  -10.325
Cumulative rewards  [-6.275, 0.4125, -1.8625, -1.375, -1.225]
Num plays  [2, 2, 2, 1, 1]
Mean rewards  [-3.1375, 0.20625, -0.93125, -1.375, -1.225]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [2, 2, 2, 1, 1]
potentials:  [5.65685425 5.65685425 5.65685425 2.         2.        ]
sampled base index:  3
potentials:  [5.65685425 5.65685425 5.65685425 2.         2.        ]
sampled base index:  3
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:08<01:20,  8.90s/it]                                               10%|â–ˆ         | 1/10 [00:08<01:20,  8.90s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:13<00:52,  6.53s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:13<00:52,  6.53s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:41,  5.95s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:41,  5.95s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:34,  5.75s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:34,  5.75s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:35<00:37,  7.55s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:35<00:37,  7.55s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:39<00:25,  6.35s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:39<00:25,  6.35s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:44<00:18,  6.05s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:44<00:18,  6.05s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:49<00:11,  5.58s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:49<00:11,  5.58s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:55<00:05,  5.68s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:55<00:05,  5.68s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  5.74s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  5.74s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  5.74s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  6.30s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.5625
wandb:      modelselection/base_2_episodic_reward -0.825
wandb:      modelselection/base_3_episodic_reward -1.375
wandb:      modelselection/base_4_episodic_reward -1.225
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward -0.825
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_160838-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_160946-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.387489914894104, 'learning_rate': 1e-06, 'num_tokens': 2225.0, 'completions/mean_length': 390.25, 'completions/min_length': 255.0, 'completions/max_length': 493.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 390.25, 'completions/min_terminated_length': 255.0, 'completions/max_terminated_length': 493.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.875, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.875, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 390.25, 'kl': 0.0005567115440499038, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 7.295092655112967e-05, 'learning_rate': 1e-06, 'num_tokens': 3419.0, 'completions/mean_length': 173.5, 'completions/min_length': 141.0, 'completions/max_length': 221.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 173.5, 'completions/min_terminated_length': 141.0, 'completions/max_terminated_length': 221.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 173.5, 'kl': 0.0003262548962084111, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.6599736213684082, 'learning_rate': 1e-06, 'num_tokens': 4692.0, 'completions/mean_length': 195.25, 'completions/min_length': 170.0, 'completions/max_length': 247.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 195.25, 'completions/min_terminated_length': 170.0, 'completions/max_terminated_length': 247.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 195.25, 'kl': 0.0005087906429253053, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3413707911968231, 'learning_rate': 1e-06, 'num_tokens': 6157.0, 'completions/mean_length': 216.25, 'completions/min_length': 176.0, 'completions/max_length': 262.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 216.25, 'completions/min_terminated_length': 176.0, 'completions/max_terminated_length': 262.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 1.8874585628509521, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -1.625, 'reward_std': 1.7017147541046143, 'frac_reward_zero_std': 0.0, 'completion_length': 216.25, 'kl': 0.00032587727037025616, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.2910225987434387, 'learning_rate': 1e-06, 'num_tokens': 8237.0, 'completions/mean_length': 364.0, 'completions/min_length': 240.0, 'completions/max_length': 622.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 364.0, 'completions/min_terminated_length': 240.0, 'completions/max_terminated_length': 622.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 364.0, 'kl': 0.00029389351766440086, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.8178523778915405, 'learning_rate': 1e-06, 'num_tokens': 9290.0, 'completions/mean_length': 135.25, 'completions/min_length': 79.0, 'completions/max_length': 167.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 135.25, 'completions/min_terminated_length': 79.0, 'completions/max_terminated_length': 167.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 135.25, 'kl': 0.0003890638690791093, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5160865187644958, 'learning_rate': 1e-06, 'num_tokens': 10581.0, 'completions/mean_length': 183.75, 'completions/min_length': 120.0, 'completions/max_length': 258.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 183.75, 'completions/min_terminated_length': 120.0, 'completions/max_terminated_length': 258.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': -0.875, 'reward_std': 1.3768926858901978, 'frac_reward_zero_std': 0.0, 'completion_length': 183.75, 'kl': 0.00047513851313851774, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4052983820438385, 'learning_rate': 1e-06, 'num_tokens': 11895.0, 'completions/mean_length': 187.5, 'completions/min_length': 163.0, 'completions/max_length': 201.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 187.5, 'completions/min_terminated_length': 163.0, 'completions/max_terminated_length': 201.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 187.5, 'kl': 0.0003668880308396183, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3882264792919159, 'learning_rate': 1e-06, 'num_tokens': 13353.0, 'completions/mean_length': 233.5, 'completions/min_length': 150.0, 'completions/max_length': 292.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 233.5, 'completions/min_terminated_length': 150.0, 'completions/max_terminated_length': 292.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 233.5, 'kl': 0.0005538803306990303, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.37868285179138184, 'learning_rate': 1e-06, 'num_tokens': 14743.0, 'completions/mean_length': 241.5, 'completions/min_length': 127.0, 'completions/max_length': 293.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 241.5, 'completions/min_terminated_length': 127.0, 'completions/max_terminated_length': 293.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -1.25, 'reward_std': 0.28867512941360474, 'frac_reward_zero_std': 0.0, 'completion_length': 241.5, 'kl': 0.000400275421270635, 'epoch': 0.0}
{'train_runtime': 63.0185, 'train_samples_per_second': 0.635, 'train_steps_per_second': 0.159, 'train_loss': 4.289963783321582e-07, 'epoch': 0.0}
[EP 0008] 3 | reward_mean=-1.250 | 
*** stats:  {'episode_reward_mean': -1.25, 'episode_reward_last': -1.25, 'episode_reward_std_mean': 0.8099333345890045, 'episode_reward_trajectory': [-2.875, -1.0, -0.625, -1.625, -0.25, -1.125, -0.875, -1.125, -1.75, -1.25], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.3, 'rewards/match_format_approximately/mean/last': -1.0, 'rewards/match_format_approximately/std/mean': 0.5952973783016204, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.05, 'rewards/check_numbers/mean/last': -0.25, 'rewards/check_numbers/std/mean': 0.36398603916168215, 'rewards/check_numbers/std/last': 0.28867512941360474}
Curr reward  -1.25
All rewards  -11.575
Cumulative rewards  [-6.275, 0.4125, -1.8625, -2.625, -1.225]
Num plays  [2, 2, 2, 2, 1]
Mean rewards  [-3.1375, 0.20625, -0.93125, -1.3125, -1.225]
Balancing probabilities  [0, 0, 0, 1, 0]
Mis-Specification Test [2, 2, 2, 2, 1]
potentials:  [5.65685425 5.65685425 5.65685425 5.65685425 2.        ]
sampled base index:  4
potentials:  [5.65685425 5.65685425 5.65685425 5.65685425 2.        ]
sampled base index:  4
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.43s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.43s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:17<01:06,  8.31s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:17<01:06,  8.31s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:49,  7.13s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:49,  7.13s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:30<00:42,  7.08s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:30<00:42,  7.08s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:36<00:33,  6.75s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:36<00:33,  6.75s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:40<00:23,  5.89s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:40<00:23,  5.89s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:46<00:17,  5.74s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:46<00:17,  5.74s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:52<00:11,  5.80s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:52<00:11,  5.80s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:57<00:05,  5.66s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:57<00:05,  5.66s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:05<00:00,  6.24s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:05<00:00,  6.24s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:07<00:00,  6.24s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:07<00:00,  6.70s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_3_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.5625
wandb:      modelselection/base_2_episodic_reward -0.825
wandb:      modelselection/base_3_episodic_reward -1.25
wandb:      modelselection/base_4_episodic_reward -1.225
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.25
wandb:       modelselection/selected_base_learner 3
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_160946-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_161057-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.31338387727737427, 'learning_rate': 1e-07, 'num_tokens': 2750.0, 'completions/mean_length': 521.5, 'completions/min_length': 299.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 450.0, 'completions/min_terminated_length': 299.0, 'completions/max_terminated_length': 635.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 1.8874585628509521, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 521.5, 'kl': 0.0005168724528630264, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00011793789599323645, 'learning_rate': 1e-07, 'num_tokens': 3995.0, 'completions/mean_length': 186.25, 'completions/min_length': 142.0, 'completions/max_length': 254.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 186.25, 'completions/min_terminated_length': 142.0, 'completions/max_terminated_length': 254.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 186.25, 'kl': 0.0004089200847374741, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3551492989063263, 'learning_rate': 1e-07, 'num_tokens': 5379.0, 'completions/mean_length': 223.0, 'completions/min_length': 159.0, 'completions/max_length': 278.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 223.0, 'completions/min_terminated_length': 159.0, 'completions/max_terminated_length': 278.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 223.0, 'kl': 0.00021994650523993187, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.37322285771369934, 'learning_rate': 1e-07, 'num_tokens': 7145.0, 'completions/mean_length': 291.5, 'completions/min_length': 231.0, 'completions/max_length': 365.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 291.5, 'completions/min_terminated_length': 231.0, 'completions/max_terminated_length': 365.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -1.625, 'reward_std': 0.6291528940200806, 'frac_reward_zero_std': 0.0, 'completion_length': 291.5, 'kl': 0.00042525905155343935, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.39785516262054443, 'learning_rate': 1e-07, 'num_tokens': 8901.0, 'completions/mean_length': 283.0, 'completions/min_length': 240.0, 'completions/max_length': 305.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 283.0, 'completions/min_terminated_length': 240.0, 'completions/max_terminated_length': 305.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 283.0, 'kl': 0.0003359049078426324, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.44436487555503845, 'learning_rate': 1e-07, 'num_tokens': 9955.0, 'completions/mean_length': 135.5, 'completions/min_length': 108.0, 'completions/max_length': 172.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 135.5, 'completions/min_terminated_length': 108.0, 'completions/max_terminated_length': 172.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': -0.875, 'reward_std': 1.973786473274231, 'frac_reward_zero_std': 0.0, 'completion_length': 135.5, 'kl': 0.0004250224883435294, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5526484251022339, 'learning_rate': 1e-07, 'num_tokens': 11275.0, 'completions/mean_length': 191.0, 'completions/min_length': 115.0, 'completions/max_length': 260.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 191.0, 'completions/min_terminated_length': 115.0, 'completions/max_terminated_length': 260.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 0.0, 'reward_std': 0.7071067690849304, 'frac_reward_zero_std': 0.0, 'completion_length': 191.0, 'kl': 0.0005479890096466988, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.34952041506767273, 'learning_rate': 1e-07, 'num_tokens': 12797.0, 'completions/mean_length': 239.5, 'completions/min_length': 188.0, 'completions/max_length': 289.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 223.0, 'completions/min_terminated_length': 188.0, 'completions/max_terminated_length': 289.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.5, 'reward_std': 0.7071067690849304, 'frac_reward_zero_std': 0.0, 'completion_length': 211.0, 'kl': 0.0004700975405285135, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.37598365545272827, 'learning_rate': 1e-07, 'num_tokens': 14251.0, 'completions/mean_length': 232.5, 'completions/min_length': 214.0, 'completions/max_length': 252.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 232.5, 'completions/min_terminated_length': 214.0, 'completions/max_terminated_length': 252.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.75, 'reward_std': 1.3228756189346313, 'frac_reward_zero_std': 0.0, 'completion_length': 232.5, 'kl': 0.00036647248634835705, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4901823103427887, 'learning_rate': 1e-07, 'num_tokens': 15551.0, 'completions/mean_length': 219.0, 'completions/min_length': 134.0, 'completions/max_length': 401.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 219.0, 'completions/min_terminated_length': 134.0, 'completions/max_terminated_length': 401.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 219.0, 'kl': 0.0006094170748838224, 'epoch': 0.0}
{'train_runtime': 67.0151, 'train_samples_per_second': 0.597, 'train_steps_per_second': 0.149, 'train_loss': 4.326782232055848e-07, 'epoch': 0.0}
[EP 0009] 4 | reward_mean=-1.225 | 
*** stats:  {'episode_reward_mean': -1.225, 'episode_reward_last': -1.125, 'episode_reward_std_mean': 1.0163627743721009, 'episode_reward_trajectory': [-2.125, -1.0, -1.125, -1.625, -2.125, -0.875, 0.0, -1.5, -0.75, -1.125], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.2625, 'rewards/match_format_approximately/mean/last': -1.0, 'rewards/match_format_approximately/std/mean': 0.9247833967208863, 'rewards/match_format_approximately/std/last': 1.2247449159622192, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0375, 'rewards/check_numbers/mean/last': -0.125, 'rewards/check_numbers/std/mean': 0.38819616436958315, 'rewards/check_numbers/std/last': 0.25}
Curr reward  -1.225
All rewards  -12.799999999999999
Cumulative rewards  [-6.275, 0.4125, -1.8625, -2.625, -2.45]
Num plays  [2, 2, 2, 2, 2]
Mean rewards  [-3.1375, 0.20625, -0.93125, -1.3125, -1.225]
Balancing probabilities  [0, 0, 0, 0, 1]
Mis-Specification Test [2, 2, 2, 2, 2]
potentials:  [5.65685425 5.65685425 5.65685425 5.65685425 5.65685425]
sampled base index:  0
potentials:  [5.65685425 5.65685425 5.65685425 5.65685425 5.65685425]
sampled base index:  0
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.39s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.39s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.35s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.35s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:37<01:26, 12.32s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:37<01:26, 12.32s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.33s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.33s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.35s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.35s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:14<00:49, 12.33s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:14<00:49, 12.33s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:37, 12.34s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:37, 12.34s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.34s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.34s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:51<00:12, 12.34s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:51<00:12, 12.34s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:03<00:00, 12.33s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:03<00:00, 12.33s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:05<00:00, 12.33s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:05<00:00, 12.52s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_4_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.5625
wandb:      modelselection/base_2_episodic_reward -0.825
wandb:      modelselection/base_3_episodic_reward -1.25
wandb:      modelselection/base_4_episodic_reward -1.225
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.225
wandb:       modelselection/selected_base_learner 4
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_161057-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_161306-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.0007714227540418506, 'learning_rate': 0.001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.1540185548365116, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0009444131865166128, 'learning_rate': 0.001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.16341864317655563, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00041134352795779705, 'learning_rate': 0.001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.11960535310208797, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0008045482099987566, 'learning_rate': 0.001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.12694977223873138, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.004563773516565561, 'learning_rate': 0.001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.1835811510682106, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.00482856435701251, 'learning_rate': 0.001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.15329905413091183, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0017793282167986035, 'learning_rate': 0.001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.15771940723061562, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.001719595631584525, 'learning_rate': 0.001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.18941381201148033, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.031912945210933685, 'learning_rate': 0.001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.7521824985742569, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.014060349203646183, 'learning_rate': 0.001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3456725776195526, 'epoch': 0.0}
{'train_runtime': 125.1702, 'train_samples_per_second': 0.32, 'train_steps_per_second': 0.08, 'train_loss': 0.0002345860964851454, 'epoch': 0.0}
[EP 0010] 0 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  -16.799999999999997
Cumulative rewards  [-10.275, 0.4125, -1.8625, -2.625, -2.45]
Num plays  [3, 2, 2, 2, 2]
Mean rewards  [-3.4250000000000003, 0.20625, -0.93125, -1.3125, -1.225]
Balancing probabilities  [1, 0, 0, 0, 0]
Mis-Specification Test [3, 2, 2, 2, 2]
potentials:  [13.85640646  5.65685425  5.65685425  5.65685425  5.65685425]
sampled base index:  1
potentials:  [13.85640646  5.65685425  5.65685425  5.65685425  5.65685425]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:10,  7.81s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:10,  7.81s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:20<01:23, 10.41s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:20<01:23, 10.41s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:26<01:00,  8.70s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:26<01:00,  8.70s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:33<00:48,  8.03s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:33<00:48,  8.03s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:45<00:47,  9.56s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:45<00:47,  9.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:51<00:32,  8.01s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:51<00:32,  8.01s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:57<00:22,  7.57s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:57<00:22,  7.57s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:03<00:14,  7.03s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:03<00:14,  7.03s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:11<00:07,  7.43s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:11<00:07,  7.43s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:19<00:00,  7.36s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:19<00:00,  7.36s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:20<00:00,  7.36s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:20<00:00,  8.07s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_0_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.5625
wandb:      modelselection/base_2_episodic_reward -0.825
wandb:      modelselection/base_3_episodic_reward -1.25
wandb:      modelselection/base_4_episodic_reward -1.225
wandb:               modelselection/learning_rate 0.001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 0
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_161306-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_161431-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.36547261476516724, 'learning_rate': 0.0001, 'num_tokens': 2160.0, 'completions/mean_length': 374.0, 'completions/min_length': 331.0, 'completions/max_length': 426.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 374.0, 'completions/min_terminated_length': 331.0, 'completions/max_terminated_length': 426.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 0.625, 'reward_std': 1.7017147541046143, 'frac_reward_zero_std': 0.0, 'completion_length': 374.0, 'kl': 0.07834294345229864, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.23981794714927673, 'learning_rate': 0.0001, 'num_tokens': 4594.0, 'completions/mean_length': 483.5, 'completions/min_length': 254.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 399.3333435058594, 'completions/min_terminated_length': 254.0, 'completions/max_terminated_length': 585.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 0.875, 'reward_std': 2.25, 'frac_reward_zero_std': 0.0, 'completion_length': 483.5, 'kl': 0.12054435908794403, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.36151888966560364, 'learning_rate': 0.0001, 'num_tokens': 6201.0, 'completions/mean_length': 278.75, 'completions/min_length': 244.0, 'completions/max_length': 345.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 278.75, 'completions/min_terminated_length': 244.0, 'completions/max_terminated_length': 345.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.5, 'reward_std': 1.7320507764816284, 'frac_reward_zero_std': 0.0, 'completion_length': 278.75, 'kl': 0.17183438688516617, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.22377565503120422, 'learning_rate': 0.0001, 'num_tokens': 8116.0, 'completions/mean_length': 328.75, 'completions/min_length': 250.0, 'completions/max_length': 369.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 328.75, 'completions/min_terminated_length': 250.0, 'completions/max_terminated_length': 369.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 328.75, 'kl': 0.07218199502676725, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.24612027406692505, 'learning_rate': 0.0001, 'num_tokens': 10823.0, 'completions/mean_length': 520.75, 'completions/min_length': 266.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 449.0, 'completions/min_terminated_length': 266.0, 'completions/max_terminated_length': 655.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': -0.125, 'reward_std': 0.6291528940200806, 'frac_reward_zero_std': 0.0, 'completion_length': 520.75, 'kl': 0.07400182727724314, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0027879071421921253, 'learning_rate': 0.0001, 'num_tokens': 12120.0, 'completions/mean_length': 196.25, 'completions/min_length': 179.0, 'completions/max_length': 225.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 196.25, 'completions/min_terminated_length': 179.0, 'completions/max_terminated_length': 225.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 196.25, 'kl': 0.1475418619811535, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.003021199256181717, 'learning_rate': 0.0001, 'num_tokens': 13642.0, 'completions/mean_length': 241.5, 'completions/min_length': 198.0, 'completions/max_length': 341.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 241.5, 'completions/min_terminated_length': 198.0, 'completions/max_terminated_length': 341.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 241.5, 'kl': 0.18745801411569118, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0021356826182454824, 'learning_rate': 0.0001, 'num_tokens': 15284.0, 'completions/mean_length': 269.5, 'completions/min_length': 259.0, 'completions/max_length': 287.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 269.5, 'completions/min_terminated_length': 259.0, 'completions/max_terminated_length': 287.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': 0.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 269.5, 'kl': 0.09923181775957346, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.30092883110046387, 'learning_rate': 0.0001, 'num_tokens': 17344.0, 'completions/mean_length': 384.0, 'completions/min_length': 260.0, 'completions/max_length': 457.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 384.0, 'completions/min_terminated_length': 260.0, 'completions/max_terminated_length': 457.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 384.0, 'kl': 0.09642713330686092, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0010859505273401737, 'learning_rate': 0.0001, 'num_tokens': 19004.0, 'completions/mean_length': 309.0, 'completions/min_length': 202.0, 'completions/max_length': 384.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 309.0, 'completions/min_terminated_length': 202.0, 'completions/max_terminated_length': 384.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 309.0, 'kl': 0.10270927846431732, 'epoch': 0.0}
{'train_runtime': 80.7467, 'train_samples_per_second': 0.495, 'train_steps_per_second': 0.124, 'train_loss': 0.00011502951601869427, 'epoch': 0.0}
[EP 0011] 1 | reward_mean=0.863 | 
*** stats:  {'episode_reward_mean': 0.8625, 'episode_reward_last': 0.0, 'episode_reward_std_mean': 0.8178943812847137, 'episode_reward_trajectory': [0.625, 0.875, 0.5, 0.75, -0.125, 2.0, 2.0, 0.5, 1.5, 0.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.2375, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.3982050776481628, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.625, 'rewards/check_numbers/mean/last': -0.5, 'rewards/check_numbers/std/mean': 0.5583236038684845, 'rewards/check_numbers/std/last': 0.0}
Curr reward  0.8625
All rewards  -15.937499999999996
Cumulative rewards  [-10.275, 1.275, -1.8625, -2.625, -2.45]
Num plays  [3, 3, 2, 2, 2]
Mean rewards  [-3.4250000000000003, 0.425, -0.93125, -1.3125, -1.225]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [3, 3, 2, 2, 2]
potentials:  [13.85640646 13.85640646  5.65685425  5.65685425  5.65685425]
sampled base index:  2
potentials:  [13.85640646 13.85640646  5.65685425  5.65685425  5.65685425]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:08<01:19,  8.81s/it]                                               10%|â–ˆ         | 1/10 [00:08<01:19,  8.81s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:14<00:54,  6.81s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:14<00:54,  6.81s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:20<00:46,  6.67s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:20<00:46,  6.67s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:26<00:38,  6.35s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:26<00:38,  6.35s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:37<00:40,  8.05s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:37<00:40,  8.05s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:27,  6.82s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:27,  6.82s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:47<00:19,  6.41s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:47<00:19,  6.41s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:54<00:13,  6.57s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:54<00:13,  6.57s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:59<00:06,  6.20s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:59<00:06,  6.20s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:06<00:00,  6.30s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:06<00:00,  6.30s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:08<00:00,  6.30s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:08<00:00,  6.83s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.8625
wandb:      modelselection/base_2_episodic_reward -0.825
wandb:      modelselection/base_3_episodic_reward -1.25
wandb:      modelselection/base_4_episodic_reward -1.225
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 0.8625
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_161431-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_161543-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.350376695394516, 'learning_rate': 1e-05, 'num_tokens': 2249.0, 'completions/mean_length': 396.25, 'completions/min_length': 282.0, 'completions/max_length': 490.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 396.25, 'completions/min_terminated_length': 282.0, 'completions/max_terminated_length': 490.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 396.25, 'kl': 0.0012489020882640034, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.349520206451416, 'learning_rate': 1e-05, 'num_tokens': 3579.0, 'completions/mean_length': 207.5, 'completions/min_length': 171.0, 'completions/max_length': 259.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 207.5, 'completions/min_terminated_length': 171.0, 'completions/max_terminated_length': 259.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.25, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 207.5, 'kl': 0.002304881694726646, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3766229450702667, 'learning_rate': 1e-05, 'num_tokens': 5105.0, 'completions/mean_length': 258.5, 'completions/min_length': 184.0, 'completions/max_length': 339.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 258.5, 'completions/min_terminated_length': 184.0, 'completions/max_terminated_length': 339.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.125, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 258.5, 'kl': 0.003743600216694176, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3479372262954712, 'learning_rate': 1e-05, 'num_tokens': 6711.0, 'completions/mean_length': 251.5, 'completions/min_length': 208.0, 'completions/max_length': 290.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 251.5, 'completions/min_terminated_length': 208.0, 'completions/max_terminated_length': 290.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 251.5, 'kl': 0.0015903196763247252, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.31498953700065613, 'learning_rate': 1e-05, 'num_tokens': 9002.0, 'completions/mean_length': 416.75, 'completions/min_length': 189.0, 'completions/max_length': 647.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 416.75, 'completions/min_terminated_length': 189.0, 'completions/max_terminated_length': 647.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.0, 'reward_std': 2.1213202476501465, 'frac_reward_zero_std': 0.0, 'completion_length': 416.75, 'kl': 0.0029120137478457764, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5166041254997253, 'learning_rate': 1e-05, 'num_tokens': 10145.0, 'completions/mean_length': 157.75, 'completions/min_length': 139.0, 'completions/max_length': 193.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 157.75, 'completions/min_terminated_length': 139.0, 'completions/max_terminated_length': 193.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 157.75, 'kl': 0.022128032229375094, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5047789812088013, 'learning_rate': 1e-05, 'num_tokens': 11463.0, 'completions/mean_length': 190.5, 'completions/min_length': 109.0, 'completions/max_length': 271.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 190.5, 'completions/min_terminated_length': 109.0, 'completions/max_terminated_length': 271.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 0.0, 'reward_std': 0.7071067690849304, 'frac_reward_zero_std': 0.0, 'completion_length': 190.5, 'kl': 0.005580233788350597, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5429095029830933, 'learning_rate': 1e-05, 'num_tokens': 12968.0, 'completions/mean_length': 235.25, 'completions/min_length': 169.0, 'completions/max_length': 363.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 235.25, 'completions/min_terminated_length': 169.0, 'completions/max_terminated_length': 363.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 235.25, 'kl': 0.008897536201402545, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.38240721821784973, 'learning_rate': 1e-05, 'num_tokens': 14269.0, 'completions/mean_length': 194.25, 'completions/min_length': 102.0, 'completions/max_length': 260.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 194.25, 'completions/min_terminated_length': 102.0, 'completions/max_terminated_length': 260.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.125, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 194.25, 'kl': 0.008697135897818953, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4238409996032715, 'learning_rate': 1e-05, 'num_tokens': 15414.0, 'completions/mean_length': 180.25, 'completions/min_length': 97.0, 'completions/max_length': 335.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 180.25, 'completions/min_terminated_length': 97.0, 'completions/max_terminated_length': 335.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -1.625, 'reward_std': 1.1814539432525635, 'frac_reward_zero_std': 0.0, 'completion_length': 180.25, 'kl': 0.007853978720959276, 'epoch': 0.0}
{'train_runtime': 68.2615, 'train_samples_per_second': 0.586, 'train_steps_per_second': 0.146, 'train_loss': 6.5120885665237435e-06, 'epoch': 0.0}
[EP 0012] 2 | reward_mean=-0.537 | 
*** stats:  {'episode_reward_mean': -0.5375, 'episode_reward_last': -1.625, 'episode_reward_std_mean': 1.197293257713318, 'episode_reward_trajectory': [-1.5, -0.25, 0.125, -0.375, -1.0, -0.625, 0.0, -0.25, 0.125, -1.625], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -0.925, 'rewards/match_format_approximately/mean/last': -1.375, 'rewards/match_format_approximately/std/mean': 0.8924447357654571, 'rewards/match_format_approximately/std/last': 1.4361406564712524, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.3875, 'rewards/check_numbers/mean/last': -0.25, 'rewards/check_numbers/std/mean': 0.6783553063869476, 'rewards/check_numbers/std/last': 0.28867512941360474}
Curr reward  -0.5375
All rewards  -16.474999999999998
Cumulative rewards  [-10.275, 1.275, -2.4, -2.625, -2.45]
Num plays  [3, 3, 3, 2, 2]
Mean rewards  [-3.4250000000000003, 0.425, -0.7999999999999999, -1.3125, -1.225]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [3, 3, 3, 2, 2]
potentials:  [13.85640646 13.85640646 13.85640646  5.65685425  5.65685425]
sampled base index:  3
potentials:  [13.85640646 13.85640646 13.85640646  5.65685425  5.65685425]
sampled base index:  3
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.40s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.40s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:17<01:03,  7.97s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:17<01:03,  7.97s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:22<00:47,  6.78s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:22<00:47,  6.78s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:28<00:38,  6.44s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:28<00:38,  6.44s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:40<00:42,  8.58s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:40<00:42,  8.58s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:46<00:30,  7.72s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:46<00:30,  7.72s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:52<00:20,  6.84s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:52<00:20,  6.84s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:57<00:12,  6.42s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:57<00:12,  6.42s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:03<00:06,  6.41s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:03<00:06,  6.41s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:08<00:00,  5.87s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:08<00:00,  5.87s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:10<00:00,  5.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:10<00:00,  7.03s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.8625
wandb:      modelselection/base_2_episodic_reward -0.5375
wandb:      modelselection/base_3_episodic_reward -1.25
wandb:      modelselection/base_4_episodic_reward -1.225
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward -0.5375
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_161543-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_161658-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.5320031046867371, 'learning_rate': 1e-06, 'num_tokens': 2027.0, 'completions/mean_length': 340.75, 'completions/min_length': 147.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 209.0, 'completions/min_terminated_length': 147.0, 'completions/max_terminated_length': 317.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 340.75, 'kl': 0.0005110621495987289, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.9547267556190491, 'learning_rate': 1e-06, 'num_tokens': 3246.0, 'completions/mean_length': 179.75, 'completions/min_length': 140.0, 'completions/max_length': 218.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 179.75, 'completions/min_terminated_length': 140.0, 'completions/max_terminated_length': 218.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.25, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 179.75, 'kl': 0.0005961071874480695, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4906310737133026, 'learning_rate': 1e-06, 'num_tokens': 4508.0, 'completions/mean_length': 192.5, 'completions/min_length': 140.0, 'completions/max_length': 253.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 192.5, 'completions/min_terminated_length': 140.0, 'completions/max_terminated_length': 253.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.125, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 192.5, 'kl': 0.0003295172245998401, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.38531166315078735, 'learning_rate': 1e-06, 'num_tokens': 6089.0, 'completions/mean_length': 245.25, 'completions/min_length': 200.0, 'completions/max_length': 289.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 245.25, 'completions/min_terminated_length': 200.0, 'completions/max_terminated_length': 289.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -1.875, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 245.25, 'kl': 0.000262660385487834, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 2.5590588847990148e-05, 'learning_rate': 1e-06, 'num_tokens': 8375.0, 'completions/mean_length': 415.5, 'completions/min_length': 241.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 308.66668701171875, 'completions/min_terminated_length': 241.0, 'completions/max_terminated_length': 405.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 415.5, 'kl': 0.00026916666320175864, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.47793665528297424, 'learning_rate': 1e-06, 'num_tokens': 9632.0, 'completions/mean_length': 186.25, 'completions/min_length': 131.0, 'completions/max_length': 298.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 186.25, 'completions/min_terminated_length': 131.0, 'completions/max_terminated_length': 298.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 186.25, 'kl': 0.000520409201271832, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4909362494945526, 'learning_rate': 1e-06, 'num_tokens': 10894.0, 'completions/mean_length': 176.5, 'completions/min_length': 130.0, 'completions/max_length': 230.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 176.5, 'completions/min_terminated_length': 130.0, 'completions/max_terminated_length': 230.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': -1.0, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 176.5, 'kl': 0.0004984282568329945, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3525106906890869, 'learning_rate': 1e-06, 'num_tokens': 12301.0, 'completions/mean_length': 210.75, 'completions/min_length': 167.0, 'completions/max_length': 263.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 210.75, 'completions/min_terminated_length': 167.0, 'completions/max_terminated_length': 263.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': -0.375, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 210.75, 'kl': 0.00034528179457993247, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5409682989120483, 'learning_rate': 1e-06, 'num_tokens': 13674.0, 'completions/mean_length': 212.25, 'completions/min_length': 166.0, 'completions/max_length': 323.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 212.25, 'completions/min_terminated_length': 166.0, 'completions/max_terminated_length': 323.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 212.25, 'kl': 0.0007725565374130383, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.6000463962554932, 'learning_rate': 1e-06, 'num_tokens': 14745.0, 'completions/mean_length': 161.75, 'completions/min_length': 122.0, 'completions/max_length': 209.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 161.75, 'completions/min_terminated_length': 122.0, 'completions/max_terminated_length': 209.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.75, 'reward_std': 0.5, 'frac_reward_zero_std': 0.0, 'completion_length': 161.75, 'kl': 0.0002921673767559696, 'epoch': 0.0}
{'train_runtime': 70.3159, 'train_samples_per_second': 0.569, 'train_steps_per_second': 0.142, 'train_loss': 4.203073217468045e-07, 'epoch': 0.0}
[EP 0013] 3 | reward_mean=-1.012 | 
*** stats:  {'episode_reward_mean': -1.0125, 'episode_reward_last': -0.75, 'episode_reward_std_mean': 0.9859853386878967, 'episode_reward_trajectory': [-2.5, -0.25, 0.125, -1.875, -1.0, -0.75, -1.0, -0.375, -1.75, -0.75], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.225, 'rewards/match_format_approximately/mean/last': -0.625, 'rewards/match_format_approximately/std/mean': 0.5776910960674286, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.2125, 'rewards/check_numbers/mean/last': -0.125, 'rewards/check_numbers/std/mean': 0.5628852546215057, 'rewards/check_numbers/std/last': 0.25}
Curr reward  -1.0125
All rewards  -17.487499999999997
Cumulative rewards  [-10.275, 1.275, -2.4, -3.6375, -2.45]
Num plays  [3, 3, 3, 3, 2]
Mean rewards  [-3.4250000000000003, 0.425, -0.7999999999999999, -1.2125000000000001, -1.225]
Balancing probabilities  [0, 0, 0, 1, 0]
Mis-Specification Test [3, 3, 3, 3, 2]
potentials:  [13.85640646 13.85640646 13.85640646 13.85640646  5.65685425]
sampled base index:  4
potentials:  [13.85640646 13.85640646 13.85640646 13.85640646  5.65685425]
sampled base index:  4
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:08<01:16,  8.45s/it]                                               10%|â–ˆ         | 1/10 [00:08<01:16,  8.45s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:13<00:51,  6.41s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:13<00:51,  6.41s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:42,  6.01s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:42,  6.01s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:27<00:40,  6.82s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:27<00:40,  6.82s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:33<00:33,  6.72s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:33<00:33,  6.72s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:38<00:24,  6.01s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:38<00:24,  6.01s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:43<00:17,  5.71s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:43<00:17,  5.71s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:48<00:11,  5.63s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:48<00:11,  5.63s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:54<00:05,  5.71s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:54<00:05,  5.71s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:59<00:00,  5.51s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:59<00:00,  5.51s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  5.51s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_3_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.8625
wandb:      modelselection/base_2_episodic_reward -0.5375
wandb:      modelselection/base_3_episodic_reward -1.0125
wandb:      modelselection/base_4_episodic_reward -1.225
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.0125
wandb:       modelselection/selected_base_learner 3
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_161658-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_161803-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.45796921849250793, 'learning_rate': 1e-07, 'num_tokens': 2020.0, 'completions/mean_length': 339.0, 'completions/min_length': 201.0, 'completions/max_length': 474.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 339.0, 'completions/min_terminated_length': 201.0, 'completions/max_terminated_length': 474.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 1.9364917278289795, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.875, 'reward_std': 1.75, 'frac_reward_zero_std': 0.0, 'completion_length': 339.0, 'kl': 0.0005985359457554296, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 3.334452776471153e-05, 'learning_rate': 1e-07, 'num_tokens': 3320.0, 'completions/mean_length': 200.0, 'completions/min_length': 173.0, 'completions/max_length': 226.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 200.0, 'completions/min_terminated_length': 173.0, 'completions/max_terminated_length': 226.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 200.0, 'kl': 0.00026943552074953914, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.6765708327293396, 'learning_rate': 1e-07, 'num_tokens': 4520.0, 'completions/mean_length': 177.0, 'completions/min_length': 103.0, 'completions/max_length': 269.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 177.0, 'completions/min_terminated_length': 103.0, 'completions/max_terminated_length': 269.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 177.0, 'kl': 0.00041273875103797764, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.34397459030151367, 'learning_rate': 1e-07, 'num_tokens': 6395.0, 'completions/mean_length': 318.75, 'completions/min_length': 204.0, 'completions/max_length': 441.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 318.75, 'completions/min_terminated_length': 204.0, 'completions/max_terminated_length': 441.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.875, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 318.75, 'kl': 0.0004471647407626733, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3537712097167969, 'learning_rate': 1e-07, 'num_tokens': 8063.0, 'completions/mean_length': 261.0, 'completions/min_length': 236.0, 'completions/max_length': 331.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 261.0, 'completions/min_terminated_length': 236.0, 'completions/max_terminated_length': 331.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 261.0, 'kl': 0.00031308094185078517, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.6298362612724304, 'learning_rate': 1e-07, 'num_tokens': 9215.0, 'completions/mean_length': 160.0, 'completions/min_length': 131.0, 'completions/max_length': 203.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 160.0, 'completions/min_terminated_length': 131.0, 'completions/max_terminated_length': 203.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -1.0, 'reward_std': 2.1213202476501465, 'frac_reward_zero_std': 0.0, 'completion_length': 160.0, 'kl': 0.00030833289565634914, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.6782036423683167, 'learning_rate': 1e-07, 'num_tokens': 10485.0, 'completions/mean_length': 178.5, 'completions/min_length': 141.0, 'completions/max_length': 235.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 178.5, 'completions/min_terminated_length': 141.0, 'completions/max_terminated_length': 235.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 178.5, 'kl': 0.0004719388816738501, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.32695814967155457, 'learning_rate': 1e-07, 'num_tokens': 11900.0, 'completions/mean_length': 212.75, 'completions/min_length': 166.0, 'completions/max_length': 261.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 212.75, 'completions/min_terminated_length': 166.0, 'completions/max_terminated_length': 261.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -1.0, 'reward_std': 2.1213202476501465, 'frac_reward_zero_std': 0.0, 'completion_length': 212.75, 'kl': 0.0003143201938655693, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.6465033292770386, 'learning_rate': 1e-07, 'num_tokens': 13191.0, 'completions/mean_length': 191.75, 'completions/min_length': 130.0, 'completions/max_length': 288.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 191.75, 'completions/min_terminated_length': 130.0, 'completions/max_terminated_length': 288.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 191.75, 'kl': 0.0003211018774891272, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5349277853965759, 'learning_rate': 1e-07, 'num_tokens': 14409.0, 'completions/mean_length': 198.5, 'completions/min_length': 165.0, 'completions/max_length': 234.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 198.5, 'completions/min_terminated_length': 165.0, 'completions/max_terminated_length': 234.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 1.8874585628509521, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 198.5, 'kl': 0.0005669453748851083, 'epoch': 0.0}
{'train_runtime': 61.3819, 'train_samples_per_second': 0.652, 'train_steps_per_second': 0.163, 'train_loss': 4.039429342128642e-07, 'epoch': 0.0}
[EP 0014] 4 | reward_mean=-1.288 | 
*** stats:  {'episode_reward_mean': -1.2875, 'episode_reward_last': -1.375, 'episode_reward_std_mean': 1.2220869362354279, 'episode_reward_trajectory': [-1.875, -1.0, -0.625, -1.875, -2.5, -1.0, -1.375, -1.0, -0.25, -1.375], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.4875, 'rewards/match_format_approximately/mean/last': -1.375, 'rewards/match_format_approximately/std/mean': 1.0414720594882965, 'rewards/match_format_approximately/std/last': 1.8874585628509521, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.2, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.30980761647224425, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -1.2875
All rewards  -18.775
Cumulative rewards  [-10.275, 1.275, -2.4, -3.6375, -3.7375000000000003]
Num plays  [3, 3, 3, 3, 3]
Mean rewards  [-3.4250000000000003, 0.425, -0.7999999999999999, -1.2125000000000001, -1.2458333333333333]
Balancing probabilities  [0, 0, 0, 0, 1]
Mis-Specification Test [3, 3, 3, 3, 3]
potentials:  [13.85640646 13.85640646 13.85640646 13.85640646 13.85640646]
sampled base index:  0
potentials:  [13.85640646 13.85640646 13.85640646 13.85640646 13.85640646]
sampled base index:  0
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:52, 12.45s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:52, 12.45s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.37s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.37s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:37<01:26, 12.35s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:37<01:26, 12.35s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:14, 12.37s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:14, 12.37s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.36s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.36s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:14<00:49, 12.34s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:14<00:49, 12.34s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.32s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.32s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.34s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.34s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:51<00:12, 12.34s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:51<00:12, 12.34s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:03<00:00, 12.32s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:03<00:00, 12.32s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:05<00:00, 12.32s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:05<00:00, 12.53s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_4_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.8625
wandb:      modelselection/base_2_episodic_reward -0.5375
wandb:      modelselection/base_3_episodic_reward -1.0125
wandb:      modelselection/base_4_episodic_reward -1.2875
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.2875
wandb:       modelselection/selected_base_learner 4
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_161803-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_162013-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.007321519311517477, 'learning_rate': 0.001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.1775914654135704, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0015367543091997504, 'learning_rate': 0.001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.13428065925836563, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0017623613821342587, 'learning_rate': 0.001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.13092785887420177, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00212718709371984, 'learning_rate': 0.001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.10384352505207062, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0018155048601329327, 'learning_rate': 0.001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.11294739693403244, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0012458538403734565, 'learning_rate': 0.001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.10316060297191143, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0011380749056115746, 'learning_rate': 0.001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.10600261390209198, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0010874515864998102, 'learning_rate': 0.001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.10307024233043194, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0011709000682458282, 'learning_rate': 0.001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.09546117670834064, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0009626243845559657, 'learning_rate': 0.001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.09953569807112217, 'epoch': 0.0}
{'train_runtime': 125.3173, 'train_samples_per_second': 0.319, 'train_steps_per_second': 0.08, 'train_loss': 0.00011668212755466811, 'epoch': 0.0}
[EP 0015] 0 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  -22.775
Cumulative rewards  [-14.275, 1.275, -2.4, -3.6375, -3.7375000000000003]
Num plays  [4, 3, 3, 3, 3]
Mean rewards  [-3.56875, 0.425, -0.7999999999999999, -1.2125000000000001, -1.2458333333333333]
Balancing probabilities  [1, 0, 0, 0, 0]
Mis-Specification Test [4, 3, 3, 3, 3]
potentials:  [32.         13.85640646 13.85640646 13.85640646 13.85640646]
sampled base index:  1
potentials:  [32.         13.85640646 13.85640646 13.85640646 13.85640646]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:09<01:23,  9.27s/it]                                               10%|â–ˆ         | 1/10 [00:09<01:23,  9.27s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:16<01:02,  7.86s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:16<01:02,  7.86s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:52,  7.50s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:52,  7.50s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:31<00:45,  7.63s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:31<00:45,  7.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:40<00:41,  8.22s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:40<00:41,  8.22s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:50<00:35,  8.81s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:50<00:35,  8.81s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:57<00:24,  8.23s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:57<00:24,  8.23s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:08<00:18,  9.34s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:09<00:18,  9.34s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:18<00:09,  9.46s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:18<00:09,  9.46s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:25<00:00,  8.77s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:25<00:00,  8.77s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:27<00:00,  8.77s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:27<00:00,  8.77s/it]
wandb: updating run metadata
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_0_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.8625
wandb:      modelselection/base_2_episodic_reward -0.5375
wandb:      modelselection/base_3_episodic_reward -1.0125
wandb:      modelselection/base_4_episodic_reward -1.2875
wandb:               modelselection/learning_rate 0.001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 0
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_162013-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_162144-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.34291937947273254, 'learning_rate': 0.0001, 'num_tokens': 2435.0, 'completions/mean_length': 442.75, 'completions/min_length': 320.0, 'completions/max_length': 521.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 442.75, 'completions/min_terminated_length': 320.0, 'completions/max_terminated_length': 521.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 442.75, 'kl': 0.11061547696590424, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.371000736951828, 'learning_rate': 0.0001, 'num_tokens': 4291.0, 'completions/mean_length': 339.0, 'completions/min_length': 328.0, 'completions/max_length': 358.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 339.0, 'completions/min_terminated_length': 328.0, 'completions/max_terminated_length': 358.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 1.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 339.0, 'kl': 0.1761541087180376, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.3864418864250183, 'learning_rate': 0.0001, 'num_tokens': 5960.0, 'completions/mean_length': 294.25, 'completions/min_length': 251.0, 'completions/max_length': 371.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 294.25, 'completions/min_terminated_length': 251.0, 'completions/max_terminated_length': 371.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 2.1213202476501465, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 0.125, 'reward_std': 2.839454174041748, 'frac_reward_zero_std': 0.0, 'completion_length': 294.25, 'kl': 0.2098611705005169, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.24721376597881317, 'learning_rate': 0.0001, 'num_tokens': 8221.0, 'completions/mean_length': 415.25, 'completions/min_length': 403.0, 'completions/max_length': 424.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 415.25, 'completions/min_terminated_length': 403.0, 'completions/max_terminated_length': 424.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': 0.125, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 415.25, 'kl': 0.10556396655738354, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.24470122158527374, 'learning_rate': 0.0001, 'num_tokens': 10530.0, 'completions/mean_length': 421.25, 'completions/min_length': 357.0, 'completions/max_length': 521.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 421.25, 'completions/min_terminated_length': 357.0, 'completions/max_terminated_length': 521.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 0.75, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 421.25, 'kl': 0.13795466348528862, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.32002702355384827, 'learning_rate': 0.0001, 'num_tokens': 12203.0, 'completions/mean_length': 290.25, 'completions/min_length': 194.0, 'completions/max_length': 565.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 290.25, 'completions/min_terminated_length': 194.0, 'completions/max_terminated_length': 565.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 290.25, 'kl': 0.17758722230792046, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.3957769572734833, 'learning_rate': 0.0001, 'num_tokens': 13951.0, 'completions/mean_length': 298.0, 'completions/min_length': 248.0, 'completions/max_length': 368.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 298.0, 'completions/min_terminated_length': 248.0, 'completions/max_terminated_length': 368.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 298.0, 'kl': 0.13678126968443394, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.3367975652217865, 'learning_rate': 0.0001, 'num_tokens': 16086.0, 'completions/mean_length': 392.75, 'completions/min_length': 245.0, 'completions/max_length': 690.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 392.75, 'completions/min_terminated_length': 245.0, 'completions/max_terminated_length': 690.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': 0.125, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 392.75, 'kl': 0.0918952077627182, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.2511085867881775, 'learning_rate': 0.0001, 'num_tokens': 18199.0, 'completions/mean_length': 397.25, 'completions/min_length': 261.0, 'completions/max_length': 562.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 397.25, 'completions/min_terminated_length': 261.0, 'completions/max_terminated_length': 562.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 397.25, 'kl': 0.10000169556587934, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.40376192331314087, 'learning_rate': 0.0001, 'num_tokens': 19708.0, 'completions/mean_length': 271.25, 'completions/min_length': 185.0, 'completions/max_length': 387.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 271.25, 'completions/min_terminated_length': 185.0, 'completions/max_terminated_length': 387.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 271.25, 'kl': 0.1654436308890581, 'epoch': 0.0}
{'train_runtime': 87.6871, 'train_samples_per_second': 0.456, 'train_steps_per_second': 0.114, 'train_loss': 0.0001411832869052887, 'epoch': 0.0}
[EP 0016] 1 | reward_mean=0.588 | 
*** stats:  {'episode_reward_mean': 0.5875, 'episode_reward_last': 1.0, 'episode_reward_std_mean': 1.1905040264129638, 'episode_reward_trajectory': [-1.5, 1.625, 0.125, 0.125, 0.75, 1.625, 0.5, 0.125, 1.5, 1.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.0125, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.5923486292362213, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.575, 'rewards/check_numbers/mean/last': 0.5, 'rewards/check_numbers/std/mean': 0.6935476899147034, 'rewards/check_numbers/std/last': 1.154700517654419}
Curr reward  0.5875
All rewards  -22.1875
Cumulative rewards  [-14.275, 1.8624999999999998, -2.4, -3.6375, -3.7375000000000003]
Num plays  [4, 4, 3, 3, 3]
Mean rewards  [-3.56875, 0.46562499999999996, -0.7999999999999999, -1.2125000000000001, -1.2458333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [4, 4, 3, 3, 3]
potentials:  [32.         32.         13.85640646 13.85640646 13.85640646]
sampled base index:  2
potentials:  [32.         32.         13.85640646 13.85640646 13.85640646]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:06<00:58,  6.47s/it]                                               10%|â–ˆ         | 1/10 [00:06<00:58,  6.47s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:11<00:44,  5.62s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:11<00:44,  5.62s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:46,  6.66s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:46,  6.66s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:36,  6.11s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:36,  6.11s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:32,  6.54s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:32,  6.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:37<00:25,  6.31s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:37<00:25,  6.31s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:42<00:17,  5.87s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:42<00:17,  5.87s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:47<00:11,  5.59s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:47<00:11,  5.59s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:57<00:06,  6.86s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:57<00:06,  6.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  6.59s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  6.59s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:05<00:00,  6.59s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:05<00:00,  6.53s/it]
wandb: updating run metadata
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.5875
wandb:      modelselection/base_2_episodic_reward -0.5375
wandb:      modelselection/base_3_episodic_reward -1.0125
wandb:      modelselection/base_4_episodic_reward -1.2875
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 0.5875
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_162144-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_162253-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.39213019609451294, 'learning_rate': 1e-05, 'num_tokens': 1821.0, 'completions/mean_length': 289.25, 'completions/min_length': 241.0, 'completions/max_length': 327.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 289.25, 'completions/min_terminated_length': 241.0, 'completions/max_terminated_length': 327.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.7320507764816284, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 1.6007810831069946, 'frac_reward_zero_std': 0.0, 'completion_length': 289.25, 'kl': 0.0014210483932401985, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.40683919191360474, 'learning_rate': 1e-05, 'num_tokens': 3053.0, 'completions/mean_length': 183.0, 'completions/min_length': 153.0, 'completions/max_length': 228.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 183.0, 'completions/min_terminated_length': 153.0, 'completions/max_terminated_length': 228.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.25, 'reward_std': 1.9364917278289795, 'frac_reward_zero_std': 0.0, 'completion_length': 183.0, 'kl': 0.23589577694656327, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.48054662346839905, 'learning_rate': 1e-05, 'num_tokens': 4643.0, 'completions/mean_length': 274.5, 'completions/min_length': 127.0, 'completions/max_length': 433.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 274.5, 'completions/min_terminated_length': 127.0, 'completions/max_terminated_length': 433.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 274.5, 'kl': 0.00658225454390049, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.6582925319671631, 'learning_rate': 1e-05, 'num_tokens': 6095.0, 'completions/mean_length': 213.0, 'completions/min_length': 154.0, 'completions/max_length': 246.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 213.0, 'completions/min_terminated_length': 154.0, 'completions/max_terminated_length': 246.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': -1.375, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 213.0, 'kl': 0.031811546126846224, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.2619372308254242, 'learning_rate': 1e-05, 'num_tokens': 7980.0, 'completions/mean_length': 315.25, 'completions/min_length': 240.0, 'completions/max_length': 388.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 315.25, 'completions/min_terminated_length': 240.0, 'completions/max_terminated_length': 388.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -1.125, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 315.25, 'kl': 0.0038379776669899, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3092944025993347, 'learning_rate': 1e-05, 'num_tokens': 9318.0, 'completions/mean_length': 206.5, 'completions/min_length': 150.0, 'completions/max_length': 285.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 206.5, 'completions/min_terminated_length': 150.0, 'completions/max_terminated_length': 285.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 1.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 206.5, 'kl': 0.003378801397047937, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5207639932632446, 'learning_rate': 1e-05, 'num_tokens': 10617.0, 'completions/mean_length': 185.75, 'completions/min_length': 164.0, 'completions/max_length': 224.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 185.75, 'completions/min_terminated_length': 164.0, 'completions/max_terminated_length': 224.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.75, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 185.75, 'kl': 0.005216965626459569, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3061201572418213, 'learning_rate': 1e-05, 'num_tokens': 11976.0, 'completions/mean_length': 198.75, 'completions/min_length': 172.0, 'completions/max_length': 228.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 198.75, 'completions/min_terminated_length': 172.0, 'completions/max_terminated_length': 228.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 0.875, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 198.75, 'kl': 0.009852357092313468, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4769245386123657, 'learning_rate': 1e-05, 'num_tokens': 13598.0, 'completions/mean_length': 274.5, 'completions/min_length': 147.0, 'completions/max_length': 547.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 274.5, 'completions/min_terminated_length': 147.0, 'completions/max_terminated_length': 547.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 0.25, 'reward_std': 2.020725965499878, 'frac_reward_zero_std': 0.0, 'completion_length': 274.5, 'kl': 0.017340535443508998, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3771040141582489, 'learning_rate': 1e-05, 'num_tokens': 14838.0, 'completions/mean_length': 204.0, 'completions/min_length': 116.0, 'completions/max_length': 299.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 204.0, 'completions/min_terminated_length': 116.0, 'completions/max_terminated_length': 299.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 204.0, 'kl': 0.00286604993743822, 'epoch': 0.0}
{'train_runtime': 65.2826, 'train_samples_per_second': 0.613, 'train_steps_per_second': 0.153, 'train_loss': 3.1822174787521365e-05, 'epoch': 0.0}
[EP 0017] 2 | reward_mean=-0.400 | 
*** stats:  {'episode_reward_mean': -0.4, 'episode_reward_last': -1.125, 'episode_reward_std_mean': 1.2640941202640534, 'episode_reward_trajectory': [-1.125, -0.25, -0.625, -1.375, -1.125, 1.25, -0.75, 0.875, 0.25, -1.125], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -0.8125, 'rewards/match_format_approximately/mean/last': -1.0, 'rewards/match_format_approximately/std/mean': 0.8754361689090728, 'rewards/match_format_approximately/std/last': 1.2247449159622192, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.4125, 'rewards/check_numbers/mean/last': -0.125, 'rewards/check_numbers/std/mean': 0.6002776682376861, 'rewards/check_numbers/std/last': 0.25}
Curr reward  -0.4
All rewards  -22.5875
Cumulative rewards  [-14.275, 1.8624999999999998, -2.8, -3.6375, -3.7375000000000003]
Num plays  [4, 4, 4, 3, 3]
Mean rewards  [-3.56875, 0.46562499999999996, -0.7, -1.2125000000000001, -1.2458333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [4, 4, 4, 3, 3]
potentials:  [32.         32.         32.         13.85640646 13.85640646]
sampled base index:  3
potentials:  [32.         32.         32.         13.85640646 13.85640646]
sampled base index:  3
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:06<00:59,  6.58s/it]                                               10%|â–ˆ         | 1/10 [00:06<00:59,  6.58s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:15<01:04,  8.09s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:15<01:04,  8.09s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:50,  7.16s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:50,  7.16s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:28<00:40,  6.80s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:28<00:40,  6.80s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:36<00:36,  7.26s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:36<00:36,  7.26s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:41<00:27,  6.76s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:41<00:27,  6.76s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:54<00:25,  8.63s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:54<00:25,  8.63s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:00<00:15,  7.71s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:00<00:15,  7.71s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:05<00:07,  7.02s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:05<00:07,  7.02s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:13<00:00,  7.37s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:13<00:00,  7.37s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:15<00:00,  7.37s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:15<00:00,  7.58s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.5875
wandb:      modelselection/base_2_episodic_reward -0.4
wandb:      modelselection/base_3_episodic_reward -1.0125
wandb:      modelselection/base_4_episodic_reward -1.2875
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward -0.4
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_162253-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_162413-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.542866587638855, 'learning_rate': 1e-06, 'num_tokens': 1666.0, 'completions/mean_length': 250.5, 'completions/min_length': 190.0, 'completions/max_length': 336.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 222.0, 'completions/min_terminated_length': 190.0, 'completions/max_terminated_length': 269.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 250.5, 'kl': 0.0008066496957326308, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.36967378854751587, 'learning_rate': 1e-06, 'num_tokens': 3382.0, 'completions/mean_length': 304.0, 'completions/min_length': 189.0, 'completions/max_length': 515.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 304.0, 'completions/min_terminated_length': 189.0, 'completions/max_terminated_length': 515.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 304.0, 'kl': 0.0004007125462521799, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3326151371002197, 'learning_rate': 1e-06, 'num_tokens': 4767.0, 'completions/mean_length': 223.25, 'completions/min_length': 188.0, 'completions/max_length': 300.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 223.25, 'completions/min_terminated_length': 188.0, 'completions/max_terminated_length': 300.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 223.25, 'kl': 0.00036480844210018404, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.37716740369796753, 'learning_rate': 1e-06, 'num_tokens': 6359.0, 'completions/mean_length': 248.0, 'completions/min_length': 190.0, 'completions/max_length': 312.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 248.0, 'completions/min_terminated_length': 190.0, 'completions/max_terminated_length': 312.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 0.0, 'reward_std': 0.7071067690849304, 'frac_reward_zero_std': 0.0, 'completion_length': 248.0, 'kl': 0.0003022460005013272, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.41453197598457336, 'learning_rate': 1e-06, 'num_tokens': 8128.0, 'completions/mean_length': 286.25, 'completions/min_length': 188.0, 'completions/max_length': 437.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 286.25, 'completions/min_terminated_length': 188.0, 'completions/max_terminated_length': 437.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.5, 'reward_std': 0.7071067690849304, 'frac_reward_zero_std': 0.0, 'completion_length': 286.25, 'kl': 0.0004374022319098003, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.8176881670951843, 'learning_rate': 1e-06, 'num_tokens': 9422.0, 'completions/mean_length': 195.5, 'completions/min_length': 118.0, 'completions/max_length': 282.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 195.5, 'completions/min_terminated_length': 118.0, 'completions/max_terminated_length': 282.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 195.5, 'kl': 0.0005954548869340215, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4304942488670349, 'learning_rate': 1e-06, 'num_tokens': 11161.0, 'completions/mean_length': 295.75, 'completions/min_length': 140.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 149.0, 'completions/min_terminated_length': 140.0, 'completions/max_terminated_length': 155.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 295.75, 'kl': 0.0004518127752817236, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.32965096831321716, 'learning_rate': 1e-06, 'num_tokens': 12634.0, 'completions/mean_length': 227.25, 'completions/min_length': 153.0, 'completions/max_length': 276.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 227.25, 'completions/min_terminated_length': 153.0, 'completions/max_terminated_length': 276.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 227.25, 'kl': 0.0002832745940395398, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3887875974178314, 'learning_rate': 1e-06, 'num_tokens': 13973.0, 'completions/mean_length': 203.75, 'completions/min_length': 139.0, 'completions/max_length': 264.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 203.75, 'completions/min_terminated_length': 139.0, 'completions/max_terminated_length': 264.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 203.75, 'kl': 0.0003890985535690561, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.503811776638031, 'learning_rate': 1e-06, 'num_tokens': 15458.0, 'completions/mean_length': 265.25, 'completions/min_length': 121.0, 'completions/max_length': 444.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 265.25, 'completions/min_terminated_length': 121.0, 'completions/max_terminated_length': 444.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': -0.875, 'reward_std': 1.973786473274231, 'frac_reward_zero_std': 0.0, 'completion_length': 265.25, 'kl': 0.0004737307463074103, 'epoch': 0.0}
{'train_runtime': 75.8256, 'train_samples_per_second': 0.528, 'train_steps_per_second': 0.132, 'train_loss': 4.559755325317383e-07, 'epoch': 0.0}
[EP 0018] 3 | reward_mean=-1.175 | 
*** stats:  {'episode_reward_mean': -1.175, 'episode_reward_last': -0.875, 'episode_reward_std_mean': 0.9819540619850159, 'episode_reward_trajectory': [-2.5, -2.5, -0.75, 0.0, -1.5, -0.625, -0.25, -0.625, -2.125, -0.875], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.3375, 'rewards/match_format_approximately/mean/last': -1.0, 'rewards/match_format_approximately/std/mean': 0.7424234747886658, 'rewards/match_format_approximately/std/last': 1.2247449159622192, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.1625, 'rewards/check_numbers/mean/last': 0.125, 'rewards/check_numbers/std/mean': 0.40932865142822267, 'rewards/check_numbers/std/last': 0.9464847445487976}
Curr reward  -1.175
All rewards  -23.7625
Cumulative rewards  [-14.275, 1.8624999999999998, -2.8, -4.8125, -3.7375000000000003]
Num plays  [4, 4, 4, 4, 3]
Mean rewards  [-3.56875, 0.46562499999999996, -0.7, -1.203125, -1.2458333333333333]
Balancing probabilities  [0, 0, 0, 1, 0]
Mis-Specification Test [4, 4, 4, 4, 3]
potentials:  [32.         32.         32.         32.         13.85640646]
sampled base index:  4
potentials:  [32.         32.         32.         32.         13.85640646]
sampled base index:  4
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.41s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.41s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:19<01:16,  9.52s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:19<01:16,  9.52s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:26<00:57,  8.20s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:26<00:57,  8.20s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:34<00:47,  7.91s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:34<00:47,  7.91s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:45<00:46,  9.33s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:45<00:46,  9.33s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:50<00:30,  7.63s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:50<00:30,  7.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:54<00:19,  6.38s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:54<00:19,  6.38s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:00<00:12,  6.28s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:00<00:12,  6.28s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:06<00:06,  6.36s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:06<00:06,  6.36s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:19<00:00,  8.23s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:19<00:00,  8.23s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:20<00:00,  8.23s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:20<00:00,  8.07s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_3_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.5875
wandb:      modelselection/base_2_episodic_reward -0.4
wandb:      modelselection/base_3_episodic_reward -1.175
wandb:      modelselection/base_4_episodic_reward -1.2875
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.175
wandb:       modelselection/selected_base_learner 3
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_162413-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_162538-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.40964001417160034, 'learning_rate': 1e-07, 'num_tokens': 2274.0, 'completions/mean_length': 402.5, 'completions/min_length': 199.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 291.3333435058594, 'completions/min_terminated_length': 199.0, 'completions/max_terminated_length': 395.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.875, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.875, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 402.5, 'kl': 0.0006656996229139622, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00010459785698913038, 'learning_rate': 1e-07, 'num_tokens': 3731.0, 'completions/mean_length': 239.25, 'completions/min_length': 142.0, 'completions/max_length': 403.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 239.25, 'completions/min_terminated_length': 142.0, 'completions/max_terminated_length': 403.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 239.25, 'kl': 0.0004088021523784846, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3258827328681946, 'learning_rate': 1e-07, 'num_tokens': 5191.0, 'completions/mean_length': 242.0, 'completions/min_length': 173.0, 'completions/max_length': 340.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 242.0, 'completions/min_terminated_length': 173.0, 'completions/max_terminated_length': 340.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.5, 'reward_std': 0.7071067690849304, 'frac_reward_zero_std': 0.0, 'completion_length': 242.0, 'kl': 0.0003377059729245957, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3738418519496918, 'learning_rate': 1e-07, 'num_tokens': 7033.0, 'completions/mean_length': 310.5, 'completions/min_length': 184.0, 'completions/max_length': 400.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 310.5, 'completions/min_terminated_length': 184.0, 'completions/max_terminated_length': 400.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 310.5, 'kl': 0.00048677420272724703, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.2732197642326355, 'learning_rate': 1e-07, 'num_tokens': 9213.0, 'completions/mean_length': 389.0, 'completions/min_length': 276.0, 'completions/max_length': 696.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 389.0, 'completions/min_terminated_length': 276.0, 'completions/max_terminated_length': 696.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.875, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 389.0, 'kl': 0.00032477084823767655, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 3.258844299125485e-05, 'learning_rate': 1e-07, 'num_tokens': 10350.0, 'completions/mean_length': 156.25, 'completions/min_length': 126.0, 'completions/max_length': 185.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 156.25, 'completions/min_terminated_length': 126.0, 'completions/max_terminated_length': 185.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 156.25, 'kl': 0.0003275750350439921, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5903196334838867, 'learning_rate': 1e-07, 'num_tokens': 11461.0, 'completions/mean_length': 138.75, 'completions/min_length': 131.0, 'completions/max_length': 147.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 138.75, 'completions/min_terminated_length': 131.0, 'completions/max_terminated_length': 147.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 138.75, 'kl': 0.0004856349842157215, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.34620344638824463, 'learning_rate': 1e-07, 'num_tokens': 12931.0, 'completions/mean_length': 226.5, 'completions/min_length': 188.0, 'completions/max_length': 301.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 226.5, 'completions/min_terminated_length': 188.0, 'completions/max_terminated_length': 301.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -0.875, 'reward_std': 1.3768926858901978, 'frac_reward_zero_std': 0.0, 'completion_length': 226.5, 'kl': 0.00028868599110865034, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3143860995769501, 'learning_rate': 1e-07, 'num_tokens': 14635.0, 'completions/mean_length': 295.0, 'completions/min_length': 250.0, 'completions/max_length': 336.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 295.0, 'completions/min_terminated_length': 250.0, 'completions/max_terminated_length': 336.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -2.625, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 295.0, 'kl': 0.00048761838115751743, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3893123269081116, 'learning_rate': 1e-07, 'num_tokens': 16294.0, 'completions/mean_length': 308.75, 'completions/min_length': 145.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 166.33334350585938, 'completions/min_terminated_length': 145.0, 'completions/max_terminated_length': 199.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 308.75, 'kl': 0.00047816114965826273, 'epoch': 0.0}
{'train_runtime': 80.7112, 'train_samples_per_second': 0.496, 'train_steps_per_second': 0.124, 'train_loss': 4.336870262022785e-07, 'epoch': 0.0}
[EP 0019] 4 | reward_mean=-1.475 | 
*** stats:  {'episode_reward_mean': -1.475, 'episode_reward_last': -1.375, 'episode_reward_std_mean': 0.766694188117981, 'episode_reward_trajectory': [-2.875, -1.0, -1.5, -1.375, -1.875, -1.0, -0.25, -0.875, -2.625, -1.375], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.4875, 'rewards/match_format_approximately/mean/last': -1.375, 'rewards/match_format_approximately/std/mean': 0.7160885572433472, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0125, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.1904700517654419, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -1.475
All rewards  -25.2375
Cumulative rewards  [-14.275, 1.8624999999999998, -2.8, -4.8125, -5.2125]
Num plays  [4, 4, 4, 4, 4]
Mean rewards  [-3.56875, 0.46562499999999996, -0.7, -1.203125, -1.303125]
Balancing probabilities  [0, 0, 0, 0, 1]
Mis-Specification Test [4, 4, 4, 4, 4]
potentials:  [32. 32. 32. 32. 32.]
sampled base index:  0
potentials:  [32. 32. 32. 32. 32.]
sampled base index:  0
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.38s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.38s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.32s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.32s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:26, 12.30s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:26, 12.30s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.31s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.31s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.33s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.33s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.32s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.32s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.32s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.32s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.32s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.32s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.31s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.31s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:03<00:00, 12.31s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:03<00:00, 12.31s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.31s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.49s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_4_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.5875
wandb:      modelselection/base_2_episodic_reward -0.4
wandb:      modelselection/base_3_episodic_reward -1.175
wandb:      modelselection/base_4_episodic_reward -1.475
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.475
wandb:       modelselection/selected_base_learner 4
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_162538-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_162747-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.001211627502925694, 'learning_rate': 0.001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.08062171004712582, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.01197634544223547, 'learning_rate': 0.001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.10741272754967213, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0006795219960622489, 'learning_rate': 0.001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.08040183596313, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00047635810915380716, 'learning_rate': 0.001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.0606705117970705, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0003443486348260194, 'learning_rate': 0.001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.061559949070215225, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0004341339226812124, 'learning_rate': 0.001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.0551820769906044, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0003480358573142439, 'learning_rate': 0.001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.06261678133159876, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00027193748974241316, 'learning_rate': 0.001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.060055412352085114, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00035231991205364466, 'learning_rate': 0.001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.060317558236420155, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0003133798891212791, 'learning_rate': 0.001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.05770086124539375, 'epoch': 0.0}
{'train_runtime': 124.9224, 'train_samples_per_second': 0.32, 'train_steps_per_second': 0.08, 'train_loss': 6.865394716442097e-05, 'epoch': 0.0}
[EP 0020] 0 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  -29.2375
Cumulative rewards  [-18.275, 1.8624999999999998, -2.8, -4.8125, -5.2125]
Num plays  [5, 4, 4, 4, 4]
Mean rewards  [-3.655, 0.46562499999999996, -0.7, -1.203125, -1.303125]
Balancing probabilities  [1, 0, 0, 0, 0]
Mis-Specification Test [5, 4, 4, 4, 4]
potentials:  [71.55417528 32.         32.         32.         32.        ]
sampled base index:  1
potentials:  [71.55417528 32.         32.         32.         32.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.34s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.34s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:20<01:18,  9.82s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:20<01:18,  9.82s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:26<00:56,  8.14s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:26<00:56,  8.14s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:36<00:54,  9.04s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:36<00:54,  9.04s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:45<00:45,  9.01s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:45<00:45,  9.01s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:50<00:30,  7.56s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:50<00:30,  7.56s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:55<00:20,  6.72s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:55<00:20,  6.72s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:03<00:13,  7.00s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:03<00:13,  7.00s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:07<00:06,  6.22s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:07<00:06,  6.22s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:11<00:00,  5.56s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:11<00:00,  5.56s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:13<00:00,  5.56s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:13<00:00,  7.35s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_0_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.5875
wandb:      modelselection/base_2_episodic_reward -0.4
wandb:      modelselection/base_3_episodic_reward -1.175
wandb:      modelselection/base_4_episodic_reward -1.475
wandb:               modelselection/learning_rate 0.001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 0
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_162747-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_162904-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.37539568543434143, 'learning_rate': 0.0001, 'num_tokens': 2510.0, 'completions/mean_length': 461.5, 'completions/min_length': 261.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 370.0, 'completions/min_terminated_length': 261.0, 'completions/max_terminated_length': 508.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.375, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 461.5, 'kl': 0.10483652073889971, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.4268847107887268, 'learning_rate': 0.0001, 'num_tokens': 4130.0, 'completions/mean_length': 280.0, 'completions/min_length': 200.0, 'completions/max_length': 439.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 280.0, 'completions/min_terminated_length': 200.0, 'completions/max_terminated_length': 439.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': 1.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 1.2247449159622192, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 3.75, 'reward_std': 3.5, 'frac_reward_zero_std': 0.0, 'completion_length': 280.0, 'kl': 0.20830638334155083, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.369332879781723, 'learning_rate': 0.0001, 'num_tokens': 5737.0, 'completions/mean_length': 278.75, 'completions/min_length': 260.0, 'completions/max_length': 308.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 278.75, 'completions/min_terminated_length': 260.0, 'completions/max_terminated_length': 308.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 1.7320507764816284, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 5.375, 'reward_std': 4.802343368530273, 'frac_reward_zero_std': 0.0, 'completion_length': 278.75, 'kl': 0.2014491967856884, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.2632651925086975, 'learning_rate': 0.0001, 'num_tokens': 7943.0, 'completions/mean_length': 401.5, 'completions/min_length': 255.0, 'completions/max_length': 602.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 401.5, 'completions/min_terminated_length': 255.0, 'completions/max_terminated_length': 602.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.875, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 401.5, 'kl': 0.1303213145583868, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0048322174698114395, 'learning_rate': 0.0001, 'num_tokens': 10005.0, 'completions/mean_length': 359.5, 'completions/min_length': 252.0, 'completions/max_length': 501.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 359.5, 'completions/min_terminated_length': 252.0, 'completions/max_terminated_length': 501.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 359.5, 'kl': 0.18140702415257692, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.36273255944252014, 'learning_rate': 0.0001, 'num_tokens': 11291.0, 'completions/mean_length': 193.5, 'completions/min_length': 167.0, 'completions/max_length': 211.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 193.5, 'completions/min_terminated_length': 167.0, 'completions/max_terminated_length': 211.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 6.125, 'reward_std': 2.25, 'frac_reward_zero_std': 0.0, 'completion_length': 193.5, 'kl': 0.19716934487223625, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0010289254132658243, 'learning_rate': 0.0001, 'num_tokens': 12559.0, 'completions/mean_length': 178.0, 'completions/min_length': 89.0, 'completions/max_length': 227.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 178.0, 'completions/min_terminated_length': 89.0, 'completions/max_terminated_length': 227.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 178.0, 'kl': 0.17206093110144138, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.3487122356891632, 'learning_rate': 0.0001, 'num_tokens': 14332.0, 'completions/mean_length': 302.25, 'completions/min_length': 172.0, 'completions/max_length': 408.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 302.25, 'completions/min_terminated_length': 172.0, 'completions/max_terminated_length': 408.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 4.625, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 302.25, 'kl': 0.19460897892713547, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006097297300584614, 'learning_rate': 0.0001, 'num_tokens': 15608.0, 'completions/mean_length': 188.0, 'completions/min_length': 180.0, 'completions/max_length': 196.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 188.0, 'completions/min_terminated_length': 180.0, 'completions/max_terminated_length': 196.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 188.0, 'kl': 0.15874681621789932, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.004047776572406292, 'learning_rate': 0.0001, 'num_tokens': 16645.0, 'completions/mean_length': 153.25, 'completions/min_length': 134.0, 'completions/max_length': 165.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 153.25, 'completions/min_terminated_length': 134.0, 'completions/max_terminated_length': 165.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 153.25, 'kl': 0.24928086251020432, 'epoch': 0.0}
{'train_runtime': 73.5256, 'train_samples_per_second': 0.544, 'train_steps_per_second': 0.136, 'train_loss': 0.00017982290592044592, 'epoch': 0.0}
[EP 0021] 1 | reward_mean=6.537 | 
*** stats:  {'episode_reward_mean': 6.5375, 'episode_reward_last': 9.5, 'episode_reward_std_mean': 1.8939801931381226, 'episode_reward_trajectory': [-0.375, 3.75, 5.375, 7.875, 9.5, 6.125, 9.5, 4.625, 9.5, 9.5], 'rewards/match_format_exactly/mean/mean': 2.4, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.3464101552963257, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.55, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.37383067011833193, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 1.4625, 'rewards/check_answer/mean/last': 3.0, 'rewards/check_answer/std/mean': 0.9706795692443848, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.125, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.3866025388240814, 'rewards/check_numbers/std/last': 0.0}
Curr reward  6.5375
All rewards  -22.700000000000003
Cumulative rewards  [-18.275, 8.399999999999999, -2.8, -4.8125, -5.2125]
Num plays  [5, 5, 4, 4, 4]
Mean rewards  [-3.655, 1.6799999999999997, -0.7, -1.203125, -1.303125]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 4, 4, 4]
potentials:  [71.55417528 35.77708764 32.         32.         32.        ]
sampled base index:  2
potentials:  [71.55417528 35.77708764 32.         32.         32.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.35s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.35s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:17<01:07,  8.38s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:17<01:07,  8.38s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:48,  7.00s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:48,  7.00s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:30<00:43,  7.21s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:30<00:43,  7.21s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:36<00:34,  6.81s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:36<00:34,  6.81s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:25,  6.27s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:25,  6.27s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:49<00:19,  6.50s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:49<00:19,  6.50s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:55<00:12,  6.41s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:55<00:12,  6.41s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:01<00:06,  6.21s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:01<00:06,  6.21s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:08<00:00,  6.71s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:08<00:00,  6.71s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:10<00:00,  6.71s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:10<00:00,  7.07s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 6.5375
wandb:      modelselection/base_2_episodic_reward -0.4
wandb:      modelselection/base_3_episodic_reward -1.175
wandb:      modelselection/base_4_episodic_reward -1.475
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 6.5375
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_162904-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_163018-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.42019808292388916, 'learning_rate': 1e-05, 'num_tokens': 2342.0, 'completions/mean_length': 419.5, 'completions/min_length': 239.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 314.0, 'completions/min_terminated_length': 239.0, 'completions/max_terminated_length': 434.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': -1.125, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 419.5, 'kl': 0.005133562837727368, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.6064987182617188, 'learning_rate': 1e-05, 'num_tokens': 3559.0, 'completions/mean_length': 179.25, 'completions/min_length': 118.0, 'completions/max_length': 269.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 179.25, 'completions/min_terminated_length': 118.0, 'completions/max_terminated_length': 269.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 0.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 179.25, 'kl': 0.00911385368090123, 'epoch': 0.0}
{'loss': 0.0017, 'grad_norm': 0.5025644898414612, 'learning_rate': 1e-05, 'num_tokens': 4897.0, 'completions/mean_length': 211.5, 'completions/min_length': 165.0, 'completions/max_length': 252.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 211.5, 'completions/min_terminated_length': 165.0, 'completions/max_terminated_length': 252.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 211.5, 'kl': 1.69255551090464, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3428734838962555, 'learning_rate': 1e-05, 'num_tokens': 6711.0, 'completions/mean_length': 303.5, 'completions/min_length': 216.0, 'completions/max_length': 404.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 303.5, 'completions/min_terminated_length': 216.0, 'completions/max_terminated_length': 404.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.75, 'reward_std': 0.5, 'frac_reward_zero_std': 0.0, 'completion_length': 303.5, 'kl': 0.0064276683551725, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.27851954102516174, 'learning_rate': 1e-05, 'num_tokens': 8392.0, 'completions/mean_length': 264.25, 'completions/min_length': 224.0, 'completions/max_length': 303.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 264.25, 'completions/min_terminated_length': 224.0, 'completions/max_terminated_length': 303.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 264.25, 'kl': 0.0050783929182216525, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.374078631401062, 'learning_rate': 1e-05, 'num_tokens': 9635.0, 'completions/mean_length': 182.75, 'completions/min_length': 148.0, 'completions/max_length': 242.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 182.75, 'completions/min_terminated_length': 148.0, 'completions/max_terminated_length': 242.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 1.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 182.75, 'kl': 0.009438697015866637, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5175794363021851, 'learning_rate': 1e-05, 'num_tokens': 11037.0, 'completions/mean_length': 211.5, 'completions/min_length': 124.0, 'completions/max_length': 364.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 211.5, 'completions/min_terminated_length': 124.0, 'completions/max_terminated_length': 364.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': 0.375, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 211.5, 'kl': 0.017665400402620435, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4459034502506256, 'learning_rate': 1e-05, 'num_tokens': 12376.0, 'completions/mean_length': 193.75, 'completions/min_length': 133.0, 'completions/max_length': 308.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 193.75, 'completions/min_terminated_length': 133.0, 'completions/max_terminated_length': 308.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 0.375, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 193.75, 'kl': 0.01874154433608055, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.44041427969932556, 'learning_rate': 1e-05, 'num_tokens': 13707.0, 'completions/mean_length': 201.75, 'completions/min_length': 169.0, 'completions/max_length': 279.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 201.75, 'completions/min_terminated_length': 169.0, 'completions/max_terminated_length': 279.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.7320507764816284, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.75, 'reward_std': 2.1794495582580566, 'frac_reward_zero_std': 0.0, 'completion_length': 201.75, 'kl': 0.009858613717369735, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.43486931920051575, 'learning_rate': 1e-05, 'num_tokens': 15152.0, 'completions/mean_length': 255.25, 'completions/min_length': 136.0, 'completions/max_length': 425.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 255.25, 'completions/min_terminated_length': 136.0, 'completions/max_terminated_length': 425.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.125, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 255.25, 'kl': 0.020600819494575262, 'epoch': 0.0}
{'train_runtime': 70.7127, 'train_samples_per_second': 0.566, 'train_steps_per_second': 0.141, 'train_loss': 0.00017946102161658928, 'epoch': 0.0}
[EP 0022] 2 | reward_mean=0.025 | 
*** stats:  {'episode_reward_mean': 0.025, 'episode_reward_last': 0.125, 'episode_reward_std_mean': 1.0477086424827575, 'episode_reward_trajectory': [-1.125, 0.5, -0.75, -0.75, 1.0, 1.25, 0.375, 0.375, -0.75, 0.125], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -0.2875, 'rewards/match_format_approximately/mean/last': 0.125, 'rewards/match_format_approximately/std/mean': 0.7214101552963257, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.3125, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.5551502287387848, 'rewards/check_numbers/std/last': 1.0}
Curr reward  0.025
All rewards  -22.675000000000004
Cumulative rewards  [-18.275, 8.399999999999999, -2.775, -4.8125, -5.2125]
Num plays  [5, 5, 5, 4, 4]
Mean rewards  [-3.655, 1.6799999999999997, -0.5549999999999999, -1.203125, -1.303125]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [5, 4, 5, 4, 4]
potentials:  [71.55417528 35.77708764 71.55417528 32.         32.        ]
sampled base index:  3
potentials:  [71.55417528 35.77708764 71.55417528 32.         32.        ]
sampled base index:  3
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:52, 12.45s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:52, 12.45s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:19<01:16,  9.51s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:19<01:16,  9.51s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:25<00:52,  7.53s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:25<00:52,  7.53s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:32<00:46,  7.67s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:33<00:46,  7.67s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:40<00:37,  7.57s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:40<00:37,  7.57s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:44<00:26,  6.54s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:44<00:26,  6.54s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:51<00:19,  6.41s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:51<00:19,  6.41s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:56<00:12,  6.21s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:56<00:12,  6.21s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:02<00:06,  6.19s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:02<00:06,  6.19s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:10<00:00,  6.76s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:11<00:00,  6.76s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:13<00:00,  6.76s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:13<00:00,  7.30s/it]
wandb: updating run metadata
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 6.5375
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -1.175
wandb:      modelselection/base_4_episodic_reward -1.475
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 0.025
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_163018-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_163135-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.3496019244194031, 'learning_rate': 1e-06, 'num_tokens': 2387.0, 'completions/mean_length': 430.75, 'completions/min_length': 190.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 329.0, 'completions/min_terminated_length': 190.0, 'completions/max_terminated_length': 400.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.875, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.875, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 430.75, 'kl': 0.0005893996567465365, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 1.1347296237945557, 'learning_rate': 1e-06, 'num_tokens': 3851.0, 'completions/mean_length': 241.0, 'completions/min_length': 140.0, 'completions/max_length': 399.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 241.0, 'completions/min_terminated_length': 140.0, 'completions/max_terminated_length': 399.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.125, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 241.0, 'kl': 0.0006525903809233569, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5235275030136108, 'learning_rate': 1e-06, 'num_tokens': 5051.0, 'completions/mean_length': 177.0, 'completions/min_length': 141.0, 'completions/max_length': 239.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 177.0, 'completions/min_terminated_length': 141.0, 'completions/max_terminated_length': 239.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.5, 'reward_std': 1.7320507764816284, 'frac_reward_zero_std': 0.0, 'completion_length': 177.0, 'kl': 0.0006815232682129135, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3619556128978729, 'learning_rate': 1e-06, 'num_tokens': 6856.0, 'completions/mean_length': 301.25, 'completions/min_length': 202.0, 'completions/max_length': 427.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 301.25, 'completions/min_terminated_length': 202.0, 'completions/max_terminated_length': 427.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 301.25, 'kl': 0.00041388225508853793, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.7862402200698853, 'learning_rate': 1e-06, 'num_tokens': 8553.0, 'completions/mean_length': 268.25, 'completions/min_length': 117.0, 'completions/max_length': 390.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 268.25, 'completions/min_terminated_length': 117.0, 'completions/max_terminated_length': 390.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -1.125, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 268.25, 'kl': 0.0005261158075882122, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5059999823570251, 'learning_rate': 1e-06, 'num_tokens': 9678.0, 'completions/mean_length': 153.25, 'completions/min_length': 109.0, 'completions/max_length': 196.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 153.25, 'completions/min_terminated_length': 109.0, 'completions/max_terminated_length': 196.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 153.25, 'kl': 0.00035417093749856576, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3523313105106354, 'learning_rate': 1e-06, 'num_tokens': 11197.0, 'completions/mean_length': 240.75, 'completions/min_length': 194.0, 'completions/max_length': 307.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 240.75, 'completions/min_terminated_length': 194.0, 'completions/max_terminated_length': 307.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 240.75, 'kl': 0.0004903802255284972, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3135279417037964, 'learning_rate': 1e-06, 'num_tokens': 12605.0, 'completions/mean_length': 211.0, 'completions/min_length': 186.0, 'completions/max_length': 279.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 211.0, 'completions/min_terminated_length': 186.0, 'completions/max_terminated_length': 279.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.5, 'reward_std': 0.7071067690849304, 'frac_reward_zero_std': 0.0, 'completion_length': 211.0, 'kl': 0.00031881508039077744, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5468112826347351, 'learning_rate': 1e-06, 'num_tokens': 13924.0, 'completions/mean_length': 198.75, 'completions/min_length': 151.0, 'completions/max_length': 306.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 198.75, 'completions/min_terminated_length': 151.0, 'completions/max_terminated_length': 306.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.125, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 198.75, 'kl': 0.00042559638677630574, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.36015570163726807, 'learning_rate': 1e-06, 'num_tokens': 15293.0, 'completions/mean_length': 236.25, 'completions/min_length': 144.0, 'completions/max_length': 435.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 236.25, 'completions/min_terminated_length': 144.0, 'completions/max_terminated_length': 435.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.25, 'reward_std': 1.9364917278289795, 'frac_reward_zero_std': 0.0, 'completion_length': 236.25, 'kl': 0.000299911687761778, 'epoch': 0.0}
{'train_runtime': 73.0197, 'train_samples_per_second': 0.548, 'train_steps_per_second': 0.137, 'train_loss': 4.801899194717407e-07, 'epoch': 0.0}
[EP 0023] 3 | reward_mean=-0.875 | 
*** stats:  {'episode_reward_mean': -0.875, 'episode_reward_last': -0.25, 'episode_reward_std_mean': 1.1472675502300262, 'episode_reward_trajectory': [-2.875, 0.125, 0.5, -1.5, -1.125, -1.125, -1.125, -1.5, 0.125, -0.25], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.15, 'rewards/match_format_approximately/mean/last': -1.0, 'rewards/match_format_approximately/std/mean': 0.8501655876636505, 'rewards/match_format_approximately/std/last': 1.2247449159622192, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.275, 'rewards/check_numbers/mean/last': 0.75, 'rewards/check_numbers/std/mean': 0.5330126941204071, 'rewards/check_numbers/std/last': 0.8660253882408142}
Curr reward  -0.875
All rewards  -23.550000000000004
Cumulative rewards  [-18.275, 8.399999999999999, -2.775, -5.6875, -5.2125]
Num plays  [5, 5, 5, 5, 4]
Mean rewards  [-3.655, 1.6799999999999997, -0.5549999999999999, -1.1375, -1.303125]
Balancing probabilities  [0, 0, 0, 1, 0]
Mis-Specification Test [5, 4, 5, 5, 4]
potentials:  [71.55417528 35.77708764 71.55417528 71.55417528 32.        ]
sampled base index:  4
potentials:  [71.55417528 35.77708764 71.55417528 71.55417528 32.        ]
sampled base index:  4
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:08,  7.56s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:08,  7.56s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:14<00:55,  6.99s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:14<00:55,  6.99s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:44,  6.36s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:44,  6.36s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:25<00:36,  6.12s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:25<00:36,  6.12s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:29,  5.94s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:29,  5.94s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:36<00:23,  5.79s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:36<00:23,  5.79s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:42<00:17,  5.95s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:42<00:17,  5.95s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:48<00:11,  5.97s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:48<00:11,  5.97s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:54<00:05,  5.74s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:54<00:05,  5.74s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  6.98s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  6.98s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:05<00:00,  6.98s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:05<00:00,  6.56s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_3_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 6.5375
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.475
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -0.875
wandb:       modelselection/selected_base_learner 3
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_163135-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_163245-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.4914419651031494, 'learning_rate': 1e-07, 'num_tokens': 1814.0, 'completions/mean_length': 287.5, 'completions/min_length': 181.0, 'completions/max_length': 408.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 287.5, 'completions/min_terminated_length': 181.0, 'completions/max_terminated_length': 408.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 287.5, 'kl': 0.0006437560150516219, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3256058692932129, 'learning_rate': 1e-07, 'num_tokens': 3194.0, 'completions/mean_length': 220.0, 'completions/min_length': 154.0, 'completions/max_length': 340.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 220.0, 'completions/min_terminated_length': 154.0, 'completions/max_terminated_length': 340.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 220.0, 'kl': 0.000347660097759217, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4545868933200836, 'learning_rate': 1e-07, 'num_tokens': 4530.0, 'completions/mean_length': 211.0, 'completions/min_length': 129.0, 'completions/max_length': 274.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 211.0, 'completions/min_terminated_length': 129.0, 'completions/max_terminated_length': 274.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.875, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 211.0, 'kl': 0.00040057253499981016, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 5.4219028243096545e-05, 'learning_rate': 1e-07, 'num_tokens': 6057.0, 'completions/mean_length': 231.75, 'completions/min_length': 162.0, 'completions/max_length': 283.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 231.75, 'completions/min_terminated_length': 162.0, 'completions/max_terminated_length': 283.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 231.75, 'kl': 0.0005405439515016042, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.350630521774292, 'learning_rate': 1e-07, 'num_tokens': 7702.0, 'completions/mean_length': 255.25, 'completions/min_length': 243.0, 'completions/max_length': 271.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 255.25, 'completions/min_terminated_length': 243.0, 'completions/max_terminated_length': 271.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 255.25, 'kl': 0.00034702934863162227, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00010417288285680115, 'learning_rate': 1e-07, 'num_tokens': 9003.0, 'completions/mean_length': 197.25, 'completions/min_length': 149.0, 'completions/max_length': 266.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 197.25, 'completions/min_terminated_length': 149.0, 'completions/max_terminated_length': 266.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 197.25, 'kl': 0.0003330141553306021, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.49072155356407166, 'learning_rate': 1e-07, 'num_tokens': 10297.0, 'completions/mean_length': 184.5, 'completions/min_length': 124.0, 'completions/max_length': 317.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 184.5, 'completions/min_terminated_length': 124.0, 'completions/max_terminated_length': 317.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 184.5, 'kl': 0.0004050313145853579, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5484908223152161, 'learning_rate': 1e-07, 'num_tokens': 11749.0, 'completions/mean_length': 222.0, 'completions/min_length': 126.0, 'completions/max_length': 304.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 222.0, 'completions/min_terminated_length': 126.0, 'completions/max_terminated_length': 304.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 222.0, 'kl': 0.0004453315559658222, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4423731863498688, 'learning_rate': 1e-07, 'num_tokens': 13044.0, 'completions/mean_length': 192.75, 'completions/min_length': 148.0, 'completions/max_length': 247.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 192.75, 'completions/min_terminated_length': 148.0, 'completions/max_terminated_length': 247.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 192.75, 'kl': 0.00031670299722463824, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.455870658159256, 'learning_rate': 1e-07, 'num_tokens': 14552.0, 'completions/mean_length': 271.0, 'completions/min_length': 150.0, 'completions/max_length': 554.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 271.0, 'completions/min_terminated_length': 150.0, 'completions/max_terminated_length': 554.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': -0.375, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 271.0, 'kl': 0.0005625235717161559, 'epoch': 0.0}
{'train_runtime': 65.6523, 'train_samples_per_second': 0.609, 'train_steps_per_second': 0.152, 'train_loss': 4.30082519642383e-07, 'epoch': 0.0}
[EP 0024] 4 | reward_mean=-1.125 | 
*** stats:  {'episode_reward_mean': -1.125, 'episode_reward_last': -0.375, 'episode_reward_std_mean': 0.6776910960674286, 'episode_reward_trajectory': [-2.5, -1.375, -1.875, -1.0, -1.125, -1.0, -0.625, -0.75, -0.625, -0.375], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.2625, 'rewards/match_format_approximately/mean/last': -1.0, 'rewards/match_format_approximately/std/mean': 0.4065515220165253, 'rewards/match_format_approximately/std/last': 1.2247449159622192, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.1375, 'rewards/check_numbers/mean/last': 0.625, 'rewards/check_numbers/std/mean': 0.3896801769733429, 'rewards/check_numbers/std/last': 1.0307763814926147}
Curr reward  -1.125
All rewards  -24.675000000000004
Cumulative rewards  [-18.275, 8.399999999999999, -2.775, -5.6875, -6.3375]
Num plays  [5, 5, 5, 5, 5]
Mean rewards  [-3.655, 1.6799999999999997, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 0, 0, 0, 1]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 35.77708764 71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 35.77708764 71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:08<01:18,  8.73s/it]                                               10%|â–ˆ         | 1/10 [00:08<01:18,  8.73s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:13<00:52,  6.57s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:13<00:52,  6.57s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:39,  5.71s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:39,  5.71s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:34,  5.74s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:34,  5.74s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:32,  6.45s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:32,  6.45s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:37<00:24,  6.05s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:37<00:24,  6.05s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:41<00:16,  5.45s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:41<00:16,  5.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:46<00:10,  5.26s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:46<00:10,  5.26s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:50<00:04,  4.88s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:50<00:04,  4.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  4.53s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  4.53s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:55<00:00,  4.53s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:55<00:00,  5.58s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_4_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 6.5375
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.125
wandb:       modelselection/selected_base_learner 4
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_163245-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_163345-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.33203771710395813, 'learning_rate': 0.0001, 'num_tokens': 2009.0, 'completions/mean_length': 336.25, 'completions/min_length': 220.0, 'completions/max_length': 485.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 336.25, 'completions/min_terminated_length': 220.0, 'completions/max_terminated_length': 485.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.875, 'rewards/check_answer/std': 1.25, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.625, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 336.25, 'kl': 0.1398699525743723, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.3566267490386963, 'learning_rate': 0.0001, 'num_tokens': 3210.0, 'completions/mean_length': 175.25, 'completions/min_length': 130.0, 'completions/max_length': 232.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 175.25, 'completions/min_terminated_length': 130.0, 'completions/max_terminated_length': 232.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 4.625, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 175.25, 'kl': 0.21874798089265823, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0011153584346175194, 'learning_rate': 0.0001, 'num_tokens': 4443.0, 'completions/mean_length': 185.25, 'completions/min_length': 160.0, 'completions/max_length': 207.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 185.25, 'completions/min_terminated_length': 160.0, 'completions/max_terminated_length': 207.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 185.25, 'kl': 0.1939142681658268, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.2520224153995514, 'learning_rate': 0.0001, 'num_tokens': 6129.0, 'completions/mean_length': 271.5, 'completions/min_length': 257.0, 'completions/max_length': 284.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 271.5, 'completions/min_terminated_length': 257.0, 'completions/max_terminated_length': 284.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.875, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 271.5, 'kl': 0.13751809857785702, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.3078143298625946, 'learning_rate': 0.0001, 'num_tokens': 7893.0, 'completions/mean_length': 285.0, 'completions/min_length': 188.0, 'completions/max_length': 415.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 285.0, 'completions/min_terminated_length': 188.0, 'completions/max_terminated_length': 415.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 1.125, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 4.875, 'reward_std': 5.7933149337768555, 'frac_reward_zero_std': 0.0, 'completion_length': 285.0, 'kl': 0.1522719981148839, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.3617691695690155, 'learning_rate': 0.0001, 'num_tokens': 9083.0, 'completions/mean_length': 169.5, 'completions/min_length': 131.0, 'completions/max_length': 247.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 169.5, 'completions/min_terminated_length': 131.0, 'completions/max_terminated_length': 247.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.25, 'rewards/check_answer/std': 2.1794495582580566, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.25, 'reward_std': 2.598076105117798, 'frac_reward_zero_std': 0.0, 'completion_length': 169.5, 'kl': 0.18668640404939651, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.4530659019947052, 'learning_rate': 0.0001, 'num_tokens': 10154.0, 'completions/mean_length': 128.75, 'completions/min_length': 90.0, 'completions/max_length': 175.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 128.75, 'completions/min_terminated_length': 90.0, 'completions/max_terminated_length': 175.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.875, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 128.75, 'kl': 0.2502726577222347, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.40467292070388794, 'learning_rate': 0.0001, 'num_tokens': 11393.0, 'completions/mean_length': 168.75, 'completions/min_length': 121.0, 'completions/max_length': 220.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 168.75, 'completions/min_terminated_length': 121.0, 'completions/max_terminated_length': 220.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.875, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 168.75, 'kl': 0.29227621480822563, 'epoch': 0.0}
{'loss': 0.0007, 'grad_norm': 2.3734638690948486, 'learning_rate': 0.0001, 'num_tokens': 12238.0, 'completions/mean_length': 80.25, 'completions/min_length': 20.0, 'completions/max_length': 165.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 80.25, 'completions/min_terminated_length': 20.0, 'completions/max_terminated_length': 165.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 1.7320507764816284, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 4.5, 'reward_std': 5.787918567657471, 'frac_reward_zero_std': 0.0, 'completion_length': 80.25, 'kl': 0.6847147680819035, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.5420510172843933, 'learning_rate': 0.0001, 'num_tokens': 13167.0, 'completions/mean_length': 126.25, 'completions/min_length': 102.0, 'completions/max_length': 140.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 126.25, 'completions/min_terminated_length': 102.0, 'completions/max_terminated_length': 140.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 2.375, 'rewards/check_answer/std': 1.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 8.375, 'reward_std': 2.25, 'frac_reward_zero_std': 0.0, 'completion_length': 126.25, 'kl': 0.26422910764813423, 'epoch': 0.0}
{'train_runtime': 55.8339, 'train_samples_per_second': 0.716, 'train_steps_per_second': 0.179, 'train_loss': 0.00025204325647791847, 'epoch': 0.0}
[EP 0025] 1 | reward_mean=6.638 | 
*** stats:  {'episode_reward_mean': 6.6375, 'episode_reward_last': 8.375, 'episode_reward_std_mean': 3.0679309606552123, 'episode_reward_trajectory': [3.625, 4.625, 9.5, 7.875, 4.875, 7.25, 7.875, 7.875, 4.5, 8.375], 'rewards/match_format_exactly/mean/mean': 2.775, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.32320507764816286, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.775, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.36861406564712523, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 1.3625, 'rewards/check_answer/mean/last': 2.375, 'rewards/check_answer/std/mean': 1.7661500334739686, 'rewards/check_answer/std/last': 1.25, 'rewards/check_numbers/mean/mean': 0.725, 'rewards/check_numbers/mean/last': 1.0, 'rewards/check_numbers/std/mean': 0.8061552762985229, 'rewards/check_numbers/std/last': 1.0}
Curr reward  6.6375
All rewards  -18.037500000000005
Cumulative rewards  [-18.275, 15.037499999999998, -2.775, -5.6875, -6.3375]
Num plays  [5, 6, 5, 5, 5]
Mean rewards  [-3.655, 2.5062499999999996, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 39.19183588 71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 39.19183588 71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:05<00:51,  5.76s/it]                                               10%|â–ˆ         | 1/10 [00:05<00:51,  5.76s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:11<00:46,  5.79s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:11<00:46,  5.79s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:16<00:36,  5.23s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:16<00:36,  5.23s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:39,  6.65s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:39,  6.65s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:37<00:43,  8.76s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:37<00:43,  8.76s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:29,  7.39s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:29,  7.39s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:46<00:18,  6.23s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:46<00:18,  6.23s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:49<00:10,  5.41s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:49<00:10,  5.41s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:54<00:05,  5.25s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:54<00:05,  5.25s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:58<00:00,  4.84s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:58<00:00,  4.84s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  4.84s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  6.05s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 6.6375
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 6.6375
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_163345-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_163449-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0003, 'grad_norm': 0.500813364982605, 'learning_rate': 0.0001, 'num_tokens': 1268.0, 'completions/mean_length': 151.0, 'completions/min_length': 83.0, 'completions/max_length': 274.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 151.0, 'completions/min_terminated_length': 83.0, 'completions/max_terminated_length': 274.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.875, 'rewards/check_answer/std': 1.25, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.625, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 151.0, 'kl': 0.2788171023130417, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.4550166130065918, 'learning_rate': 0.0001, 'num_tokens': 2474.0, 'completions/mean_length': 176.5, 'completions/min_length': 128.0, 'completions/max_length': 283.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 176.5, 'completions/min_terminated_length': 128.0, 'completions/max_terminated_length': 283.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 2.598076105117798, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 6.25, 'reward_std': 3.752776622772217, 'frac_reward_zero_std': 0.0, 'completion_length': 176.5, 'kl': 0.2521256357431412, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0008339839405380189, 'learning_rate': 0.0001, 'num_tokens': 3563.0, 'completions/mean_length': 149.25, 'completions/min_length': 115.0, 'completions/max_length': 198.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 149.25, 'completions/min_terminated_length': 115.0, 'completions/max_terminated_length': 198.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 149.25, 'kl': 0.24185601249337196, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.26749542355537415, 'learning_rate': 0.0001, 'num_tokens': 5513.0, 'completions/mean_length': 337.5, 'completions/min_length': 198.0, 'completions/max_length': 493.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 337.5, 'completions/min_terminated_length': 198.0, 'completions/max_terminated_length': 493.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.375, 'rewards/check_answer/std': 2.136000871658325, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 6.875, 'reward_std': 3.1983067989349365, 'frac_reward_zero_std': 0.0, 'completion_length': 337.5, 'kl': 0.13887467049062252, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.23756204545497894, 'learning_rate': 0.0001, 'num_tokens': 7536.0, 'completions/mean_length': 349.75, 'completions/min_length': 178.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 221.0, 'completions/min_terminated_length': 178.0, 'completions/max_terminated_length': 248.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 1.75, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 5.5, 'reward_std': 5.656854152679443, 'frac_reward_zero_std': 0.0, 'completion_length': 349.75, 'kl': 0.13996656984090805, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.3027096390724182, 'learning_rate': 0.0001, 'num_tokens': 8805.0, 'completions/mean_length': 189.25, 'completions/min_length': 137.0, 'completions/max_length': 209.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 189.25, 'completions/min_terminated_length': 137.0, 'completions/max_terminated_length': 209.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': 1.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 1.7320507764816284, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 4.875, 'reward_std': 5.34438943862915, 'frac_reward_zero_std': 0.0, 'completion_length': 189.25, 'kl': 0.19506456702947617, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.3747301697731018, 'learning_rate': 0.0001, 'num_tokens': 9871.0, 'completions/mean_length': 127.5, 'completions/min_length': 114.0, 'completions/max_length': 148.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 127.5, 'completions/min_terminated_length': 114.0, 'completions/max_terminated_length': 148.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 4.625, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 127.5, 'kl': 0.29631442576646805, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.4144882261753082, 'learning_rate': 0.0001, 'num_tokens': 10941.0, 'completions/mean_length': 126.5, 'completions/min_length': 115.0, 'completions/max_length': 137.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 126.5, 'completions/min_terminated_length': 115.0, 'completions/max_terminated_length': 137.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.875, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 126.5, 'kl': 0.2876625880599022, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.49057990312576294, 'learning_rate': 0.0001, 'num_tokens': 12285.0, 'completions/mean_length': 205.0, 'completions/min_length': 193.0, 'completions/max_length': 219.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 205.0, 'completions/min_terminated_length': 193.0, 'completions/max_terminated_length': 219.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.875, 'reward_std': 3.75, 'frac_reward_zero_std': 0.0, 'completion_length': 205.0, 'kl': 0.2011580429971218, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.00040484388591721654, 'learning_rate': 0.0001, 'num_tokens': 13252.0, 'completions/mean_length': 135.75, 'completions/min_length': 125.0, 'completions/max_length': 154.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 135.75, 'completions/min_terminated_length': 125.0, 'completions/max_terminated_length': 154.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 135.75, 'kl': 0.24000075086951256, 'epoch': 0.0}
{'train_runtime': 60.4573, 'train_samples_per_second': 0.662, 'train_steps_per_second': 0.165, 'train_loss': 0.00022719332919223233, 'epoch': 0.0}
[EP 0026] 1 | reward_mean=6.250 | 
*** stats:  {'episode_reward_mean': 6.25, 'episode_reward_last': 9.5, 'episode_reward_std_mean': 2.945232701301575, 'episode_reward_trajectory': [3.625, 6.25, 9.5, 6.875, 5.5, 4.875, 4.625, 7.875, 3.875, 9.5], 'rewards/match_format_exactly/mean/mean': 2.55, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.47320507764816283, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.7, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.3866025388240814, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 1.275, 'rewards/check_answer/mean/last': 3.0, 'rewards/check_answer/std/mean': 1.521612775325775, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.725, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.6370953798294068, 'rewards/check_numbers/std/last': 0.0}
Curr reward  6.25
All rewards  -11.787500000000005
Cumulative rewards  [-18.275, 21.287499999999998, -2.775, -5.6875, -6.3375]
Num plays  [5, 7, 5, 5, 5]
Mean rewards  [-3.655, 3.041071428571428, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 42.33202098 71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 42.33202098 71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.19s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.19s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:17<01:03,  7.94s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:17<01:03,  7.94s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:45,  6.47s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:45,  6.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:28<00:38,  6.41s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:28<00:38,  6.41s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:37<00:36,  7.35s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:37<00:36,  7.35s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:41<00:25,  6.33s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:41<00:25,  6.33s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:45<00:16,  5.56s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:45<00:16,  5.56s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:49<00:10,  5.18s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:49<00:10,  5.18s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:54<00:05,  5.11s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:54<00:05,  5.11s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  5.56s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  5.56s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  5.56s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  6.32s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 6.25
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 6.25
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_163449-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_163556-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.31131765246391296, 'learning_rate': 0.0001, 'num_tokens': 2690.0, 'completions/mean_length': 506.5, 'completions/min_length': 208.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 277.0, 'completions/min_terminated_length': 208.0, 'completions/max_terminated_length': 346.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 0.4787135720252991, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': 1.375, 'reward_std': 4.479118347167969, 'frac_reward_zero_std': 0.0, 'completion_length': 506.5, 'kl': 0.12961654551327229, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.37682008743286133, 'learning_rate': 0.0001, 'num_tokens': 3933.0, 'completions/mean_length': 185.75, 'completions/min_length': 151.0, 'completions/max_length': 225.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 185.75, 'completions/min_terminated_length': 151.0, 'completions/max_terminated_length': 225.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.875, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 185.75, 'kl': 0.256935466080904, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006929960800334811, 'learning_rate': 0.0001, 'num_tokens': 5191.0, 'completions/mean_length': 191.5, 'completions/min_length': 169.0, 'completions/max_length': 208.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 191.5, 'completions/min_terminated_length': 169.0, 'completions/max_terminated_length': 208.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 191.5, 'kl': 0.1603768989443779, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0004757063288707286, 'learning_rate': 0.0001, 'num_tokens': 6801.0, 'completions/mean_length': 252.5, 'completions/min_length': 172.0, 'completions/max_length': 324.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 252.5, 'completions/min_terminated_length': 172.0, 'completions/max_terminated_length': 324.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 252.5, 'kl': 0.13787343725562096, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.3112201690673828, 'learning_rate': 0.0001, 'num_tokens': 8628.0, 'completions/mean_length': 300.75, 'completions/min_length': 187.0, 'completions/max_length': 502.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 300.75, 'completions/min_terminated_length': 187.0, 'completions/max_terminated_length': 502.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.875, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 300.75, 'kl': 0.1069144681096077, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0007094956235960126, 'learning_rate': 0.0001, 'num_tokens': 9810.0, 'completions/mean_length': 167.5, 'completions/min_length': 153.0, 'completions/max_length': 184.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 167.5, 'completions/min_terminated_length': 153.0, 'completions/max_terminated_length': 184.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 167.5, 'kl': 0.19585822522640228, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.0024653694126755, 'learning_rate': 0.0001, 'num_tokens': 10852.0, 'completions/mean_length': 121.5, 'completions/min_length': 82.0, 'completions/max_length': 158.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 121.5, 'completions/min_terminated_length': 82.0, 'completions/max_terminated_length': 158.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 121.5, 'kl': 0.36196285486221313, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0005894363857805729, 'learning_rate': 0.0001, 'num_tokens': 12053.0, 'completions/mean_length': 159.25, 'completions/min_length': 135.0, 'completions/max_length': 185.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 159.25, 'completions/min_terminated_length': 135.0, 'completions/max_terminated_length': 185.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 159.25, 'kl': 0.21988330408930779, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0005707662785425782, 'learning_rate': 0.0001, 'num_tokens': 13354.0, 'completions/mean_length': 194.25, 'completions/min_length': 157.0, 'completions/max_length': 225.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 194.25, 'completions/min_terminated_length': 157.0, 'completions/max_terminated_length': 225.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 194.25, 'kl': 0.16411536931991577, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.41419926285743713, 'learning_rate': 0.0001, 'num_tokens': 14638.0, 'completions/mean_length': 215.0, 'completions/min_length': 174.0, 'completions/max_length': 332.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 215.0, 'completions/min_terminated_length': 174.0, 'completions/max_terminated_length': 332.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': 1.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 1.7320507764816284, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 5.75, 'reward_std': 4.330127239227295, 'frac_reward_zero_std': 0.0, 'completion_length': 215.0, 'kl': 0.18759690038859844, 'epoch': 0.0}
{'train_runtime': 63.1675, 'train_samples_per_second': 0.633, 'train_steps_per_second': 0.158, 'train_loss': 0.00019211649778299033, 'epoch': 0.0}
[EP 0027] 1 | reward_mean=7.987 | 
*** stats:  {'episode_reward_mean': 7.9875, 'episode_reward_last': 5.75, 'episode_reward_std_mean': 1.5309245586395264, 'episode_reward_trajectory': [1.375, 7.875, 9.5, 9.5, 7.875, 9.5, 9.5, 9.5, 9.5, 5.75], 'rewards/match_format_exactly/mean/mean': 2.7, 'rewards/match_format_exactly/mean/last': 1.5, 'rewards/match_format_exactly/std/mean': 0.3464101552963257, 'rewards/match_format_exactly/std/last': 1.7320507764816284, 'rewards/match_format_approximately/mean/mean': 1.7375, 'rewards/match_format_approximately/mean/last': 1.625, 'rewards/match_format_approximately/std/mean': 0.33480761051177976, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 2.3625, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.6710764348506928, 'rewards/check_answer/std/last': 1.7320507764816284, 'rewards/check_numbers/mean/mean': 1.1875, 'rewards/check_numbers/mean/last': 1.125, 'rewards/check_numbers/std/mean': 0.3038675129413605, 'rewards/check_numbers/std/last': 0.75}
Curr reward  7.9875
All rewards  -3.800000000000005
Cumulative rewards  [-18.275, 29.275, -2.775, -5.6875, -6.3375]
Num plays  [5, 8, 5, 5, 5]
Mean rewards  [-3.655, 3.659375, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 45.254834   71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 45.254834   71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:05<00:53,  5.93s/it]                                               10%|â–ˆ         | 1/10 [00:05<00:53,  5.93s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:11<00:44,  5.56s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:11<00:44,  5.56s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:35,  5.14s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:35,  5.14s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:33,  5.60s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:33,  5.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:30<00:33,  6.68s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:30<00:33,  6.68s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:35<00:24,  6.05s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:35<00:24,  6.05s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:41<00:17,  5.98s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:41<00:17,  5.98s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:46<00:11,  5.65s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:46<00:11,  5.65s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:58<00:07,  7.77s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:58<00:07,  7.77s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:02<00:00,  6.66s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:02<00:00,  6.66s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:04<00:00,  6.66s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:04<00:00,  6.48s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 7.9875
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 7.9875
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_163556-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_163705-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.4017069935798645, 'learning_rate': 0.0001, 'num_tokens': 1688.0, 'completions/mean_length': 256.0, 'completions/min_length': 212.0, 'completions/max_length': 294.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 256.0, 'completions/min_terminated_length': 212.0, 'completions/max_terminated_length': 294.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.25, 'rewards/check_answer/std': 1.4433757066726685, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 4.25, 'reward_std': 1.443375587463379, 'frac_reward_zero_std': 0.0, 'completion_length': 256.0, 'kl': 0.20278573408722878, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0004533012106548995, 'learning_rate': 0.0001, 'num_tokens': 3106.0, 'completions/mean_length': 229.5, 'completions/min_length': 199.0, 'completions/max_length': 252.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 229.5, 'completions/min_terminated_length': 199.0, 'completions/max_terminated_length': 252.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 229.5, 'kl': 0.18407201394438744, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0010445755906403065, 'learning_rate': 0.0001, 'num_tokens': 4282.0, 'completions/mean_length': 171.0, 'completions/min_length': 134.0, 'completions/max_length': 210.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 171.0, 'completions/min_terminated_length': 134.0, 'completions/max_terminated_length': 210.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 171.0, 'kl': 0.2119567170739174, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.000383832462830469, 'learning_rate': 0.0001, 'num_tokens': 5884.0, 'completions/mean_length': 250.5, 'completions/min_length': 167.0, 'completions/max_length': 320.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 250.5, 'completions/min_terminated_length': 167.0, 'completions/max_terminated_length': 320.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 250.5, 'kl': 0.13266574777662754, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.3600969910621643, 'learning_rate': 0.0001, 'num_tokens': 7700.0, 'completions/mean_length': 298.0, 'completions/min_length': 207.0, 'completions/max_length': 475.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 298.0, 'completions/min_terminated_length': 207.0, 'completions/max_terminated_length': 475.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.875, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 298.0, 'kl': 0.10724203661084175, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0005592156667262316, 'learning_rate': 0.0001, 'num_tokens': 8916.0, 'completions/mean_length': 176.0, 'completions/min_length': 138.0, 'completions/max_length': 221.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 176.0, 'completions/min_terminated_length': 138.0, 'completions/max_terminated_length': 221.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 176.0, 'kl': 0.19655094295740128, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.22966553270816803, 'learning_rate': 0.0001, 'num_tokens': 10530.0, 'completions/mean_length': 264.5, 'completions/min_length': 235.0, 'completions/max_length': 289.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 264.5, 'completions/min_terminated_length': 235.0, 'completions/max_terminated_length': 289.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 1.3149778842926025, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 7.375, 'reward_std': 2.462214469909668, 'frac_reward_zero_std': 0.0, 'completion_length': 264.5, 'kl': 0.14742770418524742, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006680062506347895, 'learning_rate': 0.0001, 'num_tokens': 11835.0, 'completions/mean_length': 185.25, 'completions/min_length': 170.0, 'completions/max_length': 226.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 185.25, 'completions/min_terminated_length': 170.0, 'completions/max_terminated_length': 226.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 185.25, 'kl': 0.17273263819515705, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.2635088264942169, 'learning_rate': 0.0001, 'num_tokens': 13698.0, 'completions/mean_length': 334.75, 'completions/min_length': 160.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 201.0, 'completions/min_terminated_length': 160.0, 'completions/max_terminated_length': 263.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 1.125, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 4.875, 'reward_std': 5.7933149337768555, 'frac_reward_zero_std': 0.0, 'completion_length': 334.75, 'kl': 0.15168161131441593, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0015797726809978485, 'learning_rate': 0.0001, 'num_tokens': 14777.0, 'completions/mean_length': 163.75, 'completions/min_length': 151.0, 'completions/max_length': 176.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 163.75, 'completions/min_terminated_length': 151.0, 'completions/max_terminated_length': 176.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 163.75, 'kl': 0.24774841591715813, 'epoch': 0.0}
{'train_runtime': 64.7542, 'train_samples_per_second': 0.618, 'train_steps_per_second': 0.154, 'train_loss': 0.0001754774188157171, 'epoch': 0.0}
[EP 0028] 1 | reward_mean=8.137 | 
*** stats:  {'episode_reward_mean': 8.1375, 'episode_reward_last': 9.5, 'episode_reward_std_mean': 1.2948904991149903, 'episode_reward_trajectory': [4.25, 9.5, 9.5, 9.5, 7.875, 9.5, 7.375, 9.5, 4.875, 9.5], 'rewards/match_format_exactly/mean/mean': 2.925, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.15, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.8875, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.225, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 2.2625, 'rewards/check_answer/mean/last': 3.0, 'rewards/check_answer/std/mean': 0.7258353590965271, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.0625, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.3185476899147034, 'rewards/check_numbers/std/last': 0.0}
Curr reward  8.1375
All rewards  4.337499999999994
Cumulative rewards  [-18.275, 37.412499999999994, -2.775, -5.6875, -6.3375]
Num plays  [5, 9, 5, 5, 5]
Mean rewards  [-3.655, 4.156944444444444, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 48.         71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 48.         71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:05,  7.30s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:05,  7.30s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:13<00:54,  6.77s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:13<00:54,  6.77s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:41,  5.91s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:41,  5.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:35,  5.98s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:35,  5.98s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:30<00:29,  5.93s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:30<00:29,  5.93s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:34<00:21,  5.33s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:34<00:21,  5.33s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:40<00:16,  5.61s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:40<00:16,  5.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:53<00:15,  7.79s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:53<00:15,  7.79s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:59<00:07,  7.16s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:59<00:07,  7.16s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  6.21s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  6.21s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:05<00:00,  6.21s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:05<00:00,  6.50s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 8.1375
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 8.1375
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_163705-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_163814-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.4763646125793457, 'learning_rate': 0.0001, 'num_tokens': 1733.0, 'completions/mean_length': 267.25, 'completions/min_length': 174.0, 'completions/max_length': 388.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 267.25, 'completions/min_terminated_length': 174.0, 'completions/max_terminated_length': 388.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 2.1213202476501465, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 1.8874585628509521, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 3.0, 'reward_std': 4.949747562408447, 'frac_reward_zero_std': 0.0, 'completion_length': 267.25, 'kl': 0.2388009876012802, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.3335764408111572, 'learning_rate': 0.0001, 'num_tokens': 3318.0, 'completions/mean_length': 271.25, 'completions/min_length': 233.0, 'completions/max_length': 328.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 271.25, 'completions/min_terminated_length': 233.0, 'completions/max_terminated_length': 328.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 4.625, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 271.25, 'kl': 0.18333787471055984, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.3015988767147064, 'learning_rate': 0.0001, 'num_tokens': 4531.0, 'completions/mean_length': 180.25, 'completions/min_length': 157.0, 'completions/max_length': 222.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 180.25, 'completions/min_terminated_length': 157.0, 'completions/max_terminated_length': 222.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.875, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 180.25, 'kl': 0.20954164862632751, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.25937438011169434, 'learning_rate': 0.0001, 'num_tokens': 6269.0, 'completions/mean_length': 284.5, 'completions/min_length': 242.0, 'completions/max_length': 307.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 284.5, 'completions/min_terminated_length': 242.0, 'completions/max_terminated_length': 307.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 1.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 1.125, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 5.25, 'reward_std': 5.172039985656738, 'frac_reward_zero_std': 0.0, 'completion_length': 284.5, 'kl': 0.12914887256920338, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.3624173402786255, 'learning_rate': 0.0001, 'num_tokens': 7910.0, 'completions/mean_length': 254.25, 'completions/min_length': 222.0, 'completions/max_length': 287.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 254.25, 'completions/min_terminated_length': 222.0, 'completions/max_terminated_length': 287.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.875, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 254.25, 'kl': 0.15668437629938126, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0063765812665224075, 'learning_rate': 0.0001, 'num_tokens': 9055.0, 'completions/mean_length': 158.25, 'completions/min_length': 141.0, 'completions/max_length': 177.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 158.25, 'completions/min_terminated_length': 141.0, 'completions/max_terminated_length': 177.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 158.25, 'kl': 0.3250479996204376, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.4023093283176422, 'learning_rate': 0.0001, 'num_tokens': 10625.0, 'completions/mean_length': 253.5, 'completions/min_length': 210.0, 'completions/max_length': 316.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 253.5, 'completions/min_terminated_length': 210.0, 'completions/max_terminated_length': 316.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.875, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 253.5, 'kl': 0.18256307020783424, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.2398795187473297, 'learning_rate': 0.0001, 'num_tokens': 12422.0, 'completions/mean_length': 308.25, 'completions/min_length': 146.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 165.6666717529297, 'completions/min_terminated_length': 146.0, 'completions/max_terminated_length': 202.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 2.1213202476501465, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 1.7320507764816284, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 4.625, 'reward_std': 5.921359539031982, 'frac_reward_zero_std': 0.0, 'completion_length': 308.25, 'kl': 0.3320966702885926, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.46598976850509644, 'learning_rate': 0.0001, 'num_tokens': 13775.0, 'completions/mean_length': 207.25, 'completions/min_length': 159.0, 'completions/max_length': 284.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 207.25, 'completions/min_terminated_length': 159.0, 'completions/max_terminated_length': 284.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 4.625, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 207.25, 'kl': 0.2941128760576248, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0012264222605153918, 'learning_rate': 0.0001, 'num_tokens': 14787.0, 'completions/mean_length': 147.0, 'completions/min_length': 126.0, 'completions/max_length': 170.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 147.0, 'completions/min_terminated_length': 126.0, 'completions/max_terminated_length': 170.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 147.0, 'kl': 0.2720787934958935, 'epoch': 0.0}
{'train_runtime': 65.0191, 'train_samples_per_second': 0.615, 'train_steps_per_second': 0.154, 'train_loss': 0.00023233816609717904, 'epoch': 0.0}
[EP 0029] 1 | reward_mean=6.475 | 
*** stats:  {'episode_reward_mean': 6.475, 'episode_reward_last': 9.5, 'episode_reward_std_mean': 3.2293147087097167, 'episode_reward_trajectory': [3.0, 4.625, 7.875, 5.25, 7.875, 9.5, 7.875, 4.625, 4.625, 9.5], 'rewards/match_format_exactly/mean/mean': 2.625, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.4964101552963257, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.625, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.5742640495300293, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 1.3875, 'rewards/check_answer/mean/last': 3.0, 'rewards/check_answer/std/mean': 1.7119509339332581, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.8375, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.781155276298523, 'rewards/check_numbers/std/last': 0.0}
Curr reward  6.475
All rewards  10.812499999999993
Cumulative rewards  [-18.275, 43.887499999999996, -2.775, -5.6875, -6.3375]
Num plays  [5, 10, 5, 5, 5]
Mean rewards  [-3.655, 4.38875, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 50.59644256 71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 50.59644256 71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.34s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.34s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:17<01:06,  8.30s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:17<01:06,  8.30s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:48,  6.92s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:48,  6.92s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:32<00:47,  7.94s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:32<00:47,  7.94s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:45<00:47,  9.56s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:45<00:47,  9.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:49<00:31,  7.92s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:49<00:31,  7.92s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:02<00:28,  9.37s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:02<00:28,  9.37s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:14<00:20, 10.31s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:14<00:20, 10.31s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:26<00:10, 10.93s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:26<00:10, 10.93s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:31<00:00,  8.97s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:31<00:00,  8.97s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:33<00:00,  8.97s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:33<00:00,  9.30s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 6.475
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 6.475
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_163814-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_163951-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.3755785822868347, 'learning_rate': 0.0001, 'num_tokens': 3184.0, 'completions/mean_length': 630.0, 'completions/min_length': 312.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 312.0, 'completions/min_terminated_length': 312.0, 'completions/max_terminated_length': 312.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.25, 'rewards/check_answer/std': 0.5, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.5, 'reward_std': 4.0, 'frac_reward_zero_std': 0.0, 'completion_length': 630.0, 'kl': 0.1607573814690113, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.3631495237350464, 'learning_rate': 0.0001, 'num_tokens': 4592.0, 'completions/mean_length': 227.0, 'completions/min_length': 203.0, 'completions/max_length': 262.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 227.0, 'completions/min_terminated_length': 203.0, 'completions/max_terminated_length': 262.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 2.598076105117798, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 6.25, 'reward_std': 3.752776622772217, 'frac_reward_zero_std': 0.0, 'completion_length': 227.0, 'kl': 0.2815915495157242, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.5245459079742432, 'learning_rate': 0.0001, 'num_tokens': 5946.0, 'completions/mean_length': 215.5, 'completions/min_length': 147.0, 'completions/max_length': 247.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 215.5, 'completions/min_terminated_length': 147.0, 'completions/max_terminated_length': 247.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 1.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 2.25, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 7.625, 'reward_std': 3.75, 'frac_reward_zero_std': 0.0, 'completion_length': 215.5, 'kl': 0.3799070194363594, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.3283555507659912, 'learning_rate': 0.0001, 'num_tokens': 7985.0, 'completions/mean_length': 359.75, 'completions/min_length': 225.0, 'completions/max_length': 539.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 359.75, 'completions/min_terminated_length': 225.0, 'completions/max_terminated_length': 539.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 5.875, 'reward_std': 3.3757715225219727, 'frac_reward_zero_std': 0.0, 'completion_length': 359.75, 'kl': 0.2597108595073223, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.33232247829437256, 'learning_rate': 0.0001, 'num_tokens': 10449.0, 'completions/mean_length': 460.0, 'completions/min_length': 305.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 368.0, 'completions/min_terminated_length': 305.0, 'completions/max_terminated_length': 409.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.5, 'rewards/check_answer/std': 1.8708287477493286, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': 3.75, 'reward_std': 4.9749369621276855, 'frac_reward_zero_std': 0.0, 'completion_length': 460.0, 'kl': 0.2514590248465538, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0008190430817194283, 'learning_rate': 0.0001, 'num_tokens': 11723.0, 'completions/mean_length': 190.5, 'completions/min_length': 148.0, 'completions/max_length': 212.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 190.5, 'completions/min_terminated_length': 148.0, 'completions/max_terminated_length': 212.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 190.5, 'kl': 0.2995557188987732, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.2548084855079651, 'learning_rate': 0.0001, 'num_tokens': 15223.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 736.0, 'kl': 0.16202548518776894, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.3657606542110443, 'learning_rate': 0.0001, 'num_tokens': 18338.0, 'completions/mean_length': 637.75, 'completions/min_length': 343.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 343.0, 'completions/min_terminated_length': 343.0, 'completions/max_terminated_length': 343.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': 0.125, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 637.75, 'kl': 0.2041686214506626, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.009178098291158676, 'learning_rate': 0.0001, 'num_tokens': 21806.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.35412988625466824, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.002683119149878621, 'learning_rate': 0.0001, 'num_tokens': 22976.0, 'completions/mean_length': 186.5, 'completions/min_length': 170.0, 'completions/max_length': 203.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 186.5, 'completions/min_terminated_length': 170.0, 'completions/max_terminated_length': 203.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 186.5, 'kl': 0.4687190428376198, 'epoch': 0.0}
{'train_runtime': 93.0381, 'train_samples_per_second': 0.43, 'train_steps_per_second': 0.107, 'train_loss': 0.00028221280663274226, 'epoch': 0.0}
[EP 0030] 1 | reward_mean=3.450 | 
*** stats:  {'episode_reward_mean': 3.45, 'episode_reward_last': 8.0, 'episode_reward_std_mean': 2.5853485107421874, 'episode_reward_trajectory': [-0.5, 6.25, 7.625, 5.875, 3.75, 8.0, -2.125, 0.125, -2.5, 8.0], 'rewards/match_format_exactly/mean/mean': 1.8, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.6, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.3125, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.825, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.75, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.9468904852867126, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.5875, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.42558857798576355, 'rewards/check_numbers/std/last': 0.0}
Curr reward  3.45
All rewards  14.262499999999992
Cumulative rewards  [-18.275, 47.3375, -2.775, -5.6875, -6.3375]
Num plays  [5, 11, 5, 5, 5]
Mean rewards  [-3.655, 4.303409090909091, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 53.06599665 71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 53.06599665 71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.34s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.34s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:37, 12.16s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:37, 12.16s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.21s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.21s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:13, 12.26s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:13, 12.26s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.27s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.27s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.27s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.27s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.29s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.29s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.34s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.34s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.33s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.33s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:56<00:00, 10.20s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:56<00:00, 10.20s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:57<00:00, 10.20s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:57<00:00, 11.78s/it]
wandb: updating run metadata
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 3.45
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 3.45
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_163951-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_164152-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.0015671837609261274, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.1881757229566574, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.4082512855529785, 'learning_rate': 0.0001, 'num_tokens': 6022.0, 'completions/mean_length': 478.5, 'completions/min_length': 212.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 221.0, 'completions/min_terminated_length': 212.0, 'completions/max_terminated_length': 230.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 1.2247449159622192, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 1.5, 'reward_std': 5.049752235412598, 'frac_reward_zero_std': 0.0, 'completion_length': 478.5, 'kl': 0.2981153652071953, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.22069618105888367, 'learning_rate': 0.0001, 'num_tokens': 9458.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 736.0, 'kl': 0.18475513719022274, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.2811245322227478, 'learning_rate': 0.0001, 'num_tokens': 13002.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 2.75, 'frac_reward_zero_std': 0.0, 'completion_length': 736.0, 'kl': 0.21422173455357552, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0014124689623713493, 'learning_rate': 0.0001, 'num_tokens': 16570.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.19314423948526382, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.48538869619369507, 'learning_rate': 0.0001, 'num_tokens': 19525.0, 'completions/mean_length': 610.75, 'completions/min_length': 235.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 235.0, 'completions/min_terminated_length': 235.0, 'completions/max_terminated_length': 235.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': 0.125, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 610.75, 'kl': 1.8229308016598225, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.007079266011714935, 'learning_rate': 0.0001, 'num_tokens': 23025.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.24944394454360008, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.4634401500225067, 'learning_rate': 0.0001, 'num_tokens': 25186.0, 'completions/mean_length': 399.25, 'completions/min_length': 285.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 287.0, 'completions/min_terminated_length': 285.0, 'completions/max_terminated_length': 291.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 0.8660253882408142, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 2.75, 'reward_std': 4.330127239227295, 'frac_reward_zero_std': 0.0, 'completion_length': 399.25, 'kl': 0.3454463928937912, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.32164645195007324, 'learning_rate': 0.0001, 'num_tokens': 28654.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 736.0, 'kl': 0.1889490820467472, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.5731182098388672, 'learning_rate': 0.0001, 'num_tokens': 29869.0, 'completions/mean_length': 197.75, 'completions/min_length': 160.0, 'completions/max_length': 257.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 197.75, 'completions/min_terminated_length': 160.0, 'completions/max_terminated_length': 257.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 6.125, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 197.75, 'kl': 0.5348101034760475, 'epoch': 0.0}
{'train_runtime': 117.8377, 'train_samples_per_second': 0.339, 'train_steps_per_second': 0.085, 'train_loss': 0.0004219976835884154, 'epoch': 0.0}
[EP 0031] 1 | reward_mean=-0.237 | 
*** stats:  {'episode_reward_mean': -0.2375, 'episode_reward_last': 6.125, 'episode_reward_std_mean': 1.9629879474639893, 'episode_reward_trajectory': [-2.5, 1.5, -2.125, -1.125, -2.5, 0.125, -2.5, 2.75, -2.125, 6.125], 'rewards/match_format_exactly/mean/mean': 0.75, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.6464101552963257, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.4875, 'rewards/match_format_approximately/mean/last': 0.125, 'rewards/match_format_approximately/std/mean': 1.0214101493358612, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.225, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.35907703042030337, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.275, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.2732050776481628, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -0.2375
All rewards  14.024999999999991
Cumulative rewards  [-18.275, 47.1, -2.775, -5.6875, -6.3375]
Num plays  [5, 12, 5, 5, 5]
Mean rewards  [-3.655, 3.9250000000000003, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 55.42562584 71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 55.42562584 71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.15s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.15s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:17<01:06,  8.37s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:17<01:06,  8.37s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:22<00:47,  6.83s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:22<00:47,  6.83s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:29<00:40,  6.73s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:29<00:40,  6.73s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:37<00:36,  7.27s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:37<00:36,  7.27s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:25,  6.48s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:25,  6.48s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:54<00:24,  8.24s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:54<00:24,  8.24s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:58<00:13,  7.00s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:58<00:13,  7.00s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:03<00:06,  6.30s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:03<00:06,  6.30s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:07<00:00,  5.69s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:07<00:00,  5.69s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:09<00:00,  5.69s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:09<00:00,  6.96s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -0.2375
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -0.2375
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_164152-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_164305-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0011, 'grad_norm': 0.5652247071266174, 'learning_rate': 0.0001, 'num_tokens': 2736.0, 'completions/mean_length': 518.0, 'completions/min_length': 262.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 300.0, 'completions/min_terminated_length': 262.0, 'completions/max_terminated_length': 338.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.7320507764816284, 'rewards/check_answer/mean': 0.5, 'rewards/check_answer/std': 0.5773502588272095, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': 0.75, 'reward_std': 3.752776622772217, 'frac_reward_zero_std': 0.0, 'completion_length': 518.0, 'kl': 1.1033649165183306, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.4216512441635132, 'learning_rate': 0.0001, 'num_tokens': 4288.0, 'completions/mean_length': 263.0, 'completions/min_length': 239.0, 'completions/max_length': 280.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 263.0, 'completions/min_terminated_length': 239.0, 'completions/max_terminated_length': 280.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 1.7320507764816284, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 4.0, 'reward_std': 2.886751174926758, 'frac_reward_zero_std': 0.0, 'completion_length': 263.0, 'kl': 0.44860734045505524, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.002061211271211505, 'learning_rate': 0.0001, 'num_tokens': 5542.0, 'completions/mean_length': 190.5, 'completions/min_length': 158.0, 'completions/max_length': 229.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 190.5, 'completions/min_terminated_length': 158.0, 'completions/max_terminated_length': 229.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 6.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 190.5, 'kl': 0.39471955597400665, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.3265608251094818, 'learning_rate': 0.0001, 'num_tokens': 7222.0, 'completions/mean_length': 270.0, 'completions/min_length': 209.0, 'completions/max_length': 342.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 270.0, 'completions/min_terminated_length': 209.0, 'completions/max_terminated_length': 342.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 5.25, 'reward_std': 2.5, 'frac_reward_zero_std': 0.0, 'completion_length': 270.0, 'kl': 0.4344622492790222, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.3266991078853607, 'learning_rate': 0.0001, 'num_tokens': 9310.0, 'completions/mean_length': 366.0, 'completions/min_length': 190.0, 'completions/max_length': 461.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 366.0, 'completions/min_terminated_length': 190.0, 'completions/max_terminated_length': 461.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.75, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 2.75, 'reward_std': 2.5, 'frac_reward_zero_std': 0.0, 'completion_length': 366.0, 'kl': 0.4789950028061867, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.4178521931171417, 'learning_rate': 0.0001, 'num_tokens': 10582.0, 'completions/mean_length': 190.0, 'completions/min_length': 138.0, 'completions/max_length': 236.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 190.0, 'completions/min_terminated_length': 138.0, 'completions/max_terminated_length': 236.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.375, 'rewards/check_answer/std': 0.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 5.875, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 190.0, 'kl': 0.37554173916578293, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.8630377054214478, 'learning_rate': 0.0001, 'num_tokens': 12922.0, 'completions/mean_length': 446.0, 'completions/min_length': 139.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 156.0, 'completions/min_terminated_length': 139.0, 'completions/max_terminated_length': 173.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': -0.125, 'rewards/check_answer/std': 1.0307763814926147, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -0.25, 'reward_std': 3.662876844406128, 'frac_reward_zero_std': 0.0, 'completion_length': 446.0, 'kl': 0.4989021196961403, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0018839020049199462, 'learning_rate': 0.0001, 'num_tokens': 14162.0, 'completions/mean_length': 169.0, 'completions/min_length': 157.0, 'completions/max_length': 194.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 169.0, 'completions/min_terminated_length': 157.0, 'completions/max_terminated_length': 194.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 6.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 169.0, 'kl': 0.34863705933094025, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.003509924979880452, 'learning_rate': 0.0001, 'num_tokens': 15465.0, 'completions/mean_length': 194.75, 'completions/min_length': 152.0, 'completions/max_length': 224.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 194.75, 'completions/min_terminated_length': 152.0, 'completions/max_terminated_length': 224.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 6.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 194.75, 'kl': 0.4617989510297775, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.02576773799955845, 'learning_rate': 0.0001, 'num_tokens': 16588.0, 'completions/mean_length': 174.75, 'completions/min_length': 158.0, 'completions/max_length': 197.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 174.75, 'completions/min_terminated_length': 158.0, 'completions/max_terminated_length': 197.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 6.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 174.75, 'kl': 0.7568762302398682, 'epoch': 0.0}
{'train_runtime': 69.6169, 'train_samples_per_second': 0.575, 'train_steps_per_second': 0.144, 'train_loss': 0.0005301926023093984, 'epoch': 0.0}
[EP 0032] 1 | reward_mean=4.438 | 
*** stats:  {'episode_reward_mean': 4.4375, 'episode_reward_last': 6.5, 'episode_reward_std_mean': 1.6552404642105103, 'episode_reward_trajectory': [0.75, 4.0, 6.5, 5.25, 2.75, 5.875, -0.25, 6.5, 6.5, 6.5], 'rewards/match_format_exactly/mean/mean': 2.7, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.3464101552963257, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.1625, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.3982050776481628, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.775, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.6590177416801453, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.8, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.47320507764816283, 'rewards/check_numbers/std/last': 0.0}
Curr reward  4.4375
All rewards  18.46249999999999
Cumulative rewards  [-18.275, 51.5375, -2.775, -5.6875, -6.3375]
Num plays  [5, 13, 5, 5, 5]
Mean rewards  [-3.655, 3.964423076923077, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 57.68882041 71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 57.68882041 71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:06<00:54,  6.03s/it]                                               10%|â–ˆ         | 1/10 [00:06<00:54,  6.03s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:12<00:50,  6.31s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:12<00:50,  6.31s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:40,  5.84s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:40,  5.84s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:23<00:34,  5.75s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:23<00:34,  5.75s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:29,  5.90s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:29,  5.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:33<00:21,  5.30s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:33<00:21,  5.30s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:38<00:15,  5.01s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:38<00:15,  5.01s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:43<00:10,  5.01s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:43<00:10,  5.01s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:55<00:07,  7.27s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:55<00:07,  7.27s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  6.53s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  6.53s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.53s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.20s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 4.4375
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 4.4375
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_164305-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_164411-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.001, 'grad_norm': 0.571171760559082, 'learning_rate': 0.0001, 'num_tokens': 1619.0, 'completions/mean_length': 238.75, 'completions/min_length': 190.0, 'completions/max_length': 310.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 238.75, 'completions/min_terminated_length': 190.0, 'completions/max_terminated_length': 310.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.625, 'rewards/check_answer/std': 1.4361406564712524, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 5.0, 'reward_std': 2.8577380180358887, 'frac_reward_zero_std': 0.0, 'completion_length': 238.75, 'kl': 1.0431869700551033, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.41076916456222534, 'learning_rate': 0.0001, 'num_tokens': 3163.0, 'completions/mean_length': 261.0, 'completions/min_length': 162.0, 'completions/max_length': 344.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 261.0, 'completions/min_terminated_length': 162.0, 'completions/max_terminated_length': 344.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 1.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 1.7320507764816284, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 4.75, 'reward_std': 3.013856887817383, 'frac_reward_zero_std': 0.0, 'completion_length': 261.0, 'kl': 0.37152618914842606, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.45002979040145874, 'learning_rate': 0.0001, 'num_tokens': 4384.0, 'completions/mean_length': 182.25, 'completions/min_length': 136.0, 'completions/max_length': 257.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 182.25, 'completions/min_terminated_length': 136.0, 'completions/max_terminated_length': 257.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 6.875, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 182.25, 'kl': 0.31852708011865616, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0013388806255534291, 'learning_rate': 0.0001, 'num_tokens': 5950.0, 'completions/mean_length': 241.5, 'completions/min_length': 212.0, 'completions/max_length': 281.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 241.5, 'completions/min_terminated_length': 212.0, 'completions/max_terminated_length': 281.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 241.5, 'kl': 0.2879020757973194, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0013520519714802504, 'learning_rate': 0.0001, 'num_tokens': 7575.0, 'completions/mean_length': 250.25, 'completions/min_length': 195.0, 'completions/max_length': 319.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 250.25, 'completions/min_terminated_length': 195.0, 'completions/max_terminated_length': 319.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 250.25, 'kl': 0.2636158652603626, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0026578018441796303, 'learning_rate': 0.0001, 'num_tokens': 8728.0, 'completions/mean_length': 160.25, 'completions/min_length': 140.0, 'completions/max_length': 181.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 160.25, 'completions/min_terminated_length': 140.0, 'completions/max_terminated_length': 181.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 160.25, 'kl': 0.3099043518304825, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.5937503576278687, 'learning_rate': 0.0001, 'num_tokens': 9939.0, 'completions/mean_length': 163.75, 'completions/min_length': 94.0, 'completions/max_length': 200.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 163.75, 'completions/min_terminated_length': 94.0, 'completions/max_terminated_length': 200.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.625, 'rewards/check_answer/std': 1.4361406564712524, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 6.125, 'reward_std': 2.3935678005218506, 'frac_reward_zero_std': 0.0, 'completion_length': 163.75, 'kl': 0.5996096804738045, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0010161591926589608, 'learning_rate': 0.0001, 'num_tokens': 11356.0, 'completions/mean_length': 213.25, 'completions/min_length': 153.0, 'completions/max_length': 241.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 213.25, 'completions/min_terminated_length': 153.0, 'completions/max_terminated_length': 241.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 213.25, 'kl': 0.2499554082751274, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.3820652663707733, 'learning_rate': 0.0001, 'num_tokens': 13402.0, 'completions/mean_length': 380.5, 'completions/min_length': 251.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 262.0, 'completions/min_terminated_length': 251.0, 'completions/max_terminated_length': 275.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 1.2247449159622192, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 1.5, 'reward_std': 5.049752235412598, 'frac_reward_zero_std': 0.0, 'completion_length': 380.5, 'kl': 0.24145862087607384, 'epoch': 0.0}
{'loss': 0.0017, 'grad_norm': 0.13889271020889282, 'learning_rate': 0.0001, 'num_tokens': 14638.0, 'completions/mean_length': 203.0, 'completions/min_length': 160.0, 'completions/max_length': 235.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 203.0, 'completions/min_terminated_length': 160.0, 'completions/max_terminated_length': 235.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 203.0, 'kl': 1.6784560717642307, 'epoch': 0.0}
{'train_runtime': 61.998, 'train_samples_per_second': 0.645, 'train_steps_per_second': 0.161, 'train_loss': 0.0005364173470297828, 'epoch': 0.0}
[EP 0033] 1 | reward_mean=5.925 | 
*** stats:  {'episode_reward_mean': 5.925, 'episode_reward_last': 8.0, 'episode_reward_std_mean': 1.406491494178772, 'episode_reward_trajectory': [5.0, 4.75, 6.875, 8.0, 3.0, 8.0, 6.125, 8.0, 1.5, 8.0], 'rewards/match_format_exactly/mean/mean': 2.85, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.17320507764816284, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.475, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.4964101493358612, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.725, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.5829077005386353, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.875, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.4330126941204071, 'rewards/check_numbers/std/last': 0.0}
Curr reward  5.925
All rewards  24.387499999999992
Cumulative rewards  [-18.275, 57.4625, -2.775, -5.6875, -6.3375]
Num plays  [5, 14, 5, 5, 5]
Mean rewards  [-3.655, 4.104464285714285, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 59.86651819 71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 59.86651819 71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:05,  7.31s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:05,  7.31s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:14<01:00,  7.52s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:14<01:00,  7.52s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:20<00:46,  6.66s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:20<00:46,  6.66s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:28<00:43,  7.18s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:28<00:43,  7.18s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:37<00:39,  7.86s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:37<00:39,  7.86s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:27,  6.82s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:27,  6.82s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:48<00:19,  6.42s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:48<00:19,  6.42s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:55<00:13,  6.77s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:55<00:13,  6.77s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:07<00:08,  8.41s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:07<00:08,  8.41s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:12<00:00,  7.27s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:12<00:00,  7.27s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:14<00:00,  7.27s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:14<00:00,  7.40s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.925
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 5.925
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_164411-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_164529-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0004, 'grad_norm': 0.5498326420783997, 'learning_rate': 0.0001, 'num_tokens': 1894.0, 'completions/mean_length': 307.5, 'completions/min_length': 236.0, 'completions/max_length': 400.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 307.5, 'completions/min_terminated_length': 236.0, 'completions/max_terminated_length': 400.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 1.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 1.0, 'rewards/check_answer/std': 0.7071067690849304, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 5.875, 'reward_std': 2.839454174041748, 'frac_reward_zero_std': 0.0, 'completion_length': 307.5, 'kl': 0.4427798017859459, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.3601522743701935, 'learning_rate': 0.0001, 'num_tokens': 3786.0, 'completions/mean_length': 348.0, 'completions/min_length': 298.0, 'completions/max_length': 426.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 348.0, 'completions/min_terminated_length': 298.0, 'completions/max_terminated_length': 426.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 1.4361406564712524, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 4.125, 'reward_std': 5.006246089935303, 'frac_reward_zero_std': 0.0, 'completion_length': 348.0, 'kl': 0.2625419571995735, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.5527945160865784, 'learning_rate': 0.0001, 'num_tokens': 5197.0, 'completions/mean_length': 229.75, 'completions/min_length': 201.0, 'completions/max_length': 285.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 229.75, 'completions/min_terminated_length': 201.0, 'completions/max_terminated_length': 285.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 1.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 1.125, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 6.125, 'reward_std': 3.75, 'frac_reward_zero_std': 0.0, 'completion_length': 229.75, 'kl': 0.44389277696609497, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.3002219498157501, 'learning_rate': 0.0001, 'num_tokens': 7290.0, 'completions/mean_length': 373.25, 'completions/min_length': 271.0, 'completions/max_length': 449.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 373.25, 'completions/min_terminated_length': 271.0, 'completions/max_terminated_length': 449.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 1.4361406564712524, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 4.125, 'reward_std': 5.006246089935303, 'frac_reward_zero_std': 0.0, 'completion_length': 373.25, 'kl': 0.24592650681734085, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.2853531837463379, 'learning_rate': 0.0001, 'num_tokens': 9392.0, 'completions/mean_length': 369.5, 'completions/min_length': 312.0, 'completions/max_length': 518.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 369.5, 'completions/min_terminated_length': 312.0, 'completions/max_terminated_length': 518.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.625, 'rewards/check_answer/std': 1.4361406564712524, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 6.125, 'reward_std': 2.3935678005218506, 'frac_reward_zero_std': 0.0, 'completion_length': 369.5, 'kl': 0.17960412055253983, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.43895605206489563, 'learning_rate': 0.0001, 'num_tokens': 10704.0, 'completions/mean_length': 200.0, 'completions/min_length': 183.0, 'completions/max_length': 225.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 200.0, 'completions/min_terminated_length': 183.0, 'completions/max_terminated_length': 225.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 1.125, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 5.375, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 200.0, 'kl': 0.293257188051939, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.009346826002001762, 'learning_rate': 0.0001, 'num_tokens': 12298.0, 'completions/mean_length': 259.5, 'completions/min_length': 204.0, 'completions/max_length': 282.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 259.5, 'completions/min_terminated_length': 204.0, 'completions/max_terminated_length': 282.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 259.5, 'kl': 0.5546238049864769, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.2634866535663605, 'learning_rate': 0.0001, 'num_tokens': 14216.0, 'completions/mean_length': 338.5, 'completions/min_length': 294.0, 'completions/max_length': 414.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 338.5, 'completions/min_terminated_length': 294.0, 'completions/max_terminated_length': 414.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 6.75, 'reward_std': 2.5, 'frac_reward_zero_std': 0.0, 'completion_length': 338.5, 'kl': 0.1787368431687355, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.2857033312320709, 'learning_rate': 0.0001, 'num_tokens': 16984.0, 'completions/mean_length': 561.0, 'completions/min_length': 344.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 386.0, 'completions/min_terminated_length': 344.0, 'completions/max_terminated_length': 428.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 0.8660253882408142, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 2.75, 'reward_std': 6.062177658081055, 'frac_reward_zero_std': 0.0, 'completion_length': 561.0, 'kl': 0.21767815947532654, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0012313701445236802, 'learning_rate': 0.0001, 'num_tokens': 18189.0, 'completions/mean_length': 195.25, 'completions/min_length': 166.0, 'completions/max_length': 223.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 195.25, 'completions/min_terminated_length': 166.0, 'completions/max_terminated_length': 223.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 195.25, 'kl': 0.28396090865135193, 'epoch': 0.0}
{'train_runtime': 74.0312, 'train_samples_per_second': 0.54, 'train_steps_per_second': 0.135, 'train_loss': 0.000310294286464341, 'epoch': 0.0}
[EP 0034] 1 | reward_mean=5.725 | 
*** stats:  {'episode_reward_mean': 5.725, 'episode_reward_last': 8.0, 'episode_reward_std_mean': 3.280769181251526, 'episode_reward_trajectory': [5.875, 4.125, 6.125, 4.125, 6.125, 5.375, 8.0, 6.75, 2.75, 8.0], 'rewards/match_format_exactly/mean/mean': 2.475, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.9232050776481628, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.325, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 1.1598076105117798, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.9125, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.8881554126739502, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.0125, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.6832278668880463, 'rewards/check_numbers/std/last': 0.0}
Curr reward  5.725
All rewards  30.11249999999999
Cumulative rewards  [-18.275, 63.1875, -2.775, -5.6875, -6.3375]
Num plays  [5, 15, 5, 5, 5]
Mean rewards  [-3.655, 4.2125, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 61.96773354 71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 61.96773354 71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.16s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.16s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:37, 12.15s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:37, 12.15s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.17s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.17s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:45<01:05, 10.87s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:45<01:05, 10.87s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:57<00:56, 11.35s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:57<00:56, 11.35s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:03<00:37,  9.36s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:03<00:37,  9.36s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:10<00:25,  8.63s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:10<00:25,  8.63s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:17<00:16,  8.09s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:17<00:16,  8.09s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:29<00:09,  9.36s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:29<00:09,  9.36s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:33<00:00,  7.81s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:33<00:00,  7.81s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:35<00:00,  7.81s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:35<00:00,  9.54s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.725
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 5.725
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_164529-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_164708-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.3285277485847473, 'learning_rate': 0.0001, 'num_tokens': 3247.0, 'completions/mean_length': 645.75, 'completions/min_length': 375.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 375.0, 'completions/min_terminated_length': 375.0, 'completions/max_terminated_length': 375.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': 0.125, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 645.75, 'kl': 0.21425139158964157, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.2495366781949997, 'learning_rate': 0.0001, 'num_tokens': 5831.0, 'completions/mean_length': 521.0, 'completions/min_length': 437.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 449.3333435058594, 'completions/min_terminated_length': 437.0, 'completions/max_terminated_length': 465.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 1.4361406564712524, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 4.125, 'reward_std': 5.006246089935303, 'frac_reward_zero_std': 0.0, 'completion_length': 521.0, 'kl': 0.2423422522842884, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.26933935284614563, 'learning_rate': 0.0001, 'num_tokens': 7802.0, 'completions/mean_length': 369.75, 'completions/min_length': 235.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 247.6666717529297, 'completions/min_terminated_length': 235.0, 'completions/max_terminated_length': 272.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 1.125, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 5.375, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 369.75, 'kl': 0.3125365376472473, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006365028093568981, 'learning_rate': 0.0001, 'num_tokens': 9919.0, 'completions/mean_length': 379.25, 'completions/min_length': 293.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 379.25, 'completions/min_terminated_length': 293.0, 'completions/max_terminated_length': 512.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 379.25, 'kl': 0.1728125587105751, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.28277549147605896, 'learning_rate': 0.0001, 'num_tokens': 12282.0, 'completions/mean_length': 434.75, 'completions/min_length': 253.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 334.3333435058594, 'completions/min_terminated_length': 253.0, 'completions/max_terminated_length': 398.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 1.4361406564712524, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': 2.875, 'reward_std': 4.289036273956299, 'frac_reward_zero_std': 0.0, 'completion_length': 434.75, 'kl': 0.20851587317883968, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006022509769536555, 'learning_rate': 0.0001, 'num_tokens': 13771.0, 'completions/mean_length': 244.25, 'completions/min_length': 212.0, 'completions/max_length': 273.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 244.25, 'completions/min_terminated_length': 212.0, 'completions/max_terminated_length': 273.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 244.25, 'kl': 0.20912528410553932, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.4692268371582031, 'learning_rate': 0.0001, 'num_tokens': 15479.0, 'completions/mean_length': 288.0, 'completions/min_length': 249.0, 'completions/max_length': 387.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 288.0, 'completions/min_terminated_length': 249.0, 'completions/max_terminated_length': 387.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.375, 'rewards/check_answer/std': 0.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.375, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 288.0, 'kl': 0.3502751886844635, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.3262607753276825, 'learning_rate': 0.0001, 'num_tokens': 17338.0, 'completions/mean_length': 323.75, 'completions/min_length': 290.0, 'completions/max_length': 376.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 323.75, 'completions/min_terminated_length': 290.0, 'completions/max_terminated_length': 376.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.5, 'rewards/check_answer/std': 1.4142135381698608, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 6.0, 'reward_std': 2.4494898319244385, 'frac_reward_zero_std': 0.0, 'completion_length': 323.75, 'kl': 0.21358124539256096, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.27715596556663513, 'learning_rate': 0.0001, 'num_tokens': 19881.0, 'completions/mean_length': 504.75, 'completions/min_length': 348.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 427.66668701171875, 'completions/min_terminated_length': 348.0, 'completions/max_terminated_length': 494.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 1.4361406564712524, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 4.125, 'reward_std': 5.006246089935303, 'frac_reward_zero_std': 0.0, 'completion_length': 504.75, 'kl': 0.23127176985144615, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0013314177049323916, 'learning_rate': 0.0001, 'num_tokens': 21027.0, 'completions/mean_length': 180.5, 'completions/min_length': 151.0, 'completions/max_length': 197.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 180.5, 'completions/min_terminated_length': 151.0, 'completions/max_terminated_length': 197.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 180.5, 'kl': 0.27456874400377274, 'epoch': 0.0}
{'train_runtime': 95.3691, 'train_samples_per_second': 0.419, 'train_steps_per_second': 0.105, 'train_loss': 0.00024293201277032496, 'epoch': 0.0}
[EP 0035] 1 | reward_mean=5.400 | 
*** stats:  {'episode_reward_mean': 5.4, 'episode_reward_last': 8.0, 'episode_reward_std_mean': 2.8501018285751343, 'episode_reward_trajectory': [0.125, 4.125, 5.375, 8.0, 2.875, 8.0, 7.375, 6.0, 4.125, 8.0], 'rewards/match_format_exactly/mean/mean': 2.475, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.75, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.2125, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 1.125, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.825, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.7472635507583618, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.8875, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.6662738025188446, 'rewards/check_numbers/std/last': 0.0}
Curr reward  5.4
All rewards  35.51249999999999
Cumulative rewards  [-18.275, 68.5875, -2.775, -5.6875, -6.3375]
Num plays  [5, 16, 5, 5, 5]
Mean rewards  [-3.655, 4.28671875, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 64.         71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 64.         71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:08<01:15,  8.42s/it]                                               10%|â–ˆ         | 1/10 [00:08<01:15,  8.42s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:20<01:26, 10.76s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:20<01:26, 10.76s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:27<01:03,  9.02s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:27<01:03,  9.02s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:34<00:48,  8.01s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:34<00:48,  8.01s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:46<00:47,  9.59s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:46<00:47,  9.59s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:51<00:31,  7.95s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:51<00:31,  7.95s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:57<00:21,  7.31s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:57<00:21,  7.31s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:09<00:17,  8.93s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:09<00:17,  8.93s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:22<00:09,  9.99s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:22<00:09,  9.99s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:27<00:00,  8.47s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:27<00:00,  8.47s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:28<00:00,  8.47s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:28<00:00,  8.89s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.4
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 5.4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_164708-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_164841-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0004, 'grad_norm': 0.42777854204177856, 'learning_rate': 0.0001, 'num_tokens': 2209.0, 'completions/mean_length': 386.25, 'completions/min_length': 299.0, 'completions/max_length': 466.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 386.25, 'completions/min_terminated_length': 299.0, 'completions/max_terminated_length': 466.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 1.125, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 5.375, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 386.25, 'kl': 0.35641859471797943, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.3014155626296997, 'learning_rate': 0.0001, 'num_tokens': 4632.0, 'completions/mean_length': 480.75, 'completions/min_length': 352.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 395.66668701171875, 'completions/min_terminated_length': 352.0, 'completions/max_terminated_length': 432.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 2.1213202476501465, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 0.8660253882408142, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 3.375, 'reward_std': 5.437140941619873, 'frac_reward_zero_std': 0.0, 'completion_length': 480.75, 'kl': 0.3411746919155121, 'epoch': 0.0}
{'loss': 0.0007, 'grad_norm': 0.022155586630105972, 'learning_rate': 0.0001, 'num_tokens': 6200.0, 'completions/mean_length': 269.0, 'completions/min_length': 203.0, 'completions/max_length': 367.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 269.0, 'completions/min_terminated_length': 203.0, 'completions/max_terminated_length': 367.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 269.0, 'kl': 0.7477397695183754, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.004678066354244947, 'learning_rate': 0.0001, 'num_tokens': 8046.0, 'completions/mean_length': 311.5, 'completions/min_length': 288.0, 'completions/max_length': 331.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 311.5, 'completions/min_terminated_length': 288.0, 'completions/max_terminated_length': 331.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 311.5, 'kl': 0.36534859240055084, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.29160353541374207, 'learning_rate': 0.0001, 'num_tokens': 10496.0, 'completions/mean_length': 456.5, 'completions/min_length': 270.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 363.3333435058594, 'completions/min_terminated_length': 270.0, 'completions/max_terminated_length': 423.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 1.4361406564712524, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': 2.875, 'reward_std': 4.289036273956299, 'frac_reward_zero_std': 0.0, 'completion_length': 456.5, 'kl': 0.4075610190629959, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.77281653881073, 'learning_rate': 0.0001, 'num_tokens': 11736.0, 'completions/mean_length': 182.0, 'completions/min_length': 137.0, 'completions/max_length': 213.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 182.0, 'completions/min_terminated_length': 137.0, 'completions/max_terminated_length': 213.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 6.75, 'reward_std': 2.5, 'frac_reward_zero_std': 0.0, 'completion_length': 182.0, 'kl': 0.3413148522377014, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.4799124300479889, 'learning_rate': 0.0001, 'num_tokens': 13280.0, 'completions/mean_length': 247.0, 'completions/min_length': 188.0, 'completions/max_length': 299.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 247.0, 'completions/min_terminated_length': 188.0, 'completions/max_terminated_length': 299.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 6.75, 'reward_std': 2.5, 'frac_reward_zero_std': 0.0, 'completion_length': 247.0, 'kl': 0.3965033069252968, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.244174525141716, 'learning_rate': 0.0001, 'num_tokens': 15561.0, 'completions/mean_length': 429.25, 'completions/min_length': 295.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 327.0, 'completions/min_terminated_length': 295.0, 'completions/max_terminated_length': 361.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 2.1213202476501465, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 0.8660253882408142, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 3.875, 'reward_std': 5.105144500732422, 'frac_reward_zero_std': 0.0, 'completion_length': 429.25, 'kl': 0.24881814420223236, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.36328190565109253, 'learning_rate': 0.0001, 'num_tokens': 18670.0, 'completions/mean_length': 646.25, 'completions/min_length': 377.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 377.0, 'completions/min_terminated_length': 377.0, 'completions/max_terminated_length': 377.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': 0.125, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 646.25, 'kl': 0.2607145607471466, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0011665665078908205, 'learning_rate': 0.0001, 'num_tokens': 19942.0, 'completions/mean_length': 212.0, 'completions/min_length': 193.0, 'completions/max_length': 234.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 212.0, 'completions/min_terminated_length': 193.0, 'completions/max_terminated_length': 234.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 212.0, 'kl': 0.29424886405467987, 'epoch': 0.0}
{'train_runtime': 88.8883, 'train_samples_per_second': 0.45, 'train_steps_per_second': 0.113, 'train_loss': 0.00037598581402562556, 'epoch': 0.0}
[EP 0036] 1 | reward_mean=5.312 | 
*** stats:  {'episode_reward_mean': 5.3125, 'episode_reward_last': 8.0, 'episode_reward_std_mean': 3.0331321716308595, 'episode_reward_trajectory': [5.375, 3.375, 8.0, 8.0, 2.875, 6.75, 6.75, 3.875, 0.125, 8.0], 'rewards/match_format_exactly/mean/mean': 2.325, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.7964101552963256, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.1375, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 1.0992640495300292, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.8625, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.7668191432952881, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.9875, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.6227261126041412, 'rewards/check_numbers/std/last': 0.0}
Curr reward  5.3125
All rewards  40.82499999999999
Cumulative rewards  [-18.275, 73.9, -2.775, -5.6875, -6.3375]
Num plays  [5, 17, 5, 5, 5]
Mean rewards  [-3.655, 4.347058823529412, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 65.96969001 71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 65.96969001 71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.34s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.34s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.30s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.30s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:32<01:10, 10.08s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:32<01:10, 10.08s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:44<01:05, 10.96s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:44<01:05, 10.96s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:56<00:56, 11.39s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:56<00:56, 11.39s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:02<00:38,  9.57s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:02<00:38,  9.57s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:09<00:25,  8.61s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:09<00:25,  8.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:15<00:16,  8.02s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:15<00:16,  8.02s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:28<00:09,  9.38s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:28<00:09,  9.38s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:34<00:00,  8.25s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:34<00:00,  8.25s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:35<00:00,  8.25s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:35<00:00,  9.58s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.3125
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 5.3125
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_164841-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_165021-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0003, 'grad_norm': 0.0017014597542583942, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2754145860671997, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.2852664589881897, 'learning_rate': 0.0001, 'num_tokens': 6745.0, 'completions/mean_length': 659.25, 'completions/min_length': 429.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 429.0, 'completions/min_terminated_length': 429.0, 'completions/max_terminated_length': 429.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': 0.125, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 659.25, 'kl': 0.40968286991119385, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.008159886114299297, 'learning_rate': 0.0001, 'num_tokens': 8447.0, 'completions/mean_length': 302.5, 'completions/min_length': 246.0, 'completions/max_length': 400.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 302.5, 'completions/min_terminated_length': 246.0, 'completions/max_terminated_length': 400.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 302.5, 'kl': 0.48385508358478546, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.2630828619003296, 'learning_rate': 0.0001, 'num_tokens': 10912.0, 'completions/mean_length': 466.25, 'completions/min_length': 311.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 376.3333435058594, 'completions/min_terminated_length': 311.0, 'completions/max_terminated_length': 472.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 1.125, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 5.375, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 466.25, 'kl': 0.271587535738945, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.33992132544517517, 'learning_rate': 0.0001, 'num_tokens': 13671.0, 'completions/mean_length': 533.75, 'completions/min_length': 319.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 331.5, 'completions/min_terminated_length': 319.0, 'completions/max_terminated_length': 344.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': -0.75, 'rewards/check_answer/std': 0.8660253882408142, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': 0.25, 'reward_std': 3.175426483154297, 'frac_reward_zero_std': 0.0, 'completion_length': 533.75, 'kl': 0.2927252799272537, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0011147231562063098, 'learning_rate': 0.0001, 'num_tokens': 15141.0, 'completions/mean_length': 239.5, 'completions/min_length': 211.0, 'completions/max_length': 298.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 239.5, 'completions/min_terminated_length': 211.0, 'completions/max_terminated_length': 298.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 239.5, 'kl': 0.3352174833416939, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.0018567076185718179, 'learning_rate': 0.0001, 'num_tokens': 16839.0, 'completions/mean_length': 285.5, 'completions/min_length': 224.0, 'completions/max_length': 344.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 285.5, 'completions/min_terminated_length': 224.0, 'completions/max_terminated_length': 344.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 285.5, 'kl': 0.46248701959848404, 'epoch': 0.0}
{'loss': 0.0009, 'grad_norm': 0.06784713268280029, 'learning_rate': 0.0001, 'num_tokens': 18710.0, 'completions/mean_length': 326.75, 'completions/min_length': 290.0, 'completions/max_length': 351.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 326.75, 'completions/min_terminated_length': 290.0, 'completions/max_terminated_length': 351.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 326.75, 'kl': 0.896874912083149, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.3208845257759094, 'learning_rate': 0.0001, 'num_tokens': 21255.0, 'completions/mean_length': 505.25, 'completions/min_length': 350.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 428.3333435058594, 'completions/min_terminated_length': 350.0, 'completions/max_terminated_length': 483.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 1.125, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 5.375, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 505.25, 'kl': 0.41731224954128265, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0009483632165938616, 'learning_rate': 0.0001, 'num_tokens': 22653.0, 'completions/mean_length': 243.5, 'completions/min_length': 217.0, 'completions/max_length': 279.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 243.5, 'completions/min_terminated_length': 217.0, 'completions/max_terminated_length': 279.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 243.5, 'kl': 0.2858894392848015, 'epoch': 0.0}
{'train_runtime': 95.7849, 'train_samples_per_second': 0.418, 'train_steps_per_second': 0.104, 'train_loss': 0.00041310675733257084, 'epoch': 0.0}
[EP 0037] 1 | reward_mean=4.862 | 
*** stats:  {'episode_reward_mean': 4.8625, 'episode_reward_last': 8.0, 'episode_reward_std_mean': 1.8925426483154297, 'episode_reward_trajectory': [-2.5, 0.125, 8.0, 5.375, 0.25, 8.0, 8.0, 8.0, 5.375, 8.0], 'rewards/match_format_exactly/mean/mean': 2.175, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.6232050776481628, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.7625, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.9348076105117797, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.9375, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.3116025388240814, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.9875, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.25386751294136045, 'rewards/check_numbers/std/last': 0.0}
Curr reward  4.8625
All rewards  45.687499999999986
Cumulative rewards  [-18.275, 78.7625, -2.775, -5.6875, -6.3375]
Num plays  [5, 18, 5, 5, 5]
Mean rewards  [-3.655, 4.375694444444445, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 67.88225099 71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 67.88225099 71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.23s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.23s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:37, 12.24s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:37, 12.24s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.27s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.27s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.30s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.30s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.32s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.32s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:08<00:42, 10.63s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:08<00:42, 10.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:15<00:28,  9.49s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:15<00:28,  9.49s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:28<00:20, 10.43s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:28<00:20, 10.43s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:40<00:10, 10.96s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:40<00:10, 10.96s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:45<00:00,  9.04s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:45<00:00,  9.04s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:47<00:00,  9.04s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:47<00:00, 10.71s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 4.8625
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 4.8625
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_165021-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_165212-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0005, 'grad_norm': 0.36882853507995605, 'learning_rate': 0.0001, 'num_tokens': 2987.0, 'completions/mean_length': 580.75, 'completions/min_length': 385.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 425.5, 'completions/min_terminated_length': 385.0, 'completions/max_terminated_length': 466.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': 0.625, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 2.125, 'reward_std': 5.437140941619873, 'frac_reward_zero_std': 0.0, 'completion_length': 580.75, 'kl': 0.46530501544475555, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.35572248697280884, 'learning_rate': 0.0001, 'num_tokens': 5626.0, 'completions/mean_length': 534.75, 'completions/min_length': 334.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 467.66668701171875, 'completions/min_terminated_length': 334.0, 'completions/max_terminated_length': 607.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 1.4361406564712524, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': 2.875, 'reward_std': 4.289036273956299, 'frac_reward_zero_std': 0.0, 'completion_length': 534.75, 'kl': 0.49893176555633545, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.3944029211997986, 'learning_rate': 0.0001, 'num_tokens': 7954.0, 'completions/mean_length': 459.0, 'completions/min_length': 281.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 366.66668701171875, 'completions/min_terminated_length': 281.0, 'completions/max_terminated_length': 448.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 1.4361406564712524, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 4.125, 'reward_std': 5.006246089935303, 'frac_reward_zero_std': 0.0, 'completion_length': 459.0, 'kl': 0.44178424030542374, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.36934176087379456, 'learning_rate': 0.0001, 'num_tokens': 10570.0, 'completions/mean_length': 504.0, 'completions/min_length': 365.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 426.66668701171875, 'completions/min_terminated_length': 365.0, 'completions/max_terminated_length': 484.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 1.4361406564712524, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 4.125, 'reward_std': 5.006246089935303, 'frac_reward_zero_std': 0.0, 'completion_length': 504.0, 'kl': 0.29072366654872894, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.3538893461227417, 'learning_rate': 0.0001, 'num_tokens': 14063.0, 'completions/mean_length': 717.25, 'completions/min_length': 661.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 661.0, 'completions/min_terminated_length': 661.0, 'completions/max_terminated_length': 661.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 2.75, 'frac_reward_zero_std': 0.0, 'completion_length': 717.25, 'kl': 0.3502337820827961, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.35326382517814636, 'learning_rate': 0.0001, 'num_tokens': 15630.0, 'completions/mean_length': 263.75, 'completions/min_length': 217.0, 'completions/max_length': 390.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 263.75, 'completions/min_terminated_length': 217.0, 'completions/max_terminated_length': 390.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.25, 'rewards/check_answer/std': 0.5, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.25, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 263.75, 'kl': 0.34494081884622574, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.5075308680534363, 'learning_rate': 0.0001, 'num_tokens': 17470.0, 'completions/mean_length': 321.0, 'completions/min_length': 237.0, 'completions/max_length': 377.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 321.0, 'completions/min_terminated_length': 237.0, 'completions/max_terminated_length': 377.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.5, 'rewards/check_answer/std': 1.4142135381698608, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 6.0, 'reward_std': 2.4494898319244385, 'frac_reward_zero_std': 0.0, 'completion_length': 321.0, 'kl': 0.483491025865078, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.46473705768585205, 'learning_rate': 0.0001, 'num_tokens': 19656.0, 'completions/mean_length': 405.5, 'completions/min_length': 276.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 295.3333435058594, 'completions/min_terminated_length': 276.0, 'completions/max_terminated_length': 320.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 1.125, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 5.375, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 405.5, 'kl': 0.45193057507276535, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 3.0856196880340576, 'learning_rate': 0.0001, 'num_tokens': 22295.0, 'completions/mean_length': 528.75, 'completions/min_length': 277.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 321.5, 'completions/min_terminated_length': 277.0, 'completions/max_terminated_length': 366.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 1.2247449159622192, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 1.5, 'reward_std': 5.049752235412598, 'frac_reward_zero_std': 0.0, 'completion_length': 528.75, 'kl': 0.5878710895776749, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.00987581629306078, 'learning_rate': 0.0001, 'num_tokens': 23556.0, 'completions/mean_length': 209.25, 'completions/min_length': 201.0, 'completions/max_length': 213.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 209.25, 'completions/min_terminated_length': 201.0, 'completions/max_terminated_length': 213.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 209.25, 'kl': 0.5154378265142441, 'epoch': 0.0}
{'train_runtime': 107.1362, 'train_samples_per_second': 0.373, 'train_steps_per_second': 0.093, 'train_loss': 0.00044306937488727274, 'epoch': 0.0}
[EP 0038] 1 | reward_mean=4.025 | 
*** stats:  {'episode_reward_mean': 4.025, 'episode_reward_last': 8.0, 'episode_reward_std_mean': 3.6737911462783814, 'episode_reward_trajectory': [2.125, 2.875, 4.125, 4.125, -1.125, 7.25, 6.0, 5.375, 1.5, 8.0], 'rewards/match_format_exactly/mean/mean': 2.175, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 1.0964101552963257, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.7625, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 1.6446152210235596, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.5, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.9697380423545837, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.5875, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.7894788801670074, 'rewards/check_numbers/std/last': 0.0}
Curr reward  4.025
All rewards  49.712499999999984
Cumulative rewards  [-18.275, 82.78750000000001, -2.775, -5.6875, -6.3375]
Num plays  [5, 19, 5, 5, 5]
Mean rewards  [-3.655, 4.357236842105263, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 69.7423831  71.55417528 71.55417528 71.55417528]
sampled base index:  1
potentials:  [71.55417528 69.7423831  71.55417528 71.55417528 71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.35s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.35s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:37, 12.22s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:37, 12.22s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:30<01:04,  9.27s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:30<01:04,  9.27s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:42<01:03, 10.51s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:42<01:03, 10.51s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:55<00:55, 11.20s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:55<00:55, 11.20s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:59<00:35,  8.97s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:59<00:35,  8.97s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:11<00:30, 10.05s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:12<00:30, 10.05s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:17<00:17,  8.76s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:17<00:17,  8.76s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:30<00:09,  9.80s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:30<00:09,  9.80s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:34<00:00,  8.13s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:34<00:00,  8.13s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:36<00:00,  8.13s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:36<00:00,  9.62s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 4.025
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 4.025
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_165212-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_165352-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0213, 'grad_norm': 3.2797088623046875, 'learning_rate': 0.0001, 'num_tokens': 2561.0, 'completions/mean_length': 474.25, 'completions/min_length': 324.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 387.0, 'completions/min_terminated_length': 324.0, 'completions/max_terminated_length': 480.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 1.0, 'rewards/check_answer/std': 0.7071067690849304, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 4.75, 'reward_std': 4.9749369621276855, 'frac_reward_zero_std': 0.0, 'completion_length': 474.25, 'kl': 21.257288619875908, 'epoch': 0.0}
{'loss': 0.0045, 'grad_norm': 11.883569717407227, 'learning_rate': 0.0001, 'num_tokens': 5177.0, 'completions/mean_length': 529.0, 'completions/min_length': 308.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 322.0, 'completions/min_terminated_length': 308.0, 'completions/max_terminated_length': 336.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 1.2247449159622192, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 1.5, 'reward_std': 5.049752235412598, 'frac_reward_zero_std': 0.0, 'completion_length': 529.0, 'kl': 4.511214330792427, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.003438249696046114, 'learning_rate': 0.0001, 'num_tokens': 6596.0, 'completions/mean_length': 231.75, 'completions/min_length': 198.0, 'completions/max_length': 280.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 231.75, 'completions/min_terminated_length': 198.0, 'completions/max_terminated_length': 280.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 231.75, 'kl': 0.5412894487380981, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.6989195942878723, 'learning_rate': 0.0001, 'num_tokens': 8804.0, 'completions/mean_length': 402.0, 'completions/min_length': 259.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 290.66668701171875, 'completions/min_terminated_length': 259.0, 'completions/max_terminated_length': 328.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 2.1213202476501465, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 0.8660253882408142, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 3.5, 'reward_std': 5.338539123535156, 'frac_reward_zero_std': 0.0, 'completion_length': 402.0, 'kl': 0.49468301981687546, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.8333703279495239, 'learning_rate': 0.0001, 'num_tokens': 10832.0, 'completions/mean_length': 351.0, 'completions/min_length': 132.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 222.6666717529297, 'completions/min_terminated_length': 132.0, 'completions/max_terminated_length': 310.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': -0.75, 'rewards/check_answer/std': 0.8660253882408142, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': 0.625, 'reward_std': 2.8099524974823, 'frac_reward_zero_std': 0.0, 'completion_length': 351.0, 'kl': 0.5864395424723625, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0021637931931763887, 'learning_rate': 0.0001, 'num_tokens': 12057.0, 'completions/mean_length': 178.25, 'completions/min_length': 157.0, 'completions/max_length': 206.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 178.25, 'completions/min_terminated_length': 157.0, 'completions/max_terminated_length': 206.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 178.25, 'kl': 0.3161560371518135, 'epoch': 0.0}
{'loss': 1.5909, 'grad_norm': 55.69522476196289, 'learning_rate': 0.0001, 'num_tokens': 15557.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1590.8641442283988, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.48181259632110596, 'learning_rate': 0.0001, 'num_tokens': 17176.0, 'completions/mean_length': 263.75, 'completions/min_length': 242.0, 'completions/max_length': 294.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 263.75, 'completions/min_terminated_length': 242.0, 'completions/max_terminated_length': 294.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 1.125, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 5.375, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 263.75, 'kl': 0.29205797240138054, 'epoch': 0.0}
{'loss': 0.0029, 'grad_norm': 3.8679423332214355, 'learning_rate': 0.0001, 'num_tokens': 19654.0, 'completions/mean_length': 488.5, 'completions/min_length': 217.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 241.0, 'completions/min_terminated_length': 217.0, 'completions/max_terminated_length': 265.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 0.8660253882408142, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 2.75, 'reward_std': 6.062177658081055, 'frac_reward_zero_std': 0.0, 'completion_length': 488.5, 'kl': 2.8756233751773834, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.005785701796412468, 'learning_rate': 0.0001, 'num_tokens': 20735.0, 'completions/mean_length': 164.25, 'completions/min_length': 146.0, 'completions/max_length': 188.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 164.25, 'completions/min_terminated_length': 146.0, 'completions/max_terminated_length': 188.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 164.25, 'kl': 0.4518629238009453, 'epoch': 0.0}
{'train_runtime': 96.2443, 'train_samples_per_second': 0.416, 'train_steps_per_second': 0.104, 'train_loss': 0.16221908361185342, 'epoch': 0.0}
[EP 0039] 1 | reward_mean=4.000 | 
*** stats:  {'episode_reward_mean': 4.0, 'episode_reward_last': 8.0, 'episode_reward_std_mean': 2.948535847663879, 'episode_reward_trajectory': [4.75, 1.5, 8.0, 3.5, 0.625, 8.0, -2.5, 5.375, 2.75, 8.0], 'rewards/match_format_exactly/mean/mean': 1.95, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.9928203105926514, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.5375, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 1.4067472457885741, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.7375, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.5279927849769592, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.775, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.4667527675628662, 'rewards/check_numbers/std/last': 0.0}
Curr reward  4.0
All rewards  53.712499999999984
Cumulative rewards  [-18.275, 86.78750000000001, -2.775, -5.6875, -6.3375]
Num plays  [5, 20, 5, 5, 5]
Mean rewards  [-3.655, 4.339375, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [5, 4, 5, 5, 5]
potentials:  [71.55417528 71.55417528 71.55417528 71.55417528 71.55417528]
sampled base index:  0
potentials:  [71.55417528 71.55417528 71.55417528 71.55417528 71.55417528]
sampled base index:  0
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.35s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.35s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.27s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.27s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.26s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.26s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.29s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.29s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.31s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.31s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.30s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.30s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.30s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.30s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.30s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.30s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.31s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.31s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.29s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.29s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.29s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.46s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 4
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_165352-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_165601-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.00026193761732429266, 'learning_rate': 0.001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.06478447746485472, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00027909534401260316, 'learning_rate': 0.001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.06657164171338081, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0005398627836257219, 'learning_rate': 0.001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.06970391795039177, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00043010804802179337, 'learning_rate': 0.001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.04970171023160219, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00031370966462418437, 'learning_rate': 0.001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.058067780919373035, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0003677303611766547, 'learning_rate': 0.001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.058522144332528114, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00027136848075315356, 'learning_rate': 0.001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.05938313156366348, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00027787184808403254, 'learning_rate': 0.001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.054502091370522976, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00023866603442002088, 'learning_rate': 0.001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.049710032530128956, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00016043266805354506, 'learning_rate': 0.001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.052416217513382435, 'epoch': 0.0}
{'train_runtime': 124.6463, 'train_samples_per_second': 0.321, 'train_steps_per_second': 0.08, 'train_loss': 5.8336317670182326e-05, 'epoch': 0.0}
[EP 0040] 0 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  49.712499999999984
Cumulative rewards  [-22.275, 86.78750000000001, -2.775, -5.6875, -6.3375]
Num plays  [6, 20, 5, 5, 5]
Mean rewards  [-3.7125, 4.339375, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [1, 0, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  71.55417528  71.55417528  71.55417528  71.55417528]
sampled base index:  1
potentials:  [156.76734354  71.55417528  71.55417528  71.55417528  71.55417528]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.37s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.37s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.32s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.32s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:37<01:26, 12.36s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:37<01:26, 12.36s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:14, 12.36s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:14, 12.36s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:56<00:51, 10.28s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:56<00:51, 10.28s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:00<00:33,  8.39s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:00<00:33,  8.39s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:12<00:28,  9.60s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:12<00:28,  9.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:18<00:16,  8.45s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:18<00:16,  8.45s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:30<00:09,  9.59s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:30<00:09,  9.59s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:35<00:00,  7.94s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:35<00:00,  7.94s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:36<00:00,  7.94s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:36<00:00,  9.69s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_0_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 4
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 0
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_165601-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_165742-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0078, 'grad_norm': 0.4386116564273834, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 7.825893238186836, 'epoch': 0.0}
{'loss': 0.0443, 'grad_norm': 5.125420093536377, 'learning_rate': 0.0001, 'num_tokens': 6510.0, 'completions/mean_length': 600.5, 'completions/min_length': 194.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 194.0, 'completions/min_terminated_length': 194.0, 'completions/max_terminated_length': 194.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': 0.125, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 600.5, 'kl': 44.31336589157581, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.624963641166687, 'learning_rate': 0.0001, 'num_tokens': 8415.0, 'completions/mean_length': 353.25, 'completions/min_length': 162.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 225.6666717529297, 'completions/min_terminated_length': 162.0, 'completions/max_terminated_length': 260.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 1.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 1.125, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 6.5, 'reward_std': 3.0, 'frac_reward_zero_std': 0.0, 'completion_length': 353.25, 'kl': 0.5178082063794136, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.5887035727500916, 'learning_rate': 0.0001, 'num_tokens': 10831.0, 'completions/mean_length': 454.0, 'completions/min_length': 324.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 360.0, 'completions/min_terminated_length': 324.0, 'completions/max_terminated_length': 413.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 1.2247449159622192, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 1.875, 'reward_std': 4.697073459625244, 'frac_reward_zero_std': 0.0, 'completion_length': 454.0, 'kl': 0.47433600202202797, 'epoch': 0.0}
{'loss': 0.0086, 'grad_norm': 1.6920170783996582, 'learning_rate': 0.0001, 'num_tokens': 12645.0, 'completions/mean_length': 297.5, 'completions/min_length': 270.0, 'completions/max_length': 336.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 297.5, 'completions/min_terminated_length': 270.0, 'completions/max_terminated_length': 336.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 297.5, 'kl': 8.573216758668423, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.001601633382961154, 'learning_rate': 0.0001, 'num_tokens': 13868.0, 'completions/mean_length': 177.75, 'completions/min_length': 158.0, 'completions/max_length': 209.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 177.75, 'completions/min_terminated_length': 158.0, 'completions/max_terminated_length': 209.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 177.75, 'kl': 0.2980803921818733, 'epoch': 0.0}
{'loss': 0.3651, 'grad_norm': 9.819771766662598, 'learning_rate': 0.0001, 'num_tokens': 16361.0, 'completions/mean_length': 484.25, 'completions/min_length': 201.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 232.5, 'completions/min_terminated_length': 201.0, 'completions/max_terminated_length': 264.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 1.2247449159622192, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 1.5, 'reward_std': 5.049752235412598, 'frac_reward_zero_std': 0.0, 'completion_length': 484.25, 'kl': 365.0924071520567, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.007684970274567604, 'learning_rate': 0.0001, 'num_tokens': 17987.0, 'completions/mean_length': 265.5, 'completions/min_length': 239.0, 'completions/max_length': 297.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 265.5, 'completions/min_terminated_length': 239.0, 'completions/max_terminated_length': 297.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 265.5, 'kl': 0.30258309841156006, 'epoch': 0.0}
{'loss': 0.0011, 'grad_norm': 2.398561477661133, 'learning_rate': 0.0001, 'num_tokens': 20471.0, 'completions/mean_length': 490.0, 'completions/min_length': 211.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 244.0, 'completions/min_terminated_length': 211.0, 'completions/max_terminated_length': 277.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 0.8660253882408142, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 2.75, 'reward_std': 6.062177658081055, 'frac_reward_zero_std': 0.0, 'completion_length': 490.0, 'kl': 1.074017658829689, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.009056897833943367, 'learning_rate': 0.0001, 'num_tokens': 21524.0, 'completions/mean_length': 157.25, 'completions/min_length': 137.0, 'completions/max_length': 179.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 157.25, 'completions/min_terminated_length': 137.0, 'completions/max_terminated_length': 179.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 157.25, 'kl': 0.4718152806162834, 'epoch': 0.0}
{'train_runtime': 96.9037, 'train_samples_per_second': 0.413, 'train_steps_per_second': 0.103, 'train_loss': 0.04289435719256289, 'epoch': 0.0}
[EP 0041] 1 | reward_mean=4.225 | 
*** stats:  {'episode_reward_mean': 4.225, 'episode_reward_last': 8.0, 'episode_reward_std_mean': 2.4059003353118897, 'episode_reward_trajectory': [-2.5, 0.125, 6.5, 1.875, 8.0, 8.0, 1.5, 8.0, 2.75, 8.0], 'rewards/match_format_exactly/mean/mean': 1.95, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.8196152329444886, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.5375, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 1.0446152210235595, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.825, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.4815515220165253, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.9125, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.3348076164722443, 'rewards/check_numbers/std/last': 0.0}
Curr reward  4.225
All rewards  53.937499999999986
Cumulative rewards  [-22.275, 91.0125, -2.775, -5.6875, -6.3375]
Num plays  [6, 21, 5, 5, 5]
Mean rewards  [-3.7125, 4.333928571428571, -0.5549999999999999, -1.1375, -1.2675]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  73.32121112  71.55417528  71.55417528  71.55417528]
sampled base index:  2
potentials:  [156.76734354  73.32121112  71.55417528  71.55417528  71.55417528]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:07,  7.48s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:07,  7.48s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:12<00:46,  5.86s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:12<00:46,  5.86s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:40,  5.73s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:40,  5.73s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:25<00:39,  6.50s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:25<00:39,  6.50s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:34<00:37,  7.51s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:34<00:37,  7.51s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:39<00:26,  6.51s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:39<00:26,  6.51s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:44<00:17,  5.93s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:44<00:17,  5.93s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:49<00:11,  5.82s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:49<00:11,  5.82s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:59<00:06,  6.95s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:59<00:06,  6.95s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:04<00:00,  6.34s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:04<00:00,  6.34s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:05<00:00,  6.34s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:05<00:00,  6.58s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: uploading console lines 11-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 4.225
wandb:      modelselection/base_2_episodic_reward 0.025
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 4.225
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_165742-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_165852-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.40767335891723633, 'learning_rate': 1e-05, 'num_tokens': 1957.0, 'completions/mean_length': 323.25, 'completions/min_length': 237.0, 'completions/max_length': 400.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 297.66668701171875, 'completions/min_terminated_length': 237.0, 'completions/max_terminated_length': 400.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -0.875, 'reward_std': 1.1814539432525635, 'frac_reward_zero_std': 0.0, 'completion_length': 307.25, 'kl': 0.01720004330854863, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.34116989374160767, 'learning_rate': 1e-05, 'num_tokens': 3228.0, 'completions/mean_length': 192.75, 'completions/min_length': 172.0, 'completions/max_length': 212.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 192.75, 'completions/min_terminated_length': 172.0, 'completions/max_terminated_length': 212.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 192.75, 'kl': 0.012864193704444915, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.41356563568115234, 'learning_rate': 1e-05, 'num_tokens': 4584.0, 'completions/mean_length': 216.0, 'completions/min_length': 179.0, 'completions/max_length': 270.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 216.0, 'completions/min_terminated_length': 179.0, 'completions/max_terminated_length': 270.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 216.0, 'kl': 0.024198288563638926, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.28420892357826233, 'learning_rate': 1e-05, 'num_tokens': 6438.0, 'completions/mean_length': 313.5, 'completions/min_length': 254.0, 'completions/max_length': 414.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 313.5, 'completions/min_terminated_length': 254.0, 'completions/max_terminated_length': 414.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': -0.625, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 313.5, 'kl': 0.06487508624559268, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.2472238838672638, 'learning_rate': 1e-05, 'num_tokens': 8299.0, 'completions/mean_length': 309.25, 'completions/min_length': 226.0, 'completions/max_length': 517.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 309.25, 'completions/min_terminated_length': 226.0, 'completions/max_terminated_length': 517.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 0.25, 'reward_std': 1.443375587463379, 'frac_reward_zero_std': 0.0, 'completion_length': 309.25, 'kl': 0.005471173906698823, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4231938421726227, 'learning_rate': 1e-05, 'num_tokens': 9417.0, 'completions/mean_length': 151.5, 'completions/min_length': 124.0, 'completions/max_length': 199.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 151.5, 'completions/min_terminated_length': 124.0, 'completions/max_terminated_length': 199.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 151.5, 'kl': 0.012313563143834472, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5610023140907288, 'learning_rate': 1e-05, 'num_tokens': 10645.0, 'completions/mean_length': 168.0, 'completions/min_length': 122.0, 'completions/max_length': 209.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 168.0, 'completions/min_terminated_length': 122.0, 'completions/max_terminated_length': 209.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': -0.25, 'reward_std': 0.5, 'frac_reward_zero_std': 0.0, 'completion_length': 168.0, 'kl': 0.02669762820005417, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.29174140095710754, 'learning_rate': 1e-05, 'num_tokens': 12058.0, 'completions/mean_length': 212.25, 'completions/min_length': 156.0, 'completions/max_length': 268.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 212.25, 'completions/min_terminated_length': 156.0, 'completions/max_terminated_length': 268.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': 0.625, 'reward_std': 0.9464846849441528, 'frac_reward_zero_std': 0.0, 'completion_length': 212.25, 'kl': 0.015315651893615723, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.30471062660217285, 'learning_rate': 1e-05, 'num_tokens': 13963.0, 'completions/mean_length': 345.25, 'completions/min_length': 193.0, 'completions/max_length': 536.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 345.25, 'completions/min_terminated_length': 193.0, 'completions/max_terminated_length': 536.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.75, 'reward_std': 1.3228756189346313, 'frac_reward_zero_std': 0.0, 'completion_length': 345.25, 'kl': 0.013159811991499737, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4606611728668213, 'learning_rate': 1e-05, 'num_tokens': 15064.0, 'completions/mean_length': 169.25, 'completions/min_length': 118.0, 'completions/max_length': 227.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 169.25, 'completions/min_terminated_length': 118.0, 'completions/max_terminated_length': 227.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 169.25, 'kl': 0.02123264060355723, 'epoch': 0.0}
{'train_runtime': 65.814, 'train_samples_per_second': 0.608, 'train_steps_per_second': 0.152, 'train_loss': 2.133883535861969e-05, 'epoch': 0.0}
[EP 0042] 2 | reward_mean=0.350 | 
*** stats:  {'episode_reward_mean': 0.35, 'episode_reward_last': 1.0, 'episode_reward_std_mean': 1.0484367251396178, 'episode_reward_trajectory': [-0.875, 1.5, 1.625, -0.625, 0.25, 1.0, -0.25, 0.625, -0.75, 1.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.0875, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.5354332089424133, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.2625, 'rewards/check_numbers/mean/last': 0.5, 'rewards/check_numbers/std/mean': 0.7199261426925659, 'rewards/check_numbers/std/last': 1.154700517654419}
Curr reward  0.35
All rewards  54.28749999999999
Cumulative rewards  [-22.275, 91.0125, -2.425, -5.6875, -6.3375]
Num plays  [6, 21, 6, 5, 5]
Mean rewards  [-3.7125, 4.333928571428571, -0.4041666666666666, -1.1375, -1.2675]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  73.32121112  78.38367177  71.55417528  71.55417528]
sampled base index:  3
potentials:  [156.76734354  73.32121112  78.38367177  71.55417528  71.55417528]
sampled base index:  3
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:06,  7.43s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:06,  7.43s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:12<00:46,  5.84s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:12<00:46,  5.84s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:38,  5.44s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:38,  5.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:33,  5.53s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:33,  5.53s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:29,  5.98s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:29,  5.98s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:34<00:22,  5.65s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:34<00:22,  5.65s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:41<00:17,  5.94s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:41<00:17,  5.94s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:46<00:11,  5.71s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:46<00:11,  5.71s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:55<00:06,  6.84s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:55<00:06,  6.84s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:02<00:00,  6.90s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:02<00:00,  6.90s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:04<00:00,  6.90s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:04<00:00,  6.45s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 4.225
wandb:      modelselection/base_2_episodic_reward 0.35
wandb:      modelselection/base_3_episodic_reward -0.875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 0.35
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_165852-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_170001-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.4472830891609192, 'learning_rate': 1e-06, 'num_tokens': 1917.0, 'completions/mean_length': 313.25, 'completions/min_length': 277.0, 'completions/max_length': 395.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 313.25, 'completions/min_terminated_length': 277.0, 'completions/max_terminated_length': 395.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -2.625, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 313.25, 'kl': 0.0006747992301825434, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5326058864593506, 'learning_rate': 1e-06, 'num_tokens': 3155.0, 'completions/mean_length': 184.5, 'completions/min_length': 158.0, 'completions/max_length': 211.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 184.5, 'completions/min_terminated_length': 158.0, 'completions/max_terminated_length': 211.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 184.5, 'kl': 0.0002955843592644669, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5245391130447388, 'learning_rate': 1e-06, 'num_tokens': 4335.0, 'completions/mean_length': 172.0, 'completions/min_length': 112.0, 'completions/max_length': 225.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 172.0, 'completions/min_terminated_length': 112.0, 'completions/max_terminated_length': 225.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.125, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 172.0, 'kl': 0.0003033148204849567, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3814907371997833, 'learning_rate': 1e-06, 'num_tokens': 5876.0, 'completions/mean_length': 235.25, 'completions/min_length': 162.0, 'completions/max_length': 275.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 235.25, 'completions/min_terminated_length': 162.0, 'completions/max_terminated_length': 275.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -1.25, 'reward_std': 0.28867512941360474, 'frac_reward_zero_std': 0.0, 'completion_length': 235.25, 'kl': 0.0003704274204210378, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.40365567803382874, 'learning_rate': 1e-06, 'num_tokens': 7688.0, 'completions/mean_length': 297.0, 'completions/min_length': 260.0, 'completions/max_length': 352.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 297.0, 'completions/min_terminated_length': 260.0, 'completions/max_terminated_length': 352.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -1.125, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 297.0, 'kl': 0.0005905669531784952, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4220640957355499, 'learning_rate': 1e-06, 'num_tokens': 8837.0, 'completions/mean_length': 159.25, 'completions/min_length': 98.0, 'completions/max_length': 228.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 159.25, 'completions/min_terminated_length': 98.0, 'completions/max_terminated_length': 228.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.375, 'reward_std': 1.6007810831069946, 'frac_reward_zero_std': 0.0, 'completion_length': 159.25, 'kl': 0.000424085563281551, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5629092454910278, 'learning_rate': 1e-06, 'num_tokens': 10200.0, 'completions/mean_length': 201.75, 'completions/min_length': 118.0, 'completions/max_length': 333.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 201.75, 'completions/min_terminated_length': 118.0, 'completions/max_terminated_length': 333.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 201.75, 'kl': 0.00039583461330039427, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.49766576290130615, 'learning_rate': 1e-06, 'num_tokens': 11530.0, 'completions/mean_length': 191.5, 'completions/min_length': 167.0, 'completions/max_length': 243.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 191.5, 'completions/min_terminated_length': 167.0, 'completions/max_terminated_length': 243.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 191.5, 'kl': 0.0003680979134514928, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4778309464454651, 'learning_rate': 1e-06, 'num_tokens': 13218.0, 'completions/mean_length': 291.0, 'completions/min_length': 161.0, 'completions/max_length': 527.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 291.0, 'completions/min_terminated_length': 161.0, 'completions/max_terminated_length': 527.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 291.0, 'kl': 0.000419814299675636, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.37644070386886597, 'learning_rate': 1e-06, 'num_tokens': 14431.0, 'completions/mean_length': 197.25, 'completions/min_length': 130.0, 'completions/max_length': 364.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 197.25, 'completions/min_terminated_length': 130.0, 'completions/max_terminated_length': 364.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 0.0, 'reward_std': 0.7071067690849304, 'frac_reward_zero_std': 0.0, 'completion_length': 197.25, 'kl': 0.0004754852125188336, 'epoch': 0.0}
{'train_runtime': 64.4582, 'train_samples_per_second': 0.621, 'train_steps_per_second': 0.155, 'train_loss': 4.325062036514282e-07, 'epoch': 0.0}
[EP 0043] 3 | reward_mean=-0.887 | 
*** stats:  {'episode_reward_mean': -0.8875, 'episode_reward_last': 0.0, 'episode_reward_std_mean': 0.8743364751338959, 'episode_reward_trajectory': [-2.625, -0.625, 0.125, -1.25, -1.125, -0.375, -0.25, -0.625, -2.125, 0.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.15, 'rewards/match_format_approximately/mean/last': -0.625, 'rewards/match_format_approximately/std/mean': 0.5724744915962219, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.2625, 'rewards/check_numbers/mean/last': 0.625, 'rewards/check_numbers/std/mean': 0.5783553063869477, 'rewards/check_numbers/std/last': 1.0307763814926147}
Curr reward  -0.8875
All rewards  53.399999999999984
Cumulative rewards  [-22.275, 91.0125, -2.425, -6.575, -6.3375]
Num plays  [6, 21, 6, 6, 5]
Mean rewards  [-3.7125, 4.333928571428571, -0.4041666666666666, -1.0958333333333334, -1.2675]
Balancing probabilities  [0, 0, 0, 1, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  73.32121112  78.38367177  78.38367177  71.55417528]
sampled base index:  4
potentials:  [156.76734354  73.32121112  78.38367177  78.38367177  71.55417528]
sampled base index:  4
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.34s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.34s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:19<01:13,  9.15s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:19<01:13,  9.15s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:24<00:52,  7.56s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:24<00:52,  7.56s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:32<00:44,  7.41s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:32<00:44,  7.41s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:42<00:42,  8.47s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:42<00:42,  8.47s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:46<00:28,  7.04s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:46<00:28,  7.04s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:53<00:20,  6.88s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:53<00:20,  6.88s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:58<00:12,  6.34s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:58<00:12,  6.34s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:03<00:05,  5.81s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:03<00:05,  5.81s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:08<00:00,  5.57s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:08<00:00,  5.57s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:09<00:00,  5.57s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:09<00:00,  6.99s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_3_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 4.225
wandb:      modelselection/base_2_episodic_reward 0.35
wandb:      modelselection/base_3_episodic_reward -0.8875
wandb:      modelselection/base_4_episodic_reward -1.125
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -0.8875
wandb:       modelselection/selected_base_learner 3
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_170001-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_170115-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.43234190344810486, 'learning_rate': 1e-07, 'num_tokens': 2377.0, 'completions/mean_length': 428.25, 'completions/min_length': 203.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 325.66668701171875, 'completions/min_terminated_length': 203.0, 'completions/max_terminated_length': 467.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 428.25, 'kl': 0.0004806190627277829, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3488021492958069, 'learning_rate': 1e-07, 'num_tokens': 3800.0, 'completions/mean_length': 230.75, 'completions/min_length': 142.0, 'completions/max_length': 360.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 230.75, 'completions/min_terminated_length': 142.0, 'completions/max_terminated_length': 360.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 230.75, 'kl': 0.00042956201650667936, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4094196856021881, 'learning_rate': 1e-07, 'num_tokens': 5080.0, 'completions/mean_length': 197.0, 'completions/min_length': 151.0, 'completions/max_length': 274.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 197.0, 'completions/min_terminated_length': 151.0, 'completions/max_terminated_length': 274.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 197.0, 'kl': 0.0002814858926285524, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.31773367524147034, 'learning_rate': 1e-07, 'num_tokens': 6768.0, 'completions/mean_length': 272.0, 'completions/min_length': 224.0, 'completions/max_length': 380.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 272.0, 'completions/min_terminated_length': 224.0, 'completions/max_terminated_length': 380.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 272.0, 'kl': 0.00031754979136167094, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.29852089285850525, 'learning_rate': 1e-07, 'num_tokens': 8748.0, 'completions/mean_length': 339.0, 'completions/min_length': 229.0, 'completions/max_length': 595.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 339.0, 'completions/min_terminated_length': 229.0, 'completions/max_terminated_length': 595.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 339.0, 'kl': 0.0003217778976249974, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.45560115575790405, 'learning_rate': 1e-07, 'num_tokens': 9766.0, 'completions/mean_length': 126.5, 'completions/min_length': 92.0, 'completions/max_length': 179.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 126.5, 'completions/min_terminated_length': 92.0, 'completions/max_terminated_length': 179.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.0, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 126.5, 'kl': 0.00036341440863907337, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5049179792404175, 'learning_rate': 1e-07, 'num_tokens': 11152.0, 'completions/mean_length': 207.5, 'completions/min_length': 132.0, 'completions/max_length': 334.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 207.5, 'completions/min_terminated_length': 132.0, 'completions/max_terminated_length': 334.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 207.5, 'kl': 0.0005548569533857517, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.37624430656433105, 'learning_rate': 1e-07, 'num_tokens': 12562.0, 'completions/mean_length': 211.5, 'completions/min_length': 167.0, 'completions/max_length': 242.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 211.5, 'completions/min_terminated_length': 167.0, 'completions/max_terminated_length': 242.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.0, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 211.5, 'kl': 0.0003471811978670303, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.34344956278800964, 'learning_rate': 1e-07, 'num_tokens': 13824.0, 'completions/mean_length': 184.5, 'completions/min_length': 149.0, 'completions/max_length': 206.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 184.5, 'completions/min_terminated_length': 149.0, 'completions/max_terminated_length': 206.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 0.125, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 184.5, 'kl': 0.00039812885734136216, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5374797582626343, 'learning_rate': 1e-07, 'num_tokens': 14904.0, 'completions/mean_length': 164.0, 'completions/min_length': 136.0, 'completions/max_length': 231.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 164.0, 'completions/min_terminated_length': 136.0, 'completions/max_terminated_length': 231.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 164.0, 'kl': 0.0005647612124448642, 'epoch': 0.0}
{'train_runtime': 69.9442, 'train_samples_per_second': 0.572, 'train_steps_per_second': 0.143, 'train_loss': 3.9861319862666277e-07, 'epoch': 0.0}
[EP 0044] 4 | reward_mean=-0.988 | 
*** stats:  {'episode_reward_mean': -0.9875, 'episode_reward_last': -0.75, 'episode_reward_std_mean': 1.0979884743690491, 'episode_reward_trajectory': [-2.125, -1.375, -0.625, -1.0, -1.75, -1.0, -0.375, -1.0, 0.125, -0.75], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.225, 'rewards/match_format_approximately/mean/last': -0.625, 'rewards/match_format_approximately/std/mean': 0.8501655876636505, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.2375, 'rewards/check_numbers/mean/last': -0.125, 'rewards/check_numbers/std/mean': 0.41160253882408143, 'rewards/check_numbers/std/last': 0.25}
Curr reward  -0.9875
All rewards  52.41249999999999
Cumulative rewards  [-22.275, 91.0125, -2.425, -6.575, -7.325]
Num plays  [6, 21, 6, 6, 6]
Mean rewards  [-3.7125, 4.333928571428571, -0.4041666666666666, -1.0958333333333334, -1.2208333333333334]
Balancing probabilities  [0, 0, 0, 0, 1]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  73.32121112  78.38367177  78.38367177  78.38367177]
sampled base index:  1
potentials:  [156.76734354  73.32121112  78.38367177  78.38367177  78.38367177]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.33s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.33s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:37, 12.19s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:37, 12.19s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:30<01:05,  9.29s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:30<01:05,  9.29s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:38<00:53,  8.84s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:38<00:53,  8.84s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:50<00:50, 10.10s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:50<00:50, 10.10s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:55<00:32,  8.24s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:55<00:32,  8.24s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:07<00:28,  9.59s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:07<00:28,  9.59s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:20<00:20, 10.50s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:20<00:20, 10.50s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:32<00:11, 11.07s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:32<00:11, 11.07s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:36<00:00,  9.03s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:36<00:00,  9.03s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:38<00:00,  9.03s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:38<00:00,  9.87s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_4_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 4.225
wandb:      modelselection/base_2_episodic_reward 0.35
wandb:      modelselection/base_3_episodic_reward -0.8875
wandb:      modelselection/base_4_episodic_reward -0.9875
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -0.9875
wandb:       modelselection/selected_base_learner 4
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_170115-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_170258-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0014, 'grad_norm': 1.8243508338928223, 'learning_rate': 0.0001, 'num_tokens': 3253.0, 'completions/mean_length': 647.25, 'completions/min_length': 381.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 381.0, 'completions/min_terminated_length': 381.0, 'completions/max_terminated_length': 381.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': 0.125, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 647.25, 'kl': 1.3830017372965813, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.48563718795776367, 'learning_rate': 0.0001, 'num_tokens': 5984.0, 'completions/mean_length': 557.75, 'completions/min_length': 378.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 379.5, 'completions/min_terminated_length': 378.0, 'completions/max_terminated_length': 381.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 0.8660253882408142, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 2.75, 'reward_std': 6.062177658081055, 'frac_reward_zero_std': 0.0, 'completion_length': 557.75, 'kl': 0.5161388739943504, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.0014949869364500046, 'learning_rate': 0.0001, 'num_tokens': 7445.0, 'completions/mean_length': 242.25, 'completions/min_length': 198.0, 'completions/max_length': 289.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 242.25, 'completions/min_terminated_length': 198.0, 'completions/max_terminated_length': 289.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 242.25, 'kl': 0.40222394466400146, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.297863632440567, 'learning_rate': 0.0001, 'num_tokens': 9670.0, 'completions/mean_length': 406.25, 'completions/min_length': 338.0, 'completions/max_length': 446.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 406.25, 'completions/min_terminated_length': 338.0, 'completions/max_terminated_length': 446.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.75, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 4.25, 'reward_std': 2.5, 'frac_reward_zero_std': 0.0, 'completion_length': 406.25, 'kl': 0.22034164518117905, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.005760997533798218, 'learning_rate': 0.0001, 'num_tokens': 13238.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.6096396520733833, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.004230014514178038, 'learning_rate': 0.0001, 'num_tokens': 14455.0, 'completions/mean_length': 176.25, 'completions/min_length': 163.0, 'completions/max_length': 204.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 176.25, 'completions/min_terminated_length': 163.0, 'completions/max_terminated_length': 204.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 176.25, 'kl': 0.30460649356245995, 'epoch': 0.0}
{'loss': 0.0013, 'grad_norm': 0.052357450127601624, 'learning_rate': 0.0001, 'num_tokens': 17955.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.2549340426921844, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 1.419740915298462, 'learning_rate': 0.0001, 'num_tokens': 20061.0, 'completions/mean_length': 385.5, 'completions/min_length': 229.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 268.66668701171875, 'completions/min_terminated_length': 229.0, 'completions/max_terminated_length': 312.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 1.125, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 5.375, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 385.5, 'kl': 0.5342038497328758, 'epoch': 0.0}
{'loss': 0.0015, 'grad_norm': 0.8634535670280457, 'learning_rate': 0.0001, 'num_tokens': 23119.0, 'completions/mean_length': 633.5, 'completions/min_length': 326.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 326.0, 'completions/min_terminated_length': 326.0, 'completions/max_terminated_length': 326.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': 0.125, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 633.5, 'kl': 1.5390921831130981, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.007163256872445345, 'learning_rate': 0.0001, 'num_tokens': 24237.0, 'completions/mean_length': 173.5, 'completions/min_length': 160.0, 'completions/max_length': 194.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 173.5, 'completions/min_terminated_length': 160.0, 'completions/max_terminated_length': 194.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 173.5, 'kl': 0.5428762584924698, 'epoch': 0.0}
{'train_runtime': 98.6733, 'train_samples_per_second': 0.405, 'train_steps_per_second': 0.101, 'train_loss': 0.0007307154242880643, 'epoch': 0.0}
[EP 0045] 1 | reward_mean=3.163 | 
*** stats:  {'episode_reward_mean': 3.1625, 'episode_reward_last': 8.0, 'episode_reward_std_mean': 2.4312177658081056, 'episode_reward_trajectory': [0.125, 2.75, 8.0, 4.25, -2.5, 8.0, -2.5, 5.375, 0.125, 8.0], 'rewards/match_format_exactly/mean/mean': 1.725, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.6232050776481628, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.0875, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.9348076105117797, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.6375, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.4616025388240814, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.7125, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.41160253882408143, 'rewards/check_numbers/std/last': 0.0}
Curr reward  3.1625
All rewards  55.57499999999999
Cumulative rewards  [-22.275, 94.175, -2.425, -6.575, -7.325]
Num plays  [6, 22, 6, 6, 6]
Mean rewards  [-3.7125, 4.280681818181818, -0.4041666666666666, -1.0958333333333334, -1.2208333333333334]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  75.04665216  78.38367177  78.38367177  78.38367177]
sampled base index:  1
potentials:  [156.76734354  75.04665216  78.38367177  78.38367177  78.38367177]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.17s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.17s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.09s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.09s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:31<01:08,  9.77s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:31<01:08,  9.77s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:43<01:04, 10.70s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:43<01:04, 10.70s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:55<00:56, 11.21s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:55<00:56, 11.21s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:00<00:36,  9.08s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:00<00:36,  9.08s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:12<00:30, 10.06s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:12<00:30, 10.06s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:18<00:17,  8.82s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:18<00:17,  8.82s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:29<00:09,  9.39s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:29<00:09,  9.39s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:34<00:00,  7.97s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:34<00:00,  7.97s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:35<00:00,  7.97s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:35<00:00,  9.59s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 3.1625
wandb:      modelselection/base_2_episodic_reward 0.35
wandb:      modelselection/base_3_episodic_reward -0.8875
wandb:      modelselection/base_4_episodic_reward -0.9875
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 3.1625
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_170258-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_170438-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0067, 'grad_norm': 2.7849056720733643, 'learning_rate': 0.0001, 'num_tokens': 3253.0, 'completions/mean_length': 647.25, 'completions/min_length': 381.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 381.0, 'completions/min_terminated_length': 381.0, 'completions/max_terminated_length': 381.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': 0.125, 'reward_std': 5.25, 'frac_reward_zero_std': 0.0, 'completion_length': 647.25, 'kl': 6.652272745966911, 'epoch': 0.0}
{'loss': 0.001, 'grad_norm': 1.2954922914505005, 'learning_rate': 0.0001, 'num_tokens': 5785.0, 'completions/mean_length': 508.0, 'completions/min_length': 299.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 432.0, 'completions/min_terminated_length': 299.0, 'completions/max_terminated_length': 593.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 1.4361406564712524, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 4.125, 'reward_std': 5.006246089935303, 'frac_reward_zero_std': 0.0, 'completion_length': 508.0, 'kl': 1.0424688756465912, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.0026743325870484114, 'learning_rate': 0.0001, 'num_tokens': 7283.0, 'completions/mean_length': 251.5, 'completions/min_length': 187.0, 'completions/max_length': 379.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 251.5, 'completions/min_terminated_length': 187.0, 'completions/max_terminated_length': 379.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 251.5, 'kl': 0.4774950072169304, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.33882638812065125, 'learning_rate': 0.0001, 'num_tokens': 10212.0, 'completions/mean_length': 582.25, 'completions/min_length': 337.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 531.0, 'completions/min_terminated_length': 337.0, 'completions/max_terminated_length': 684.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': -0.75, 'rewards/check_answer/std': 0.8660253882408142, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': 0.25, 'reward_std': 3.175426483154297, 'frac_reward_zero_std': 0.0, 'completion_length': 582.25, 'kl': 0.2489461675286293, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0016075560124590993, 'learning_rate': 0.0001, 'num_tokens': 13780.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.32108185440301895, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.004618206527084112, 'learning_rate': 0.0001, 'num_tokens': 15148.0, 'completions/mean_length': 214.0, 'completions/min_length': 178.0, 'completions/max_length': 236.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 214.0, 'completions/min_terminated_length': 178.0, 'completions/max_terminated_length': 236.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 214.0, 'kl': 0.36178790777921677, 'epoch': 0.0}
{'loss': 0.0012, 'grad_norm': 0.533720850944519, 'learning_rate': 0.0001, 'num_tokens': 17725.0, 'completions/mean_length': 505.25, 'completions/min_length': 266.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 428.3333435058594, 'completions/min_terminated_length': 266.0, 'completions/max_terminated_length': 582.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': -0.5, 'rewards/check_answer/std': 1.2247449159622192, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': 2.25, 'reward_std': 3.3788559436798096, 'frac_reward_zero_std': 0.0, 'completion_length': 505.25, 'kl': 1.1956480294466019, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.2830831706523895, 'learning_rate': 0.0001, 'num_tokens': 19520.0, 'completions/mean_length': 307.75, 'completions/min_length': 296.0, 'completions/max_length': 320.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 307.75, 'completions/min_terminated_length': 296.0, 'completions/max_terminated_length': 320.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.75, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 4.25, 'reward_std': 2.5, 'frac_reward_zero_std': 0.0, 'completion_length': 307.75, 'kl': 0.31390462070703506, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.3519030213356018, 'learning_rate': 0.0001, 'num_tokens': 21467.0, 'completions/mean_length': 355.75, 'completions/min_length': 228.0, 'completions/max_length': 633.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 355.75, 'completions/min_terminated_length': 228.0, 'completions/max_terminated_length': 633.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 6.75, 'reward_std': 2.5, 'frac_reward_zero_std': 0.0, 'completion_length': 355.75, 'kl': 0.4470203369855881, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.001234877505339682, 'learning_rate': 0.0001, 'num_tokens': 22692.0, 'completions/mean_length': 200.25, 'completions/min_length': 187.0, 'completions/max_length': 227.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 200.25, 'completions/min_terminated_length': 187.0, 'completions/max_terminated_length': 227.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 200.25, 'kl': 0.3734161853790283, 'epoch': 0.0}
{'train_runtime': 95.8163, 'train_samples_per_second': 0.417, 'train_steps_per_second': 0.104, 'train_loss': 0.0011433956096880138, 'epoch': 0.0}
[EP 0046] 1 | reward_mean=3.925 | 
*** stats:  {'episode_reward_mean': 3.925, 'episode_reward_last': 8.0, 'episode_reward_std_mean': 2.1810528516769407, 'episode_reward_trajectory': [0.125, 4.125, 8.0, 0.25, -2.5, 8.0, 2.25, 4.25, 6.75, 8.0], 'rewards/match_format_exactly/mean/mean': 2.175, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.6232050776481628, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.7625, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.9348076105117797, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.4, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.7276910960674285, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.5875, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.4319451510906219, 'rewards/check_numbers/std/last': 0.0}
Curr reward  3.925
All rewards  59.499999999999986
Cumulative rewards  [-22.275, 98.1, -2.425, -6.575, -7.325]
Num plays  [6, 23, 6, 6, 6]
Mean rewards  [-3.7125, 4.265217391304348, -0.4041666666666666, -1.0958333333333334, -1.2208333333333334]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  76.73330437  78.38367177  78.38367177  78.38367177]
sampled base index:  1
potentials:  [156.76734354  76.73330437  78.38367177  78.38367177  78.38367177]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:08<01:20,  8.91s/it]                                               10%|â–ˆ         | 1/10 [00:08<01:20,  8.91s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:18<01:15,  9.50s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:18<01:15,  9.50s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:51,  7.40s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:51,  7.40s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:30<00:43,  7.32s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:30<00:43,  7.32s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:43<00:45,  9.15s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:43<00:45,  9.15s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:47<00:30,  7.58s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:47<00:30,  7.58s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:57<00:24,  8.22s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:57<00:24,  8.22s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:03<00:15,  7.67s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:03<00:15,  7.67s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:10<00:07,  7.29s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:10<00:07,  7.29s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:16<00:00,  7.04s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:16<00:00,  7.04s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:18<00:00,  7.04s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:18<00:00,  7.85s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 3.925
wandb:      modelselection/base_2_episodic_reward 0.35
wandb:      modelselection/base_3_episodic_reward -0.8875
wandb:      modelselection/base_4_episodic_reward -0.9875
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 3.925
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_170438-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_170600-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0005, 'grad_norm': 0.38897964358329773, 'learning_rate': 0.0001, 'num_tokens': 2161.0, 'completions/mean_length': 374.25, 'completions/min_length': 242.0, 'completions/max_length': 494.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 374.25, 'completions/min_terminated_length': 242.0, 'completions/max_terminated_length': 494.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.5, 'rewards/check_answer/std': 1.3540064096450806, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 5.5, 'reward_std': 2.041241407394409, 'frac_reward_zero_std': 0.0, 'completion_length': 374.25, 'kl': 0.5401294752955437, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.33823373913764954, 'learning_rate': 0.0001, 'num_tokens': 4453.0, 'completions/mean_length': 448.0, 'completions/min_length': 383.0, 'completions/max_length': 571.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 448.0, 'completions/min_terminated_length': 383.0, 'completions/max_terminated_length': 571.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.5, 'rewards/check_answer/std': 1.4142135381698608, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 6.0, 'reward_std': 2.4494898319244385, 'frac_reward_zero_std': 0.0, 'completion_length': 448.0, 'kl': 0.3697871118783951, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.46271082758903503, 'learning_rate': 0.0001, 'num_tokens': 5763.0, 'completions/mean_length': 204.5, 'completions/min_length': 180.0, 'completions/max_length': 224.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 204.5, 'completions/min_terminated_length': 180.0, 'completions/max_terminated_length': 224.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.375, 'rewards/check_answer/std': 0.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.375, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 204.5, 'kl': 0.4867732301354408, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.004047582857310772, 'learning_rate': 0.0001, 'num_tokens': 7639.0, 'completions/mean_length': 319.0, 'completions/min_length': 272.0, 'completions/max_length': 383.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 319.0, 'completions/min_terminated_length': 272.0, 'completions/max_terminated_length': 383.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 319.0, 'kl': 0.3320734240114689, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.37350594997406006, 'learning_rate': 0.0001, 'num_tokens': 10587.0, 'completions/mean_length': 581.0, 'completions/min_length': 427.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 529.3333740234375, 'completions/min_terminated_length': 427.0, 'completions/max_terminated_length': 581.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 1.0801235437393188, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': 2.75, 'reward_std': 3.662876844406128, 'frac_reward_zero_std': 0.0, 'completion_length': 581.0, 'kl': 0.5822496190667152, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0011519129620864987, 'learning_rate': 0.0001, 'num_tokens': 11874.0, 'completions/mean_length': 193.75, 'completions/min_length': 190.0, 'completions/max_length': 198.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 193.75, 'completions/min_terminated_length': 190.0, 'completions/max_terminated_length': 198.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 193.75, 'kl': 0.3098565712571144, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.0054632071405649185, 'learning_rate': 0.0001, 'num_tokens': 13521.0, 'completions/mean_length': 272.75, 'completions/min_length': 165.0, 'completions/max_length': 538.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 272.75, 'completions/min_terminated_length': 165.0, 'completions/max_terminated_length': 538.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 272.75, 'kl': 0.6464520916342735, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.34325480461120605, 'learning_rate': 0.0001, 'num_tokens': 15226.0, 'completions/mean_length': 285.25, 'completions/min_length': 237.0, 'completions/max_length': 328.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 285.25, 'completions/min_terminated_length': 237.0, 'completions/max_terminated_length': 328.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.75, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 4.25, 'reward_std': 2.5, 'frac_reward_zero_std': 0.0, 'completion_length': 285.25, 'kl': 0.49893756955862045, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.0014695990830659866, 'learning_rate': 0.0001, 'num_tokens': 16705.0, 'completions/mean_length': 238.75, 'completions/min_length': 163.0, 'completions/max_length': 331.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 238.75, 'completions/min_terminated_length': 163.0, 'completions/max_terminated_length': 331.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 238.75, 'kl': 0.48100773245096207, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.4925766885280609, 'learning_rate': 0.0001, 'num_tokens': 18183.0, 'completions/mean_length': 263.5, 'completions/min_length': 226.0, 'completions/max_length': 331.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 263.5, 'completions/min_terminated_length': 226.0, 'completions/max_terminated_length': 331.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 1.7320507764816284, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 5.5, 'reward_std': 2.886751174926758, 'frac_reward_zero_std': 0.0, 'completion_length': 263.5, 'kl': 0.4157864600419998, 'epoch': 0.0}
{'train_runtime': 78.5406, 'train_samples_per_second': 0.509, 'train_steps_per_second': 0.127, 'train_loss': 0.00046631334407720715, 'epoch': 0.0}
[EP 0047] 1 | reward_mean=5.338 | 
*** stats:  {'episode_reward_mean': 5.3375, 'episode_reward_last': 5.5, 'episode_reward_std_mean': 1.4790359258651733, 'episode_reward_trajectory': [5.5, 6.0, 7.375, 3.0, 2.75, 8.0, 3.0, 4.25, 8.0, 5.5], 'rewards/match_format_exactly/mean/mean': 2.925, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.15, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.8875, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.225, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.1625, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.7330394268035889, 'rewards/check_answer/std/last': 1.7320507764816284, 'rewards/check_numbers/mean/mean': 0.3625, 'rewards/check_numbers/mean/last': 0.5, 'rewards/check_numbers/std/mean': 0.5559401035308837, 'rewards/check_numbers/std/last': 1.154700517654419}
Curr reward  5.3375
All rewards  64.83749999999999
Cumulative rewards  [-22.275, 103.4375, -2.425, -6.575, -7.325]
Num plays  [6, 24, 6, 6, 6]
Mean rewards  [-3.7125, 4.309895833333333, -0.4041666666666666, -1.0958333333333334, -1.2208333333333334]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  78.38367177  78.38367177  78.38367177  78.38367177]
sampled base index:  1
potentials:  [156.76734354  78.38367177  78.38367177  78.38367177  78.38367177]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:09,  7.73s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:09,  7.73s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:16<01:06,  8.26s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:16<01:06,  8.26s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:46,  6.68s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:46,  6.68s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:26<00:38,  6.33s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:26<00:38,  6.33s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:35<00:35,  7.18s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:35<00:35,  7.18s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:39<00:24,  6.12s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:39<00:24,  6.12s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:46<00:18,  6.21s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:46<00:18,  6.21s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:50<00:11,  5.68s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:50<00:11,  5.68s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:54<00:05,  5.08s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:54<00:05,  5.08s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:58<00:00,  4.75s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:58<00:00,  4.75s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  4.75s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  6.01s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.3375
wandb:      modelselection/base_2_episodic_reward 0.35
wandb:      modelselection/base_3_episodic_reward -0.8875
wandb:      modelselection/base_4_episodic_reward -0.9875
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 5.3375
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_170600-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_170704-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0005, 'grad_norm': 0.506454586982727, 'learning_rate': 0.0001, 'num_tokens': 2073.0, 'completions/mean_length': 352.25, 'completions/min_length': 322.0, 'completions/max_length': 413.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 352.25, 'completions/min_terminated_length': 322.0, 'completions/max_terminated_length': 413.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.5, 'rewards/check_answer/std': 1.3540064096450806, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 5.5, 'reward_std': 2.041241407394409, 'frac_reward_zero_std': 0.0, 'completion_length': 352.25, 'kl': 0.5228681936860085, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.40685057640075684, 'learning_rate': 0.0001, 'num_tokens': 4243.0, 'completions/mean_length': 417.5, 'completions/min_length': 338.0, 'completions/max_length': 483.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 417.5, 'completions/min_terminated_length': 338.0, 'completions/max_terminated_length': 483.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.875, 'rewards/check_answer/std': 1.25, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.625, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 417.5, 'kl': 0.4397365152835846, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.577498733997345, 'learning_rate': 0.0001, 'num_tokens': 5476.0, 'completions/mean_length': 185.25, 'completions/min_length': 160.0, 'completions/max_length': 216.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 185.25, 'completions/min_terminated_length': 160.0, 'completions/max_terminated_length': 216.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 6.75, 'reward_std': 2.5, 'frac_reward_zero_std': 0.0, 'completion_length': 185.25, 'kl': 0.5269798263907433, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.4296213686466217, 'learning_rate': 0.0001, 'num_tokens': 7110.0, 'completions/mean_length': 258.5, 'completions/min_length': 231.0, 'completions/max_length': 286.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 258.5, 'completions/min_terminated_length': 231.0, 'completions/max_terminated_length': 286.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.75, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 4.25, 'reward_std': 2.5, 'frac_reward_zero_std': 0.0, 'completion_length': 258.5, 'kl': 0.30700575560331345, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.0028876650612801313, 'learning_rate': 0.0001, 'num_tokens': 9267.0, 'completions/mean_length': 383.25, 'completions/min_length': 299.0, 'completions/max_length': 481.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 383.25, 'completions/min_terminated_length': 299.0, 'completions/max_terminated_length': 481.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 383.25, 'kl': 0.4072391539812088, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0006572644342668355, 'learning_rate': 0.0001, 'num_tokens': 10382.0, 'completions/mean_length': 150.75, 'completions/min_length': 138.0, 'completions/max_length': 165.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 150.75, 'completions/min_terminated_length': 138.0, 'completions/max_terminated_length': 165.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 150.75, 'kl': 0.3130473792552948, 'epoch': 0.0}
{'loss': 0.0012, 'grad_norm': 1.0073834657669067, 'learning_rate': 0.0001, 'num_tokens': 11882.0, 'completions/mean_length': 236.0, 'completions/min_length': 156.0, 'completions/max_length': 328.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 236.0, 'completions/min_terminated_length': 156.0, 'completions/max_terminated_length': 328.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 1.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': -0.5, 'rewards/check_answer/std': 1.2247449159622192, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.875, 'reward_std': 2.25, 'frac_reward_zero_std': 0.0, 'completion_length': 236.0, 'kl': 1.2047961056232452, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.0071473633870482445, 'learning_rate': 0.0001, 'num_tokens': 13168.0, 'completions/mean_length': 180.5, 'completions/min_length': 143.0, 'completions/max_length': 199.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 180.5, 'completions/min_terminated_length': 143.0, 'completions/max_terminated_length': 199.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 180.5, 'kl': 0.40833546221256256, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.004795623943209648, 'learning_rate': 0.0001, 'num_tokens': 14225.0, 'completions/mean_length': 133.25, 'completions/min_length': 122.0, 'completions/max_length': 145.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 133.25, 'completions/min_terminated_length': 122.0, 'completions/max_terminated_length': 145.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 133.25, 'kl': 0.5478766113519669, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.003861822420731187, 'learning_rate': 0.0001, 'num_tokens': 15169.0, 'completions/mean_length': 130.0, 'completions/min_length': 101.0, 'completions/max_length': 162.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 130.0, 'completions/min_terminated_length': 101.0, 'completions/max_terminated_length': 162.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 130.0, 'kl': 0.5056694149971008, 'epoch': 0.0}
{'train_runtime': 60.1495, 'train_samples_per_second': 0.665, 'train_steps_per_second': 0.166, 'train_loss': 0.0005183584260521456, 'epoch': 0.0}
[EP 0048] 1 | reward_mean=5.800 | 
*** stats:  {'episode_reward_mean': 5.8, 'episode_reward_last': 8.0, 'episode_reward_std_mean': 1.0541241407394408, 'episode_reward_trajectory': [5.5, 3.625, 6.75, 4.25, 3.0, 8.0, 2.875, 8.0, 8.0, 8.0], 'rewards/match_format_exactly/mean/mean': 2.925, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.15, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.9625, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.075, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.3625, 'rewards/check_answer/mean/last': 1.5, 'rewards/check_answer/std/mean': 0.68287513256073, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.55, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.3, 'rewards/check_numbers/std/last': 0.0}
Curr reward  5.8
All rewards  70.63749999999999
Cumulative rewards  [-22.275, 109.2375, -2.425, -6.575, -7.325]
Num plays  [6, 25, 6, 6, 6]
Mean rewards  [-3.7125, 4.3694999999999995, -0.4041666666666666, -1.0958333333333334, -1.2208333333333334]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  80.          78.38367177  78.38367177  78.38367177]
sampled base index:  2
potentials:  [156.76734354  80.          78.38367177  78.38367177  78.38367177]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:06<00:57,  6.37s/it]                                               10%|â–ˆ         | 1/10 [00:06<00:57,  6.37s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:11<00:46,  5.83s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:11<00:46,  5.83s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:40,  5.82s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:40,  5.82s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:36,  6.09s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:36,  6.09s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:32,  6.50s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:32,  6.50s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:36<00:24,  6.01s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:36<00:24,  6.01s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:41<00:16,  5.66s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:41<00:16,  5.66s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:46<00:11,  5.51s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:46<00:11,  5.51s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:55<00:06,  6.46s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:55<00:06,  6.46s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  5.99s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  5.99s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  5.99s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.18s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.8
wandb:      modelselection/base_2_episodic_reward 0.35
wandb:      modelselection/base_3_episodic_reward -0.8875
wandb:      modelselection/base_4_episodic_reward -0.9875
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 5.8
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_170704-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_170810-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.39896637201309204, 'learning_rate': 1e-05, 'num_tokens': 1792.0, 'completions/mean_length': 282.0, 'completions/min_length': 237.0, 'completions/max_length': 325.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 282.0, 'completions/min_terminated_length': 237.0, 'completions/max_terminated_length': 325.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -0.5, 'reward_std': 1.3540064096450806, 'frac_reward_zero_std': 0.0, 'completion_length': 282.0, 'kl': 0.11537951650097966, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.36292946338653564, 'learning_rate': 1e-05, 'num_tokens': 3114.0, 'completions/mean_length': 205.5, 'completions/min_length': 164.0, 'completions/max_length': 263.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 205.5, 'completions/min_terminated_length': 164.0, 'completions/max_terminated_length': 263.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 205.5, 'kl': 0.024944160133600235, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.37143176794052124, 'learning_rate': 1e-05, 'num_tokens': 4402.0, 'completions/mean_length': 199.0, 'completions/min_length': 163.0, 'completions/max_length': 285.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 199.0, 'completions/min_terminated_length': 163.0, 'completions/max_terminated_length': 285.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': 0.125, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 199.0, 'kl': 0.016003295546397567, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4058156907558441, 'learning_rate': 1e-05, 'num_tokens': 5990.0, 'completions/mean_length': 247.0, 'completions/min_length': 174.0, 'completions/max_length': 338.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 247.0, 'completions/min_terminated_length': 174.0, 'completions/max_terminated_length': 338.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': 0.625, 'reward_std': 0.9464846849441528, 'frac_reward_zero_std': 0.0, 'completion_length': 247.0, 'kl': 0.012687589740380645, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3238094747066498, 'learning_rate': 1e-05, 'num_tokens': 7680.0, 'completions/mean_length': 266.5, 'completions/min_length': 203.0, 'completions/max_length': 380.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 266.5, 'completions/min_terminated_length': 203.0, 'completions/max_terminated_length': 380.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.875, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 266.5, 'kl': 0.03110468154773116, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.374297171831131, 'learning_rate': 1e-05, 'num_tokens': 8922.0, 'completions/mean_length': 182.5, 'completions/min_length': 118.0, 'completions/max_length': 236.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 182.5, 'completions/min_terminated_length': 118.0, 'completions/max_terminated_length': 236.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': 0.25, 'reward_std': 0.28867512941360474, 'frac_reward_zero_std': 0.0, 'completion_length': 182.5, 'kl': 0.017127533443272114, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.49452248215675354, 'learning_rate': 1e-05, 'num_tokens': 10190.0, 'completions/mean_length': 178.0, 'completions/min_length': 125.0, 'completions/max_length': 227.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 178.0, 'completions/min_terminated_length': 125.0, 'completions/max_terminated_length': 227.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 178.0, 'kl': 0.012816239846870303, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.2822631895542145, 'learning_rate': 1e-05, 'num_tokens': 11550.0, 'completions/mean_length': 199.0, 'completions/min_length': 135.0, 'completions/max_length': 247.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 199.0, 'completions/min_terminated_length': 135.0, 'completions/max_terminated_length': 247.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 199.0, 'kl': 0.011422721785493195, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.44193610548973083, 'learning_rate': 1e-05, 'num_tokens': 13229.0, 'completions/mean_length': 288.75, 'completions/min_length': 180.0, 'completions/max_length': 472.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 288.75, 'completions/min_terminated_length': 180.0, 'completions/max_terminated_length': 472.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': 0.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 288.75, 'kl': 0.02612704213242978, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.43117696046829224, 'learning_rate': 1e-05, 'num_tokens': 14338.0, 'completions/mean_length': 171.25, 'completions/min_length': 147.0, 'completions/max_length': 231.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 171.25, 'completions/min_terminated_length': 147.0, 'completions/max_terminated_length': 231.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 171.25, 'kl': 0.015829142765142024, 'epoch': 0.0}
{'train_runtime': 61.8348, 'train_samples_per_second': 0.647, 'train_steps_per_second': 0.162, 'train_loss': 2.831891179084778e-05, 'epoch': 0.0}
[EP 0049] 2 | reward_mean=0.688 | 
*** stats:  {'episode_reward_mean': 0.6875, 'episode_reward_last': 1.125, 'episode_reward_std_mean': 0.9342380940914154, 'episode_reward_trajectory': [-0.5, 1.125, 0.125, 0.625, 0.875, 0.25, 1.125, 1.625, 0.5, 1.125], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.275, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.36861406564712523, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.4125, 'rewards/check_numbers/mean/last': 0.625, 'rewards/check_numbers/std/mean': 0.6366164147853851, 'rewards/check_numbers/std/last': 1.0307763814926147}
Curr reward  0.6875
All rewards  71.32499999999999
Cumulative rewards  [-22.275, 109.2375, -1.7374999999999998, -6.575, -7.325]
Num plays  [6, 25, 7, 6, 6]
Mean rewards  [-3.7125, 4.3694999999999995, -0.2482142857142857, -1.0958333333333334, -1.2208333333333334]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  80.          84.66404195  78.38367177  78.38367177]
sampled base index:  3
potentials:  [156.76734354  80.          84.66404195  78.38367177  78.38367177]
sampled base index:  3
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.32s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.32s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:17<01:03,  7.88s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:17<01:03,  7.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:44,  6.40s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:44,  6.40s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:27<00:36,  6.14s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:27<00:36,  6.14s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:36<00:35,  7.09s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:36<00:35,  7.09s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:43<00:28,  7.06s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:43<00:28,  7.06s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:47<00:18,  6.10s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:47<00:18,  6.10s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:52<00:11,  5.90s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:52<00:11,  5.90s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:57<00:05,  5.62s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:57<00:05,  5.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:10<00:00,  7.65s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:10<00:00,  7.65s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:11<00:00,  7.65s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:11<00:00,  7.18s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.8
wandb:      modelselection/base_2_episodic_reward 0.6875
wandb:      modelselection/base_3_episodic_reward -0.8875
wandb:      modelselection/base_4_episodic_reward -0.9875
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 0.6875
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_170810-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_170926-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.7535803914070129, 'learning_rate': 1e-06, 'num_tokens': 2215.0, 'completions/mean_length': 387.75, 'completions/min_length': 160.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 271.66668701171875, 'completions/min_terminated_length': 160.0, 'completions/max_terminated_length': 452.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 387.75, 'kl': 0.0010040176057373174, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 3.563105929060839e-05, 'learning_rate': 1e-06, 'num_tokens': 3459.0, 'completions/mean_length': 186.0, 'completions/min_length': 142.0, 'completions/max_length': 217.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 186.0, 'completions/min_terminated_length': 142.0, 'completions/max_terminated_length': 217.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 186.0, 'kl': 0.00032134459615917876, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.6444371938705444, 'learning_rate': 1e-06, 'num_tokens': 4590.0, 'completions/mean_length': 159.75, 'completions/min_length': 126.0, 'completions/max_length': 208.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 159.75, 'completions/min_terminated_length': 126.0, 'completions/max_terminated_length': 208.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 159.75, 'kl': 0.00027197975214221515, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3260703384876251, 'learning_rate': 1e-06, 'num_tokens': 6223.0, 'completions/mean_length': 258.25, 'completions/min_length': 235.0, 'completions/max_length': 283.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 258.25, 'completions/min_terminated_length': 235.0, 'completions/max_terminated_length': 283.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 258.25, 'kl': 0.0004013029101770371, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.34522145986557007, 'learning_rate': 1e-06, 'num_tokens': 8317.0, 'completions/mean_length': 367.5, 'completions/min_length': 215.0, 'completions/max_length': 491.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 367.5, 'completions/min_terminated_length': 215.0, 'completions/max_terminated_length': 491.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.0, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 367.5, 'kl': 0.00028659016606980003, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5110487937927246, 'learning_rate': 1e-06, 'num_tokens': 9571.0, 'completions/mean_length': 185.5, 'completions/min_length': 115.0, 'completions/max_length': 366.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 185.5, 'completions/min_terminated_length': 115.0, 'completions/max_terminated_length': 366.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.375, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 185.5, 'kl': 0.0004433269386936445, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5839365124702454, 'learning_rate': 1e-06, 'num_tokens': 10679.0, 'completions/mean_length': 138.0, 'completions/min_length': 121.0, 'completions/max_length': 174.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 138.0, 'completions/min_terminated_length': 121.0, 'completions/max_terminated_length': 174.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 138.0, 'kl': 0.0005621072486974299, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5363813638687134, 'learning_rate': 1e-06, 'num_tokens': 11993.0, 'completions/mean_length': 187.5, 'completions/min_length': 149.0, 'completions/max_length': 264.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 187.5, 'completions/min_terminated_length': 149.0, 'completions/max_terminated_length': 264.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 187.5, 'kl': 0.0005320386371749919, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5586523413658142, 'learning_rate': 1e-06, 'num_tokens': 13310.0, 'completions/mean_length': 198.25, 'completions/min_length': 170.0, 'completions/max_length': 233.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 198.25, 'completions/min_terminated_length': 170.0, 'completions/max_terminated_length': 233.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 198.25, 'kl': 0.0005723406065953895, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3975123465061188, 'learning_rate': 1e-06, 'num_tokens': 14989.0, 'completions/mean_length': 313.75, 'completions/min_length': 135.0, 'completions/max_length': 726.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 313.75, 'completions/min_terminated_length': 135.0, 'completions/max_terminated_length': 726.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 313.75, 'kl': 0.0005940088522038423, 'epoch': 0.0}
{'train_runtime': 71.7895, 'train_samples_per_second': 0.557, 'train_steps_per_second': 0.139, 'train_loss': 5.022661014209006e-07, 'epoch': 0.0}
[EP 0050] 3 | reward_mean=-1.062 | 
*** stats:  {'episode_reward_mean': -1.0625, 'episode_reward_last': -1.375, 'episode_reward_std_mean': 0.889919227361679, 'episode_reward_trajectory': [-2.125, -1.0, -0.625, -0.375, -1.0, -1.375, -0.25, -1.375, -1.125, -1.375], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.2625, 'rewards/match_format_approximately/mean/last': -1.375, 'rewards/match_format_approximately/std/mean': 0.5988306701183319, 'rewards/match_format_approximately/std/last': 1.4361406564712524, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.2, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.42320507764816284, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -1.0625
All rewards  70.26249999999999
Cumulative rewards  [-22.275, 109.2375, -1.7374999999999998, -7.6375, -7.325]
Num plays  [6, 25, 7, 7, 6]
Mean rewards  [-3.7125, 4.3694999999999995, -0.2482142857142857, -1.0910714285714287, -1.2208333333333334]
Balancing probabilities  [0, 0, 0, 1, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  80.          84.66404195  84.66404195  78.38367177]
sampled base index:  4
potentials:  [156.76734354  80.          84.66404195  84.66404195  78.38367177]
sampled base index:  4
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:10<01:31, 10.15s/it]                                               10%|â–ˆ         | 1/10 [00:10<01:31, 10.15s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:14<00:55,  6.98s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:14<00:55,  6.98s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:41,  5.92s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:41,  5.92s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:25<00:36,  6.04s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:25<00:36,  6.04s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:33<00:32,  6.50s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:33<00:32,  6.50s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:37<00:22,  5.64s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:37<00:22,  5.64s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:43<00:17,  5.93s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:43<00:17,  5.93s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:48<00:11,  5.58s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:48<00:11,  5.58s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:55<00:05,  6.00s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:55<00:05,  6.00s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:59<00:00,  5.49s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:59<00:00,  5.49s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  5.49s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_3_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.8
wandb:      modelselection/base_2_episodic_reward 0.6875
wandb:      modelselection/base_3_episodic_reward -1.0625
wandb:      modelselection/base_4_episodic_reward -0.9875
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.0625
wandb:       modelselection/selected_base_learner 3
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_170926-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_171031-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.5684932470321655, 'learning_rate': 1e-07, 'num_tokens': 2216.0, 'completions/mean_length': 388.0, 'completions/min_length': 147.0, 'completions/max_length': 592.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 388.0, 'completions/min_terminated_length': 147.0, 'completions/max_terminated_length': 592.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 388.0, 'kl': 0.0005764851812273264, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.42274805903434753, 'learning_rate': 1e-07, 'num_tokens': 3465.0, 'completions/mean_length': 187.25, 'completions/min_length': 120.0, 'completions/max_length': 223.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 187.25, 'completions/min_terminated_length': 120.0, 'completions/max_terminated_length': 223.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 187.25, 'kl': 0.000483737705508247, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.47857317328453064, 'learning_rate': 1e-07, 'num_tokens': 4700.0, 'completions/mean_length': 185.75, 'completions/min_length': 126.0, 'completions/max_length': 217.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 185.75, 'completions/min_terminated_length': 126.0, 'completions/max_terminated_length': 217.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 0.125, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 185.75, 'kl': 0.00031504963408224285, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.333126425743103, 'learning_rate': 1e-07, 'num_tokens': 6478.0, 'completions/mean_length': 294.5, 'completions/min_length': 263.0, 'completions/max_length': 327.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 294.5, 'completions/min_terminated_length': 263.0, 'completions/max_terminated_length': 327.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -1.125, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 294.5, 'kl': 0.00027708384004654363, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3427280783653259, 'learning_rate': 1e-07, 'num_tokens': 8371.0, 'completions/mean_length': 317.25, 'completions/min_length': 237.0, 'completions/max_length': 400.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 317.25, 'completions/min_terminated_length': 237.0, 'completions/max_terminated_length': 400.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -2.25, 'reward_std': 1.3228756189346313, 'frac_reward_zero_std': 0.0, 'completion_length': 317.25, 'kl': 0.0004918036938761361, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4718421399593353, 'learning_rate': 1e-07, 'num_tokens': 9434.0, 'completions/mean_length': 137.75, 'completions/min_length': 113.0, 'completions/max_length': 171.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 137.75, 'completions/min_terminated_length': 113.0, 'completions/max_terminated_length': 171.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -0.875, 'reward_std': 1.1814539432525635, 'frac_reward_zero_std': 0.0, 'completion_length': 137.75, 'kl': 0.00047281872684834525, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.49713823199272156, 'learning_rate': 1e-07, 'num_tokens': 10806.0, 'completions/mean_length': 204.0, 'completions/min_length': 132.0, 'completions/max_length': 345.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 204.0, 'completions/min_terminated_length': 132.0, 'completions/max_terminated_length': 345.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 204.0, 'kl': 0.00035220372228650376, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3486235439777374, 'learning_rate': 1e-07, 'num_tokens': 12179.0, 'completions/mean_length': 202.25, 'completions/min_length': 164.0, 'completions/max_length': 227.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 202.25, 'completions/min_terminated_length': 164.0, 'completions/max_terminated_length': 227.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 202.25, 'kl': 0.0003293319168733433, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.34114187955856323, 'learning_rate': 1e-07, 'num_tokens': 13652.0, 'completions/mean_length': 237.25, 'completions/min_length': 188.0, 'completions/max_length': 371.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 237.25, 'completions/min_terminated_length': 188.0, 'completions/max_terminated_length': 371.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.375, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 237.25, 'kl': 0.0003142567366012372, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4282468557357788, 'learning_rate': 1e-07, 'num_tokens': 14777.0, 'completions/mean_length': 175.25, 'completions/min_length': 149.0, 'completions/max_length': 198.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 175.25, 'completions/min_terminated_length': 149.0, 'completions/max_terminated_length': 198.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.375, 'reward_std': 1.6007810831069946, 'frac_reward_zero_std': 0.0, 'completion_length': 175.25, 'kl': 0.0003800867634708993, 'epoch': 0.0}
{'train_runtime': 61.388, 'train_samples_per_second': 0.652, 'train_steps_per_second': 0.163, 'train_loss': 3.9844014168011197e-07, 'epoch': 0.0}
[EP 0051] 4 | reward_mean=-1.075 | 
*** stats:  {'episode_reward_mean': -1.075, 'episode_reward_last': -0.375, 'episode_reward_std_mean': 1.1699364900588989, 'episode_reward_trajectory': [-2.5, -1.375, 0.125, -1.125, -2.25, -0.875, -0.25, -0.75, -1.375, -0.375], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.3375, 'rewards/match_format_approximately/mean/last': -0.625, 'rewards/match_format_approximately/std/mean': 0.8713051617145539, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.2625, 'rewards/check_numbers/mean/last': 0.25, 'rewards/check_numbers/std/mean': 0.6136751294136047, 'rewards/check_numbers/std/last': 0.8660253882408142}
Curr reward  -1.075
All rewards  69.18749999999999
Cumulative rewards  [-22.275, 109.2375, -1.7374999999999998, -7.6375, -8.4]
Num plays  [6, 25, 7, 7, 7]
Mean rewards  [-3.7125, 4.3694999999999995, -0.2482142857142857, -1.0910714285714287, -1.2]
Balancing probabilities  [0, 0, 0, 0, 1]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  80.          84.66404195  84.66404195  84.66404195]
sampled base index:  1
potentials:  [156.76734354  80.          84.66404195  84.66404195  84.66404195]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:05<00:51,  5.68s/it]                                               10%|â–ˆ         | 1/10 [00:05<00:51,  5.68s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:10<00:43,  5.39s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:10<00:43,  5.39s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:59,  8.54s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:59,  8.54s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:28<00:43,  7.19s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:28<00:43,  7.19s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:34<00:34,  6.82s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:34<00:34,  6.82s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:38<00:22,  5.73s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:38<00:22,  5.73s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:42<00:16,  5.42s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:42<00:16,  5.42s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:47<00:10,  5.33s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:47<00:10,  5.33s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:51<00:04,  4.78s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:51<00:04,  4.78s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:55<00:00,  4.41s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:55<00:00,  4.41s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:56<00:00,  4.41s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:56<00:00,  5.68s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_4_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.8
wandb:      modelselection/base_2_episodic_reward 0.6875
wandb:      modelselection/base_3_episodic_reward -1.0625
wandb:      modelselection/base_4_episodic_reward -1.075
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.075
wandb:       modelselection/selected_base_learner 4
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_171031-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_171132-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0006, 'grad_norm': 0.6677663326263428, 'learning_rate': 0.0001, 'num_tokens': 1469.0, 'completions/mean_length': 201.25, 'completions/min_length': 171.0, 'completions/max_length': 280.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 201.25, 'completions/min_terminated_length': 171.0, 'completions/max_terminated_length': 280.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.875, 'rewards/check_answer/std': 1.25, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.625, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 201.25, 'kl': 0.5815160423517227, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.7316786050796509, 'learning_rate': 0.0001, 'num_tokens': 2847.0, 'completions/mean_length': 219.5, 'completions/min_length': 167.0, 'completions/max_length': 253.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 219.5, 'completions/min_terminated_length': 167.0, 'completions/max_terminated_length': 253.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.0, 'rewards/check_answer/std': 1.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 219.5, 'kl': 0.5314507782459259, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.6287531852722168, 'learning_rate': 0.0001, 'num_tokens': 4463.0, 'completions/mean_length': 281.0, 'completions/min_length': 113.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 129.33334350585938, 'completions/min_terminated_length': 113.0, 'completions/max_terminated_length': 142.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 1.0, 'rewards/check_answer/std': 0.7071067690849304, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 4.75, 'reward_std': 4.9749369621276855, 'frac_reward_zero_std': 0.0, 'completion_length': 281.0, 'kl': 0.8178399130702019, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.4449876844882965, 'learning_rate': 0.0001, 'num_tokens': 5916.0, 'completions/mean_length': 213.25, 'completions/min_length': 177.0, 'completions/max_length': 248.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 213.25, 'completions/min_terminated_length': 177.0, 'completions/max_terminated_length': 248.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.25, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 4.75, 'reward_std': 2.362907886505127, 'frac_reward_zero_std': 0.0, 'completion_length': 213.25, 'kl': 0.39294206351041794, 'epoch': 0.0}
{'loss': 0.0032, 'grad_norm': 0.3856830894947052, 'learning_rate': 0.0001, 'num_tokens': 7677.0, 'completions/mean_length': 284.25, 'completions/min_length': 253.0, 'completions/max_length': 319.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 284.25, 'completions/min_terminated_length': 253.0, 'completions/max_terminated_length': 319.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 284.25, 'kl': 3.2442459911108017, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.054925478994846344, 'learning_rate': 0.0001, 'num_tokens': 8698.0, 'completions/mean_length': 127.25, 'completions/min_length': 108.0, 'completions/max_length': 144.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 127.25, 'completions/min_terminated_length': 108.0, 'completions/max_terminated_length': 144.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 127.25, 'kl': 0.8149718418717384, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 1.2544357776641846, 'learning_rate': 0.0001, 'num_tokens': 9936.0, 'completions/mean_length': 170.5, 'completions/min_length': 125.0, 'completions/max_length': 224.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 170.5, 'completions/min_terminated_length': 125.0, 'completions/max_terminated_length': 224.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 1.3149778842926025, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 4.125, 'reward_std': 1.314977765083313, 'frac_reward_zero_std': 0.0, 'completion_length': 170.5, 'kl': 0.5882787853479385, 'epoch': 0.0}
{'loss': 0.0009, 'grad_norm': 0.6553595066070557, 'learning_rate': 0.0001, 'num_tokens': 11188.0, 'completions/mean_length': 172.0, 'completions/min_length': 128.0, 'completions/max_length': 248.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 172.0, 'completions/min_terminated_length': 128.0, 'completions/max_terminated_length': 248.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.75, 'rewards/check_answer/std': 1.5, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 4.25, 'reward_std': 2.5, 'frac_reward_zero_std': 0.0, 'completion_length': 172.0, 'kl': 0.9485517516732216, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.7499316334724426, 'learning_rate': 0.0001, 'num_tokens': 12220.0, 'completions/mean_length': 127.0, 'completions/min_length': 109.0, 'completions/max_length': 142.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 127.0, 'completions/min_terminated_length': 109.0, 'completions/max_terminated_length': 142.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 8.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 127.0, 'kl': 0.5160190612077713, 'epoch': 0.0}
{'loss': 0.0011, 'grad_norm': 1.0649244785308838, 'learning_rate': 0.0001, 'num_tokens': 12962.0, 'completions/mean_length': 79.5, 'completions/min_length': 19.0, 'completions/max_length': 140.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 79.5, 'completions/min_terminated_length': 19.0, 'completions/max_terminated_length': 140.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 1.375, 'rewards/check_answer/std': 2.136000871658325, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 5.75, 'reward_std': 4.173327922821045, 'frac_reward_zero_std': 0.0, 'completion_length': 79.5, 'kl': 1.0782329887151718, 'epoch': 0.0}
{'train_runtime': 56.8048, 'train_samples_per_second': 0.704, 'train_steps_per_second': 0.176, 'train_loss': 0.0009514082339592278, 'epoch': 0.0}
[EP 0052] 1 | reward_mean=5.013 | 
*** stats:  {'episode_reward_mean': 5.0125, 'episode_reward_last': 5.75, 'episode_reward_std_mean': 1.8326150536537171, 'episode_reward_trajectory': [3.625, 3.5, 4.75, 4.75, 3.0, 8.0, 4.125, 4.25, 8.375, 5.75], 'rewards/match_format_exactly/mean/mean': 2.925, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.15, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.775, 'rewards/match_format_approximately/mean/last': 0.875, 'rewards/match_format_approximately/std/mean': 0.36861406564712523, 'rewards/match_format_approximately/std/last': 1.4361406564712524, 'rewards/check_answer/mean/mean': 0.1, 'rewards/check_answer/mean/last': 1.375, 'rewards/check_answer/std/mean': 1.0158085525035858, 'rewards/check_answer/std/last': 2.136000871658325, 'rewards/check_numbers/mean/mean': 0.2125, 'rewards/check_numbers/mean/last': 0.5, 'rewards/check_numbers/std/mean': 0.41854768991470337, 'rewards/check_numbers/std/last': 1.154700517654419}
Curr reward  5.0125
All rewards  74.19999999999999
Cumulative rewards  [-22.275, 114.25, -1.7374999999999998, -7.6375, -8.4]
Num plays  [6, 26, 7, 7, 7]
Mean rewards  [-3.7125, 4.394230769230769, -0.2482142857142857, -1.0910714285714287, -1.2]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  81.58431222  84.66404195  84.66404195  84.66404195]
sampled base index:  1
potentials:  [156.76734354  81.58431222  84.66404195  84.66404195  84.66404195]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:05<00:49,  5.46s/it]                                               10%|â–ˆ         | 1/10 [00:05<00:49,  5.46s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:09<00:36,  4.52s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:09<00:36,  4.52s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:13<00:29,  4.17s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:13<00:29,  4.17s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:17<00:26,  4.35s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:17<00:26,  4.35s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:24<00:25,  5.13s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:24<00:25,  5.13s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:28<00:19,  4.86s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:28<00:19,  4.86s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:33<00:14,  4.76s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:33<00:14,  4.76s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:37<00:09,  4.67s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:37<00:09,  4.67s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:41<00:04,  4.51s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:41<00:04,  4.51s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:45<00:00,  4.14s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:45<00:00,  4.14s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:46<00:00,  4.14s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:46<00:00,  4.68s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.0125
wandb:      modelselection/base_2_episodic_reward 0.6875
wandb:      modelselection/base_3_episodic_reward -1.0625
wandb:      modelselection/base_4_episodic_reward -1.075
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 5.0125
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_171132-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_171223-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0007, 'grad_norm': 0.5973315238952637, 'learning_rate': 0.0001, 'num_tokens': 1373.0, 'completions/mean_length': 177.25, 'completions/min_length': 139.0, 'completions/max_length': 259.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 177.25, 'completions/min_terminated_length': 139.0, 'completions/max_terminated_length': 259.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.375, 'rewards/check_answer/std': 2.136000871658325, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 6.875, 'reward_std': 3.1983067989349365, 'frac_reward_zero_std': 0.0, 'completion_length': 177.25, 'kl': 0.6542795822024345, 'epoch': 0.0}
{'loss': 0.0009, 'grad_norm': 0.9260353446006775, 'learning_rate': 0.0001, 'num_tokens': 2453.0, 'completions/mean_length': 145.0, 'completions/min_length': 130.0, 'completions/max_length': 157.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 145.0, 'completions/min_terminated_length': 130.0, 'completions/max_terminated_length': 157.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 1.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 4.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 145.0, 'kl': 0.9221352338790894, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 1.0191280841827393, 'learning_rate': 0.0001, 'num_tokens': 3424.0, 'completions/mean_length': 119.75, 'completions/min_length': 99.0, 'completions/max_length': 149.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 119.75, 'completions/min_terminated_length': 99.0, 'completions/max_terminated_length': 149.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.375, 'rewards/check_answer/std': 1.25, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 4.875, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 119.75, 'kl': 0.6136563718318939, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.006920185871422291, 'learning_rate': 0.0001, 'num_tokens': 4774.0, 'completions/mean_length': 187.5, 'completions/min_length': 168.0, 'completions/max_length': 207.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 187.5, 'completions/min_terminated_length': 168.0, 'completions/max_terminated_length': 207.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 187.5, 'kl': 0.41622407734394073, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.005807858891785145, 'learning_rate': 0.0001, 'num_tokens': 6509.0, 'completions/mean_length': 277.75, 'completions/min_length': 228.0, 'completions/max_length': 336.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 277.75, 'completions/min_terminated_length': 228.0, 'completions/max_terminated_length': 336.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 277.75, 'kl': 0.5116213038563728, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.6860385537147522, 'learning_rate': 0.0001, 'num_tokens': 7653.0, 'completions/mean_length': 158.0, 'completions/min_length': 141.0, 'completions/max_length': 189.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 158.0, 'completions/min_terminated_length': 141.0, 'completions/max_terminated_length': 189.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 2.375, 'rewards/check_answer/std': 1.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 8.375, 'reward_std': 2.25, 'frac_reward_zero_std': 0.0, 'completion_length': 158.0, 'kl': 0.823729544878006, 'epoch': 0.0}
{'loss': 0.0013, 'grad_norm': 0.9134374856948853, 'learning_rate': 0.0001, 'num_tokens': 8902.0, 'completions/mean_length': 173.25, 'completions/min_length': 134.0, 'completions/max_length': 202.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 173.25, 'completions/min_terminated_length': 134.0, 'completions/max_terminated_length': 202.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.25, 'rewards/check_answer/std': 1.4433757066726685, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 4.25, 'reward_std': 1.443375587463379, 'frac_reward_zero_std': 0.0, 'completion_length': 173.25, 'kl': 1.2726489007472992, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.001516173593699932, 'learning_rate': 0.0001, 'num_tokens': 10211.0, 'completions/mean_length': 186.25, 'completions/min_length': 158.0, 'completions/max_length': 200.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 186.25, 'completions/min_terminated_length': 158.0, 'completions/max_terminated_length': 200.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 186.25, 'kl': 0.2897830493748188, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.015486077405512333, 'learning_rate': 0.0001, 'num_tokens': 11323.0, 'completions/mean_length': 147.0, 'completions/min_length': 125.0, 'completions/max_length': 176.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 147.0, 'completions/min_terminated_length': 125.0, 'completions/max_terminated_length': 176.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 147.0, 'kl': 0.8289904296398163, 'epoch': 0.0}
{'loss': 0.0009, 'grad_norm': 0.02219204604625702, 'learning_rate': 0.0001, 'num_tokens': 12192.0, 'completions/mean_length': 111.25, 'completions/min_length': 102.0, 'completions/max_length': 119.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 111.25, 'completions/min_terminated_length': 102.0, 'completions/max_terminated_length': 119.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 111.25, 'kl': 0.873873382806778, 'epoch': 0.0}
{'train_runtime': 46.8507, 'train_samples_per_second': 0.854, 'train_steps_per_second': 0.213, 'train_loss': 0.0007206878392025829, 'epoch': 0.0}
[EP 0053] 1 | reward_mean=6.338 | 
*** stats:  {'episode_reward_mean': 6.3375, 'episode_reward_last': 9.5, 'episode_reward_std_mean': 0.9141682386398315, 'episode_reward_trajectory': [6.875, 4.5, 4.875, 3.0, 3.0, 8.375, 4.25, 9.5, 9.5, 9.5], 'rewards/match_format_exactly/mean/mean': 3.0, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 2.0, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.9875, 'rewards/check_answer/mean/last': 3.0, 'rewards/check_answer/std/mean': 0.7079376578330994, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.35, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.2154700517654419, 'rewards/check_numbers/std/last': 0.0}
Curr reward  6.3375
All rewards  80.5375
Cumulative rewards  [-22.275, 120.5875, -1.7374999999999998, -7.6375, -8.4]
Num plays  [6, 27, 7, 7, 7]
Mean rewards  [-3.7125, 4.466203703703704, -0.2482142857142857, -1.0910714285714287, -1.2]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  83.13843876  84.66404195  84.66404195  84.66404195]
sampled base index:  1
potentials:  [156.76734354  83.13843876  84.66404195  84.66404195  84.66404195]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:05<00:50,  5.64s/it]                                               10%|â–ˆ         | 1/10 [00:05<00:50,  5.64s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:10<00:43,  5.45s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:10<00:43,  5.45s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:14<00:32,  4.62s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:14<00:32,  4.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:19<00:28,  4.81s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:19<00:28,  4.81s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:28<00:30,  6.19s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:28<00:30,  6.19s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:33<00:22,  5.70s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:33<00:22,  5.70s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:39<00:18,  6.03s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:39<00:18,  6.03s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:45<00:12,  6.06s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:45<00:12,  6.06s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:55<00:07,  7.13s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:55<00:07,  7.13s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:59<00:00,  6.14s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:59<00:00,  6.14s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.14s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.13s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 6.3375
wandb:      modelselection/base_2_episodic_reward 0.6875
wandb:      modelselection/base_3_episodic_reward -1.0625
wandb:      modelselection/base_4_episodic_reward -1.075
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 6.3375
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_171223-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_171328-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0007, 'grad_norm': 0.5983867049217224, 'learning_rate': 0.0001, 'num_tokens': 1606.0, 'completions/mean_length': 235.5, 'completions/min_length': 210.0, 'completions/max_length': 274.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 235.5, 'completions/min_terminated_length': 210.0, 'completions/max_terminated_length': 274.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.25, 'rewards/check_answer/std': 1.4433757066726685, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 4.25, 'reward_std': 1.443375587463379, 'frac_reward_zero_std': 0.0, 'completion_length': 235.5, 'kl': 0.6804392337799072, 'epoch': 0.0}
{'loss': 0.001, 'grad_norm': 0.02479558438062668, 'learning_rate': 0.0001, 'num_tokens': 2807.0, 'completions/mean_length': 175.25, 'completions/min_length': 118.0, 'completions/max_length': 254.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 175.25, 'completions/min_terminated_length': 118.0, 'completions/max_terminated_length': 254.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 175.25, 'kl': 0.9928407073020935, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.6011281609535217, 'learning_rate': 0.0001, 'num_tokens': 3797.0, 'completions/mean_length': 124.5, 'completions/min_length': 112.0, 'completions/max_length': 140.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 124.5, 'completions/min_terminated_length': 112.0, 'completions/max_terminated_length': 140.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 1.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 0.5, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 4.125, 'reward_std': 2.75, 'frac_reward_zero_std': 0.0, 'completion_length': 124.5, 'kl': 0.5797247439622879, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.012690606527030468, 'learning_rate': 0.0001, 'num_tokens': 5224.0, 'completions/mean_length': 206.75, 'completions/min_length': 176.0, 'completions/max_length': 239.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 206.75, 'completions/min_terminated_length': 176.0, 'completions/max_terminated_length': 239.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 206.75, 'kl': 0.4830520451068878, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.49480748176574707, 'learning_rate': 0.0001, 'num_tokens': 7447.0, 'completions/mean_length': 399.75, 'completions/min_length': 308.0, 'completions/max_length': 483.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 399.75, 'completions/min_terminated_length': 308.0, 'completions/max_terminated_length': 483.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.5, 'rewards/check_answer/std': 1.154700517654419, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 4.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 399.75, 'kl': 0.44833800196647644, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.0015889194328337908, 'learning_rate': 0.0001, 'num_tokens': 8707.0, 'completions/mean_length': 187.0, 'completions/min_length': 170.0, 'completions/max_length': 214.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 187.0, 'completions/min_terminated_length': 170.0, 'completions/max_terminated_length': 214.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 187.0, 'kl': 0.39077746123075485, 'epoch': 0.0}
{'loss': 0.001, 'grad_norm': 1.0565890073776245, 'learning_rate': 0.0001, 'num_tokens': 10206.0, 'completions/mean_length': 235.75, 'completions/min_length': 123.0, 'completions/max_length': 351.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 197.33334350585938, 'completions/min_terminated_length': 123.0, 'completions/max_terminated_length': 271.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': -1.125, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': 1.625, 'reward_std': 2.75, 'frac_reward_zero_std': 0.0, 'completion_length': 235.75, 'kl': 0.9979636818170547, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.5285969376564026, 'learning_rate': 0.0001, 'num_tokens': 11679.0, 'completions/mean_length': 227.25, 'completions/min_length': 154.0, 'completions/max_length': 311.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 227.25, 'completions/min_terminated_length': 154.0, 'completions/max_terminated_length': 311.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 2.598076105117798, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 6.25, 'reward_std': 3.752776622772217, 'frac_reward_zero_std': 0.0, 'completion_length': 227.25, 'kl': 0.5255050733685493, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.7733125686645508, 'learning_rate': 0.0001, 'num_tokens': 13338.0, 'completions/mean_length': 283.75, 'completions/min_length': 151.0, 'completions/max_length': 535.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 283.75, 'completions/min_terminated_length': 151.0, 'completions/max_terminated_length': 535.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 2.598076105117798, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 6.25, 'reward_std': 3.752776622772217, 'frac_reward_zero_std': 0.0, 'completion_length': 283.75, 'kl': 1.8252505958080292, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.009170733392238617, 'learning_rate': 0.0001, 'num_tokens': 14337.0, 'completions/mean_length': 143.75, 'completions/min_length': 132.0, 'completions/max_length': 161.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 143.75, 'completions/min_terminated_length': 132.0, 'completions/max_terminated_length': 161.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 143.75, 'kl': 0.5681555420160294, 'epoch': 0.0}
{'train_runtime': 61.3201, 'train_samples_per_second': 0.652, 'train_steps_per_second': 0.163, 'train_loss': 0.0007492004311643541, 'epoch': 0.0}
[EP 0054] 1 | reward_mean=5.150 | 
*** stats:  {'episode_reward_mean': 5.15, 'episode_reward_last': 9.5, 'episode_reward_std_mean': 1.5603629350662231, 'episode_reward_trajectory': [4.25, 3.0, 4.125, 3.0, 4.0, 9.5, 1.625, 6.25, 6.25, 9.5], 'rewards/match_format_exactly/mean/mean': 2.85, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.3, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.85, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.3, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.3375, 'rewards/check_answer/mean/last': 3.0, 'rewards/check_answer/std/mean': 0.9044228434562683, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.1125, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.2559401035308838, 'rewards/check_numbers/std/last': 0.0}
Curr reward  5.15
All rewards  85.6875
Cumulative rewards  [-22.275, 125.73750000000001, -1.7374999999999998, -7.6375, -8.4]
Num plays  [6, 28, 7, 7, 7]
Mean rewards  [-3.7125, 4.4906250000000005, -0.2482142857142857, -1.0910714285714287, -1.2]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  84.66404195  84.66404195  84.66404195  84.66404195]
sampled base index:  1
potentials:  [156.76734354  84.66404195  84.66404195  84.66404195  84.66404195]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:10,  7.84s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:10,  7.84s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:13<00:54,  6.85s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:13<00:54,  6.85s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:20<00:47,  6.79s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:20<00:47,  6.79s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:26<00:37,  6.25s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:26<00:37,  6.25s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:35<00:36,  7.31s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:35<00:36,  7.31s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:40<00:26,  6.59s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:40<00:26,  6.59s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:52<00:25,  8.39s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:52<00:25,  8.39s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:58<00:15,  7.59s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:58<00:15,  7.59s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:06<00:07,  7.73s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:06<00:07,  7.73s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:10<00:00,  6.68s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:10<00:00,  6.68s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:12<00:00,  6.68s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:12<00:00,  7.26s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.15
wandb:      modelselection/base_2_episodic_reward 0.6875
wandb:      modelselection/base_3_episodic_reward -1.0625
wandb:      modelselection/base_4_episodic_reward -1.075
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 5.15
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_171328-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_171444-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0006, 'grad_norm': 0.494148850440979, 'learning_rate': 0.0001, 'num_tokens': 2228.0, 'completions/mean_length': 391.0, 'completions/min_length': 370.0, 'completions/max_length': 436.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 391.0, 'completions/min_terminated_length': 370.0, 'completions/max_terminated_length': 436.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 1.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 6.5, 'reward_std': 2.0, 'frac_reward_zero_std': 0.0, 'completion_length': 391.0, 'kl': 0.6227906793355942, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.007075906731188297, 'learning_rate': 0.0001, 'num_tokens': 3746.0, 'completions/mean_length': 254.5, 'completions/min_length': 191.0, 'completions/max_length': 319.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 254.5, 'completions/min_terminated_length': 191.0, 'completions/max_terminated_length': 319.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 254.5, 'kl': 0.8450019508600235, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.5832820534706116, 'learning_rate': 0.0001, 'num_tokens': 5278.0, 'completions/mean_length': 260.0, 'completions/min_length': 197.0, 'completions/max_length': 361.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 260.0, 'completions/min_terminated_length': 197.0, 'completions/max_terminated_length': 361.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 2.598076105117798, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 6.25, 'reward_std': 3.752776622772217, 'frac_reward_zero_std': 0.0, 'completion_length': 260.0, 'kl': 0.8260415643453598, 'epoch': 0.0}
{'loss': 0.4243, 'grad_norm': 375.51690673828125, 'learning_rate': 0.0001, 'num_tokens': 6895.0, 'completions/mean_length': 254.25, 'completions/min_length': 238.0, 'completions/max_length': 269.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 254.25, 'completions/min_terminated_length': 238.0, 'completions/max_terminated_length': 269.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 4.625, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 254.25, 'kl': 424.29905097186565, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.41722559928894043, 'learning_rate': 0.0001, 'num_tokens': 9298.0, 'completions/mean_length': 444.75, 'completions/min_length': 392.0, 'completions/max_length': 526.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 444.75, 'completions/min_terminated_length': 392.0, 'completions/max_terminated_length': 526.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -0.5, 'rewards/check_answer/std': 1.154700517654419, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 4.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 444.75, 'kl': 0.3600398674607277, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0023406289983540773, 'learning_rate': 0.0001, 'num_tokens': 10652.0, 'completions/mean_length': 210.5, 'completions/min_length': 184.0, 'completions/max_length': 254.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 210.5, 'completions/min_terminated_length': 184.0, 'completions/max_terminated_length': 254.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 210.5, 'kl': 0.3242098316550255, 'epoch': 0.0}
{'loss': 0.0011, 'grad_norm': 0.0030648650135844946, 'learning_rate': 0.0001, 'num_tokens': 14152.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 589.0, 'kl': 1.0575783550739288, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.006167102139443159, 'learning_rate': 0.0001, 'num_tokens': 15708.0, 'completions/mean_length': 248.0, 'completions/min_length': 187.0, 'completions/max_length': 300.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 248.0, 'completions/min_terminated_length': 187.0, 'completions/max_terminated_length': 300.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 248.0, 'kl': 0.4032354801893234, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.40685781836509705, 'learning_rate': 0.0001, 'num_tokens': 17590.0, 'completions/mean_length': 339.5, 'completions/min_length': 281.0, 'completions/max_length': 453.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 339.5, 'completions/min_terminated_length': 281.0, 'completions/max_terminated_length': 453.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 2.0, 'rewards/check_answer/std': 1.154700517654419, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 7.5, 'reward_std': 2.309401035308838, 'frac_reward_zero_std': 0.0, 'completion_length': 339.5, 'kl': 0.4330895245075226, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.010485919192433357, 'learning_rate': 0.0001, 'num_tokens': 18757.0, 'completions/mean_length': 185.75, 'completions/min_length': 170.0, 'completions/max_length': 195.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 185.75, 'completions/min_terminated_length': 170.0, 'completions/max_terminated_length': 195.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 185.75, 'kl': 0.5103894397616386, 'epoch': 0.0}
{'train_runtime': 72.5695, 'train_samples_per_second': 0.551, 'train_steps_per_second': 0.138, 'train_loss': 0.04296814009721857, 'epoch': 0.0}
[EP 0055] 1 | reward_mean=5.787 | 
*** stats:  {'episode_reward_mean': 5.7875, 'episode_reward_last': 9.5, 'episode_reward_std_mean': 1.2466878175735474, 'episode_reward_trajectory': [6.5, 3.0, 6.25, 4.625, 4.0, 9.5, -2.5, 9.5, 7.5, 9.5], 'rewards/match_format_exactly/mean/mean': 2.7, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.55, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 1.0875, 'rewards/check_answer/mean/last': 3.0, 'rewards/check_answer/std/mean': 0.8157477140426636, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.45, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.4309401035308838, 'rewards/check_numbers/std/last': 0.0}
Curr reward  5.7875
All rewards  91.475
Cumulative rewards  [-22.275, 131.525, -1.7374999999999998, -7.6375, -8.4]
Num plays  [6, 29, 7, 7, 7]
Mean rewards  [-3.7125, 4.535344827586207, -0.2482142857142857, -1.0910714285714287, -1.2]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  86.16263691  84.66404195  84.66404195  84.66404195]
sampled base index:  2
potentials:  [156.76734354  86.16263691  84.66404195  84.66404195  84.66404195]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:07,  7.55s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:07,  7.55s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:12<00:46,  5.82s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:12<00:46,  5.82s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:44,  6.35s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:44,  6.35s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:27<00:41,  6.98s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:27<00:41,  6.98s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:33<00:34,  6.89s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:33<00:34,  6.89s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:37<00:23,  5.90s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:37<00:23,  5.90s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:41<00:15,  5.09s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:41<00:15,  5.09s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:46<00:10,  5.27s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:46<00:10,  5.27s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:52<00:05,  5.23s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:52<00:05,  5.23s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:57<00:00,  5.39s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:57<00:00,  5.39s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:59<00:00,  5.39s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:59<00:00,  5.95s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.7875
wandb:      modelselection/base_2_episodic_reward 0.6875
wandb:      modelselection/base_3_episodic_reward -1.0625
wandb:      modelselection/base_4_episodic_reward -1.075
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 5.7875
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_171444-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_171548-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.4212900698184967, 'learning_rate': 1e-05, 'num_tokens': 2113.0, 'completions/mean_length': 362.25, 'completions/min_length': 237.0, 'completions/max_length': 407.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 347.3333435058594, 'completions/min_terminated_length': 237.0, 'completions/max_terminated_length': 407.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 344.5, 'kl': 0.009445741539821029, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00011823603563243523, 'learning_rate': 1e-05, 'num_tokens': 3377.0, 'completions/mean_length': 191.0, 'completions/min_length': 181.0, 'completions/max_length': 207.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 191.0, 'completions/min_terminated_length': 181.0, 'completions/max_terminated_length': 207.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 191.0, 'kl': 0.014731206465512514, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.358703076839447, 'learning_rate': 1e-05, 'num_tokens': 5065.0, 'completions/mean_length': 299.0, 'completions/min_length': 171.0, 'completions/max_length': 369.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 299.0, 'completions/min_terminated_length': 171.0, 'completions/max_terminated_length': 369.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': 0.25, 'reward_std': 0.28867512941360474, 'frac_reward_zero_std': 0.0, 'completion_length': 299.0, 'kl': 0.012655087746679783, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.29767557978630066, 'learning_rate': 1e-05, 'num_tokens': 6998.0, 'completions/mean_length': 333.25, 'completions/min_length': 236.0, 'completions/max_length': 433.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 333.25, 'completions/min_terminated_length': 236.0, 'completions/max_terminated_length': 433.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': -0.625, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 333.25, 'kl': 0.012113113887608051, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.30425363779067993, 'learning_rate': 1e-05, 'num_tokens': 8824.0, 'completions/mean_length': 300.5, 'completions/min_length': 242.0, 'completions/max_length': 351.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 300.5, 'completions/min_terminated_length': 242.0, 'completions/max_terminated_length': 351.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 300.5, 'kl': 0.009478496969677508, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3905336260795593, 'learning_rate': 1e-05, 'num_tokens': 9935.0, 'completions/mean_length': 149.75, 'completions/min_length': 109.0, 'completions/max_length': 165.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 149.75, 'completions/min_terminated_length': 109.0, 'completions/max_terminated_length': 165.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 149.75, 'kl': 0.013775188708677888, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5967362523078918, 'learning_rate': 1e-05, 'num_tokens': 10953.0, 'completions/mean_length': 115.5, 'completions/min_length': 109.0, 'completions/max_length': 124.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 115.5, 'completions/min_terminated_length': 109.0, 'completions/max_terminated_length': 124.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 115.5, 'kl': 0.012831373722292483, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.26200777292251587, 'learning_rate': 1e-05, 'num_tokens': 12321.0, 'completions/mean_length': 201.0, 'completions/min_length': 146.0, 'completions/max_length': 277.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 201.0, 'completions/min_terminated_length': 146.0, 'completions/max_terminated_length': 277.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 201.0, 'kl': 0.012570013874210417, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.35399115085601807, 'learning_rate': 1e-05, 'num_tokens': 13642.0, 'completions/mean_length': 199.25, 'completions/min_length': 166.0, 'completions/max_length': 242.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 199.25, 'completions/min_terminated_length': 166.0, 'completions/max_terminated_length': 242.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 199.25, 'kl': 0.021561993518844247, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.43736353516578674, 'learning_rate': 1e-05, 'num_tokens': 14921.0, 'completions/mean_length': 213.75, 'completions/min_length': 166.0, 'completions/max_length': 286.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 213.75, 'completions/min_terminated_length': 166.0, 'completions/max_terminated_length': 286.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.25, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 213.75, 'kl': 0.02127049001865089, 'epoch': 0.0}
{'train_runtime': 59.512, 'train_samples_per_second': 0.672, 'train_steps_per_second': 0.168, 'train_loss': 1.4048955654288875e-05, 'epoch': 0.0}
[EP 0056] 2 | reward_mean=0.713 | 
*** stats:  {'episode_reward_mean': 0.7125, 'episode_reward_last': -0.25, 'episode_reward_std_mean': 0.8832278668880462, 'episode_reward_trajectory': [-0.25, 2.0, 0.25, -0.625, 1.125, 1.5, 1.5, 0.75, 1.125, -0.25], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.2375, 'rewards/match_format_approximately/mean/last': -0.625, 'rewards/match_format_approximately/std/mean': 0.44361406564712524, 'rewards/match_format_approximately/std/last': 1.4361406564712524, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.475, 'rewards/check_numbers/mean/last': 0.375, 'rewards/check_numbers/std/mean': 0.6435476899147033, 'rewards/check_numbers/std/last': 0.75}
Curr reward  0.7125
All rewards  92.1875
Cumulative rewards  [-22.275, 131.525, -1.025, -7.6375, -8.4]
Num plays  [6, 29, 8, 7, 7]
Mean rewards  [-3.7125, 4.535344827586207, -0.128125, -1.0910714285714287, -1.2]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  86.16263691  90.50966799  84.66404195  84.66404195]
sampled base index:  3
potentials:  [156.76734354  86.16263691  90.50966799  84.66404195  84.66404195]
sampled base index:  3
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.25s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.25s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:17<01:04,  8.11s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:17<01:04,  8.11s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:22<00:46,  6.71s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:22<00:46,  6.71s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:29<00:41,  6.96s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:29<00:41,  6.96s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:37<00:36,  7.22s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:37<00:36,  7.22s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:25,  6.46s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:25,  6.46s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:47<00:17,  5.83s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:47<00:17,  5.83s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:52<00:11,  5.56s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:52<00:11,  5.56s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:58<00:05,  5.89s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:58<00:05,  5.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:04<00:00,  5.88s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:04<00:00,  5.88s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:06<00:00,  5.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:06<00:00,  6.62s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.7875
wandb:      modelselection/base_2_episodic_reward 0.7125
wandb:      modelselection/base_3_episodic_reward -1.0625
wandb:      modelselection/base_4_episodic_reward -1.075
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 0.7125
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_171548-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_171658-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.47077834606170654, 'learning_rate': 1e-06, 'num_tokens': 2350.0, 'completions/mean_length': 421.5, 'completions/min_length': 277.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 316.66668701171875, 'completions/min_terminated_length': 277.0, 'completions/max_terminated_length': 344.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.875, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.875, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 421.5, 'kl': 0.0007875524534028955, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00029290225938893855, 'learning_rate': 1e-06, 'num_tokens': 3593.0, 'completions/mean_length': 185.75, 'completions/min_length': 142.0, 'completions/max_length': 254.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 185.75, 'completions/min_terminated_length': 142.0, 'completions/max_terminated_length': 254.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 185.75, 'kl': 0.0007397306835628115, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.48798510432243347, 'learning_rate': 1e-06, 'num_tokens': 4882.0, 'completions/mean_length': 199.25, 'completions/min_length': 131.0, 'completions/max_length': 244.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 199.25, 'completions/min_terminated_length': 131.0, 'completions/max_terminated_length': 244.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 199.25, 'kl': 0.0003809224290307611, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.27178001403808594, 'learning_rate': 1e-06, 'num_tokens': 6558.0, 'completions/mean_length': 269.0, 'completions/min_length': 201.0, 'completions/max_length': 403.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 269.0, 'completions/min_terminated_length': 201.0, 'completions/max_terminated_length': 403.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 269.0, 'kl': 0.00024952331295935437, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.2458837777376175, 'learning_rate': 1e-06, 'num_tokens': 8364.0, 'completions/mean_length': 295.5, 'completions/min_length': 225.0, 'completions/max_length': 422.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 295.5, 'completions/min_terminated_length': 225.0, 'completions/max_terminated_length': 422.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 295.5, 'kl': 0.00022848650041851215, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.44217947125434875, 'learning_rate': 1e-06, 'num_tokens': 9646.0, 'completions/mean_length': 192.5, 'completions/min_length': 155.0, 'completions/max_length': 238.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 192.5, 'completions/min_terminated_length': 155.0, 'completions/max_terminated_length': 238.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.75, 'reward_std': 0.5, 'frac_reward_zero_std': 0.0, 'completion_length': 192.5, 'kl': 0.0003499973281577695, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5172328948974609, 'learning_rate': 1e-06, 'num_tokens': 10787.0, 'completions/mean_length': 146.25, 'completions/min_length': 102.0, 'completions/max_length': 206.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 146.25, 'completions/min_terminated_length': 102.0, 'completions/max_terminated_length': 206.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 146.25, 'kl': 0.0005462815970531665, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4004684388637543, 'learning_rate': 1e-06, 'num_tokens': 12211.0, 'completions/mean_length': 215.0, 'completions/min_length': 199.0, 'completions/max_length': 238.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 215.0, 'completions/min_terminated_length': 199.0, 'completions/max_terminated_length': 238.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 215.0, 'kl': 0.0004101933373021893, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.36701440811157227, 'learning_rate': 1e-06, 'num_tokens': 13673.0, 'completions/mean_length': 234.5, 'completions/min_length': 179.0, 'completions/max_length': 351.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 234.5, 'completions/min_terminated_length': 179.0, 'completions/max_terminated_length': 351.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.25, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 234.5, 'kl': 0.0004506285986281, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.44151589274406433, 'learning_rate': 1e-06, 'num_tokens': 15057.0, 'completions/mean_length': 240.0, 'completions/min_length': 180.0, 'completions/max_length': 303.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 240.0, 'completions/min_terminated_length': 180.0, 'completions/max_terminated_length': 303.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.875, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 240.0, 'kl': 0.0004757469650940038, 'epoch': 0.0}
{'train_runtime': 66.2151, 'train_samples_per_second': 0.604, 'train_steps_per_second': 0.151, 'train_loss': 4.6214831854740624e-07, 'epoch': 0.0}
[EP 0057] 3 | reward_mean=-1.038 | 
*** stats:  {'episode_reward_mean': -1.0375, 'episode_reward_last': -1.875, 'episode_reward_std_mean': 0.6982050776481629, 'episode_reward_trajectory': [-2.875, -1.0, -0.625, -1.125, -1.375, -0.75, -0.25, -0.25, -0.25, -1.875], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.225, 'rewards/match_format_approximately/mean/last': -1.75, 'rewards/match_format_approximately/std/mean': 0.5090770304203034, 'rewards/match_format_approximately/std/last': 0.8660253882408142, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.1875, 'rewards/check_numbers/mean/last': -0.125, 'rewards/check_numbers/std/mean': 0.3982050776481628, 'rewards/check_numbers/std/last': 0.25}
Curr reward  -1.0375
All rewards  91.15
Cumulative rewards  [-22.275, 131.525, -1.025, -8.675, -8.4]
Num plays  [6, 29, 8, 8, 7]
Mean rewards  [-3.7125, 4.535344827586207, -0.128125, -1.084375, -1.2]
Balancing probabilities  [0, 0, 0, 1, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  86.16263691  90.50966799  90.50966799  84.66404195]
sampled base index:  4
potentials:  [156.76734354  86.16263691  90.50966799  90.50966799  84.66404195]
sampled base index:  4
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:08<01:18,  8.69s/it]                                               10%|â–ˆ         | 1/10 [00:08<01:18,  8.69s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:14<00:55,  6.92s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:14<00:55,  6.92s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:42,  6.07s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:42,  6.07s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:28<00:42,  7.14s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:28<00:42,  7.14s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:36<00:37,  7.42s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:36<00:37,  7.42s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:40<00:25,  6.38s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:40<00:25,  6.38s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:44<00:17,  5.71s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:44<00:17,  5.71s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:49<00:11,  5.51s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:49<00:11,  5.51s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:54<00:05,  5.19s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:54<00:05,  5.19s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:59<00:00,  5.25s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:59<00:00,  5.25s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  5.25s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.15s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_3_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.7875
wandb:      modelselection/base_2_episodic_reward 0.7125
wandb:      modelselection/base_3_episodic_reward -1.0375
wandb:      modelselection/base_4_episodic_reward -1.075
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.0375
wandb:       modelselection/selected_base_learner 3
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_171658-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_171803-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.6591599583625793, 'learning_rate': 1e-07, 'num_tokens': 1911.0, 'completions/mean_length': 311.75, 'completions/min_length': 147.0, 'completions/max_length': 498.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 311.75, 'completions/min_terminated_length': 147.0, 'completions/max_terminated_length': 498.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.875, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.875, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 311.75, 'kl': 0.0005080626651761122, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.38093164563179016, 'learning_rate': 1e-07, 'num_tokens': 3303.0, 'completions/mean_length': 223.0, 'completions/min_length': 154.0, 'completions/max_length': 288.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 223.0, 'completions/min_terminated_length': 154.0, 'completions/max_terminated_length': 288.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.0, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 223.0, 'kl': 0.0003040909141418524, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5562154054641724, 'learning_rate': 1e-07, 'num_tokens': 4590.0, 'completions/mean_length': 198.75, 'completions/min_length': 146.0, 'completions/max_length': 243.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 198.75, 'completions/min_terminated_length': 146.0, 'completions/max_terminated_length': 243.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 198.75, 'kl': 0.00039504012602264993, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.33056148886680603, 'learning_rate': 1e-07, 'num_tokens': 6590.0, 'completions/mean_length': 350.0, 'completions/min_length': 213.0, 'completions/max_length': 502.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 350.0, 'completions/min_terminated_length': 213.0, 'completions/max_terminated_length': 502.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 350.0, 'kl': 0.0004332379830884747, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.364455908536911, 'learning_rate': 1e-07, 'num_tokens': 8538.0, 'completions/mean_length': 331.0, 'completions/min_length': 243.0, 'completions/max_length': 442.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 331.0, 'completions/min_terminated_length': 243.0, 'completions/max_terminated_length': 442.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.125, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 331.0, 'kl': 0.00037048124795546755, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 2.3783099095453508e-05, 'learning_rate': 1e-07, 'num_tokens': 9695.0, 'completions/mean_length': 161.25, 'completions/min_length': 126.0, 'completions/max_length': 197.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 161.25, 'completions/min_terminated_length': 126.0, 'completions/max_terminated_length': 197.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 161.25, 'kl': 0.00019983781385235488, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5163336992263794, 'learning_rate': 1e-07, 'num_tokens': 10892.0, 'completions/mean_length': 160.25, 'completions/min_length': 135.0, 'completions/max_length': 195.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 160.25, 'completions/min_terminated_length': 135.0, 'completions/max_terminated_length': 195.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.125, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 160.25, 'kl': 0.00038761584073654376, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4219697117805481, 'learning_rate': 1e-07, 'num_tokens': 12295.0, 'completions/mean_length': 209.75, 'completions/min_length': 162.0, 'completions/max_length': 247.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 209.75, 'completions/min_terminated_length': 162.0, 'completions/max_terminated_length': 247.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.0, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 209.75, 'kl': 0.00037836135015822947, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4598134160041809, 'learning_rate': 1e-07, 'num_tokens': 13557.0, 'completions/mean_length': 184.5, 'completions/min_length': 166.0, 'completions/max_length': 205.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 184.5, 'completions/min_terminated_length': 166.0, 'completions/max_terminated_length': 205.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.625, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 184.5, 'kl': 0.000378090247977525, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5472971796989441, 'learning_rate': 1e-07, 'num_tokens': 14638.0, 'completions/mean_length': 164.25, 'completions/min_length': 113.0, 'completions/max_length': 266.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 164.25, 'completions/min_terminated_length': 113.0, 'completions/max_terminated_length': 266.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': -0.5, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 164.25, 'kl': 0.0005654450869769789, 'epoch': 0.0}
{'train_runtime': 61.4877, 'train_samples_per_second': 0.651, 'train_steps_per_second': 0.163, 'train_loss': 3.885831290517672e-07, 'epoch': 0.0}
[EP 0058] 4 | reward_mean=-0.938 | 
*** stats:  {'episode_reward_mean': -0.9375, 'episode_reward_last': -0.5, 'episode_reward_std_mean': 0.9726471662521362, 'episode_reward_trajectory': [-2.875, -1.0, -1.5, -0.375, -2.125, 0.5, 0.125, -1.0, -0.625, -0.5], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.3375, 'rewards/match_format_approximately/mean/last': -0.625, 'rewards/match_format_approximately/std/mean': 0.675, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.4, 'rewards/check_numbers/mean/last': 0.125, 'rewards/check_numbers/std/mean': 0.529456090927124, 'rewards/check_numbers/std/last': 0.9464847445487976}
Curr reward  -0.9375
All rewards  90.2125
Cumulative rewards  [-22.275, 131.525, -1.025, -8.675, -9.3375]
Num plays  [6, 29, 8, 8, 8]
Mean rewards  [-3.7125, 4.535344827586207, -0.128125, -1.084375, -1.1671875]
Balancing probabilities  [0, 0, 0, 0, 1]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  86.16263691  90.50966799  90.50966799  90.50966799]
sampled base index:  1
potentials:  [156.76734354  86.16263691  90.50966799  90.50966799  90.50966799]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:10<01:32, 10.32s/it]                                               10%|â–ˆ         | 1/10 [00:10<01:32, 10.32s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:19<01:17,  9.64s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:19<01:17,  9.64s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:25<00:54,  7.77s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:25<00:54,  7.77s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:32<00:45,  7.62s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:32<00:45,  7.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:44<00:45,  9.13s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:44<00:45,  9.13s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:49<00:31,  7.92s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:49<00:31,  7.92s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:02<00:28,  9.35s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:02<00:28,  9.35s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:12<00:19,  9.62s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:12<00:19,  9.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:17<00:08,  8.31s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:17<00:08,  8.31s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:22<00:00,  7.11s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:22<00:00,  7.11s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:23<00:00,  7.11s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:23<00:00,  8.39s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_4_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.7875
wandb:      modelselection/base_2_episodic_reward 0.7125
wandb:      modelselection/base_3_episodic_reward -1.0375
wandb:      modelselection/base_4_episodic_reward -0.9375
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -0.9375
wandb:       modelselection/selected_base_learner 4
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_171803-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_171931-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0005, 'grad_norm': 0.4805550277233124, 'learning_rate': 0.0001, 'num_tokens': 2491.0, 'completions/mean_length': 456.75, 'completions/min_length': 401.0, 'completions/max_length': 593.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 456.75, 'completions/min_terminated_length': 401.0, 'completions/max_terminated_length': 593.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 2.0, 'rewards/check_answer/std': 1.154700517654419, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 7.5, 'reward_std': 2.309401035308838, 'frac_reward_zero_std': 0.0, 'completion_length': 456.75, 'kl': 0.511111281812191, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.36805224418640137, 'learning_rate': 0.0001, 'num_tokens': 4784.0, 'completions/mean_length': 448.25, 'completions/min_length': 338.0, 'completions/max_length': 523.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 448.25, 'completions/min_terminated_length': 338.0, 'completions/max_terminated_length': 523.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.125, 'rewards/check_answer/std': 2.136000871658325, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 5.125, 'reward_std': 3.0652623176574707, 'frac_reward_zero_std': 0.0, 'completion_length': 448.25, 'kl': 0.6045239791274071, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.547553539276123, 'learning_rate': 0.0001, 'num_tokens': 6200.0, 'completions/mean_length': 231.0, 'completions/min_length': 203.0, 'completions/max_length': 271.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 231.0, 'completions/min_terminated_length': 203.0, 'completions/max_terminated_length': 271.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.25, 'rewards/check_answer/std': 2.1794495582580566, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 5.25, 'reward_std': 3.0686588287353516, 'frac_reward_zero_std': 0.0, 'completion_length': 231.0, 'kl': 0.5198946297168732, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.00474380049854517, 'learning_rate': 0.0001, 'num_tokens': 7973.0, 'completions/mean_length': 293.25, 'completions/min_length': 244.0, 'completions/max_length': 396.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 293.25, 'completions/min_terminated_length': 244.0, 'completions/max_terminated_length': 396.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 293.25, 'kl': 0.3399112597107887, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.3870760202407837, 'learning_rate': 0.0001, 'num_tokens': 10956.0, 'completions/mean_length': 589.75, 'completions/min_length': 496.0, 'completions/max_length': 706.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 589.75, 'completions/min_terminated_length': 496.0, 'completions/max_terminated_length': 706.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.0, 'rewards/check_answer/std': 1.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 589.75, 'kl': 0.4066130295395851, 'epoch': 0.0}
{'loss': 0.001, 'grad_norm': 0.059689175337553024, 'learning_rate': 0.0001, 'num_tokens': 12390.0, 'completions/mean_length': 230.5, 'completions/min_length': 198.0, 'completions/max_length': 271.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 230.5, 'completions/min_terminated_length': 198.0, 'completions/max_terminated_length': 271.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 230.5, 'kl': 1.0324847102165222, 'epoch': 0.0}
{'loss': 0.0009, 'grad_norm': 0.002314159180969, 'learning_rate': 0.0001, 'num_tokens': 15890.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.9077381640672684, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0023391267750412226, 'learning_rate': 0.0001, 'num_tokens': 18339.0, 'completions/mean_length': 471.25, 'completions/min_length': 285.0, 'completions/max_length': 597.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 471.25, 'completions/min_terminated_length': 285.0, 'completions/max_terminated_length': 597.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 471.25, 'kl': 0.32610757648944855, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.5214741826057434, 'learning_rate': 0.0001, 'num_tokens': 19850.0, 'completions/mean_length': 246.75, 'completions/min_length': 231.0, 'completions/max_length': 260.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 246.75, 'completions/min_terminated_length': 231.0, 'completions/max_terminated_length': 260.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.375, 'rewards/check_answer/std': 2.136000871658325, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 6.875, 'reward_std': 3.1983067989349365, 'frac_reward_zero_std': 0.0, 'completion_length': 246.75, 'kl': 0.5422190725803375, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.0037988873664289713, 'learning_rate': 0.0001, 'num_tokens': 21016.0, 'completions/mean_length': 185.5, 'completions/min_length': 163.0, 'completions/max_length': 197.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 185.5, 'completions/min_terminated_length': 163.0, 'completions/max_terminated_length': 197.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 185.5, 'kl': 0.4596854895353317, 'epoch': 0.0}
{'train_runtime': 83.8601, 'train_samples_per_second': 0.477, 'train_steps_per_second': 0.119, 'train_loss': 0.0005650354840327054, 'epoch': 0.0}
[EP 0059] 1 | reward_mean=5.725 | 
*** stats:  {'episode_reward_mean': 5.725, 'episode_reward_last': 9.5, 'episode_reward_std_mean': 1.2641628980636597, 'episode_reward_trajectory': [7.5, 5.125, 5.25, 3.0, 3.5, 9.5, -2.5, 9.5, 6.875, 9.5], 'rewards/match_format_exactly/mean/mean': 2.7, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.55, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 1.025, 'rewards/check_answer/mean/last': 3.0, 'rewards/check_answer/std/mean': 0.8606151819229126, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.45, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.4309401035308838, 'rewards/check_numbers/std/last': 0.0}
Curr reward  5.725
All rewards  95.9375
Cumulative rewards  [-22.275, 137.25, -1.025, -8.675, -9.3375]
Num plays  [6, 30, 8, 8, 8]
Mean rewards  [-3.7125, 4.575, -0.128125, -1.084375, -1.1671875]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  87.6356092   90.50966799  90.50966799  90.50966799]
sampled base index:  1
potentials:  [156.76734354  87.6356092   90.50966799  90.50966799  90.50966799]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:10<01:33, 10.36s/it]                                               10%|â–ˆ         | 1/10 [00:10<01:33, 10.36s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:19<01:15,  9.38s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:19<01:15,  9.38s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:25<00:55,  7.89s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:25<00:55,  7.89s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:33<00:49,  8.20s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:33<00:49,  8.20s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:46<00:48,  9.66s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:46<00:48,  9.66s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:53<00:35,  8.93s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:53<00:35,  8.93s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:05<00:30, 10.03s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:05<00:30, 10.03s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:12<00:17,  8.85s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:12<00:17,  8.85s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:24<00:09,  9.92s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:24<00:09,  9.92s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:29<00:00,  8.43s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:29<00:00,  8.43s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:31<00:00,  8.43s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:31<00:00,  9.15s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 5.725
wandb:      modelselection/base_2_episodic_reward 0.7125
wandb:      modelselection/base_3_episodic_reward -1.0375
wandb:      modelselection/base_4_episodic_reward -0.9375
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 5.725
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_171931-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_172208-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0014, 'grad_norm': 0.4541798233985901, 'learning_rate': 0.0001, 'num_tokens': 2673.0, 'completions/mean_length': 502.25, 'completions/min_length': 441.0, 'completions/max_length': 610.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 502.25, 'completions/min_terminated_length': 441.0, 'completions/max_terminated_length': 610.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.875, 'rewards/check_answer/std': 1.8427786827087402, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 5.875, 'reward_std': 2.688710927963257, 'frac_reward_zero_std': 0.0, 'completion_length': 502.25, 'kl': 1.3524748235940933, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.0039092060178518295, 'learning_rate': 0.0001, 'num_tokens': 4786.0, 'completions/mean_length': 403.25, 'completions/min_length': 269.0, 'completions/max_length': 487.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 403.25, 'completions/min_terminated_length': 269.0, 'completions/max_terminated_length': 487.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 403.25, 'kl': 0.5426463559269905, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.6199292540550232, 'learning_rate': 0.0001, 'num_tokens': 6264.0, 'completions/mean_length': 246.5, 'completions/min_length': 224.0, 'completions/max_length': 303.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 246.5, 'completions/min_terminated_length': 224.0, 'completions/max_terminated_length': 303.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.875, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 246.5, 'kl': 0.757724940776825, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.0061152926646173, 'learning_rate': 0.0001, 'num_tokens': 8386.0, 'completions/mean_length': 380.5, 'completions/min_length': 304.0, 'completions/max_length': 484.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 380.5, 'completions/min_terminated_length': 304.0, 'completions/max_terminated_length': 484.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 380.5, 'kl': 0.4319598078727722, 'epoch': 0.0}
{'loss': 0.0007, 'grad_norm': 0.4411675035953522, 'learning_rate': 0.0001, 'num_tokens': 11527.0, 'completions/mean_length': 629.25, 'completions/min_length': 512.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 522.5, 'completions/min_terminated_length': 512.0, 'completions/max_terminated_length': 533.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': -0.75, 'rewards/check_answer/std': 0.8660253882408142, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': 0.25, 'reward_std': 3.175426483154297, 'frac_reward_zero_std': 0.0, 'completion_length': 629.25, 'kl': 0.6587806865572929, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.5665363073348999, 'learning_rate': 0.0001, 'num_tokens': 13380.0, 'completions/mean_length': 335.25, 'completions/min_length': 300.0, 'completions/max_length': 404.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 335.25, 'completions/min_terminated_length': 300.0, 'completions/max_terminated_length': 404.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.75, 'rewards/check_answer/std': 2.598076105117798, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 6.25, 'reward_std': 3.752776622772217, 'frac_reward_zero_std': 0.0, 'completion_length': 335.25, 'kl': 0.5833156853914261, 'epoch': 0.0}
{'loss': 0.0009, 'grad_norm': 0.0033746613189578056, 'learning_rate': 0.0001, 'num_tokens': 16880.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.8982614278793335, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.0011277699377387762, 'learning_rate': 0.0001, 'num_tokens': 18573.0, 'completions/mean_length': 282.25, 'completions/min_length': 236.0, 'completions/max_length': 323.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 282.25, 'completions/min_terminated_length': 236.0, 'completions/max_terminated_length': 323.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 282.25, 'kl': 0.3579203113913536, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.6452254056930542, 'learning_rate': 0.0001, 'num_tokens': 21058.0, 'completions/mean_length': 490.25, 'completions/min_length': 239.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 244.5, 'completions/min_terminated_length': 239.0, 'completions/max_terminated_length': 250.0, 'rewards/match_format_exactly/mean': 1.5, 'rewards/match_format_exactly/std': 1.7320507764816284, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 2.598076105117798, 'rewards/check_answer/mean': 1.5, 'rewards/check_answer/std': 1.7320507764816284, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 3.5, 'reward_std': 6.928203105926514, 'frac_reward_zero_std': 0.0, 'completion_length': 424.0, 'kl': 0.7758262977004051, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.002001413144171238, 'learning_rate': 0.0001, 'num_tokens': 22298.0, 'completions/mean_length': 204.0, 'completions/min_length': 182.0, 'completions/max_length': 236.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 204.0, 'completions/min_terminated_length': 182.0, 'completions/max_terminated_length': 236.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 3.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 9.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 204.0, 'kl': 0.4518677517771721, 'epoch': 0.0}
{'train_runtime': 91.5298, 'train_samples_per_second': 0.437, 'train_steps_per_second': 0.109, 'train_loss': 0.0006810843653511256, 'epoch': 0.0}
[EP 0060] 1 | reward_mean=4.625 | 
*** stats:  {'episode_reward_mean': 4.625, 'episode_reward_last': 9.5, 'episode_reward_std_mean': 1.9795117139816285, 'episode_reward_trajectory': [5.875, 3.0, 7.875, 3.0, 0.25, 6.25, -2.5, 9.5, 3.5, 9.5], 'rewards/match_format_exactly/mean/mean': 2.4, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.3464101552963257, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 1.1, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.5196152210235596, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.725, 'rewards/check_answer/mean/last': 3.0, 'rewards/check_answer/std/mean': 0.928893095254898, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.4, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.4309401035308838, 'rewards/check_numbers/std/last': 0.0}
Curr reward  4.625
All rewards  100.5625
Cumulative rewards  [-22.275, 141.875, -1.025, -8.675, -9.3375]
Num plays  [6, 31, 8, 8, 8]
Mean rewards  [-3.7125, 4.576612903225806, -0.128125, -1.084375, -1.1671875]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  89.08422981  90.50966799  90.50966799  90.50966799]
sampled base index:  1
potentials:  [156.76734354  89.08422981  90.50966799  90.50966799  90.50966799]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.37s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.37s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:22<01:28, 11.07s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:22<01:28, 11.07s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:34<01:21, 11.64s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:34<01:21, 11.64s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:47<01:11, 11.89s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:47<01:11, 11.89s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:59<01:00, 12.06s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:59<01:00, 12.06s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:11<00:48, 12.12s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:11<00:48, 12.12s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.18s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.18s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.25s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.25s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.23s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.23s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:53<00:00, 10.00s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:53<00:00, 10.00s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:55<00:00, 10.00s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:55<00:00, 11.53s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 4.625
wandb:      modelselection/base_2_episodic_reward 0.7125
wandb:      modelselection/base_3_episodic_reward -1.0375
wandb:      modelselection/base_4_episodic_reward -0.9375
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 4.625
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_172208-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_172407-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0008, 'grad_norm': 0.005660464987158775, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.8064565807580948, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.00175522081553936, 'learning_rate': 0.0001, 'num_tokens': 6129.0, 'completions/mean_length': 505.25, 'completions/min_length': 430.0, 'completions/max_length': 592.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 505.25, 'completions/min_terminated_length': 430.0, 'completions/max_terminated_length': 592.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': -1.5, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 3.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 505.25, 'kl': 0.472433865070343, 'epoch': 0.0}
{'loss': 0.0011, 'grad_norm': 0.009240272454917431, 'learning_rate': 0.0001, 'num_tokens': 9565.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.0654961913824081, 'epoch': 0.0}
{'loss': 0.0007, 'grad_norm': 0.4334222972393036, 'learning_rate': 0.0001, 'num_tokens': 12703.0, 'completions/mean_length': 634.5, 'completions/min_length': 330.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 330.0, 'completions/min_terminated_length': 330.0, 'completions/max_terminated_length': 330.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.125, 'rewards/check_answer/std': 0.25, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.625, 'reward_std': 3.75, 'frac_reward_zero_std': 0.0, 'completion_length': 634.5, 'kl': 0.6677558049559593, 'epoch': 0.0}
{'loss': 0.0007, 'grad_norm': 0.4578542411327362, 'learning_rate': 0.0001, 'num_tokens': 16201.0, 'completions/mean_length': 718.5, 'completions/min_length': 666.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 666.0, 'completions/min_terminated_length': 666.0, 'completions/max_terminated_length': 666.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 2.75, 'frac_reward_zero_std': 0.0, 'completion_length': 718.5, 'kl': 0.7140771299600601, 'epoch': 0.0}
{'loss': 0.0038, 'grad_norm': 0.5131909847259521, 'learning_rate': 0.0001, 'num_tokens': 19657.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 3.7764310240745544, 'epoch': 0.0}
{'loss': 0.001, 'grad_norm': 0.004107990302145481, 'learning_rate': 0.0001, 'num_tokens': 23157.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 622.5, 'kl': 1.0309287160634995, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.4930465519428253, 'learning_rate': 0.0001, 'num_tokens': 25455.0, 'completions/mean_length': 433.5, 'completions/min_length': 284.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 332.66668701171875, 'completions/min_terminated_length': 284.0, 'completions/max_terminated_length': 364.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 1.125, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 4.875, 'reward_std': 5.7933149337768555, 'frac_reward_zero_std': 0.0, 'completion_length': 433.5, 'kl': 0.58144860714674, 'epoch': 0.0}
{'loss': 0.0011, 'grad_norm': 0.04333386570215225, 'learning_rate': 0.0001, 'num_tokens': 28923.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 593.25, 'kl': 1.121773898601532, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.8084030151367188, 'learning_rate': 0.0001, 'num_tokens': 30145.0, 'completions/mean_length': 199.5, 'completions/min_length': 170.0, 'completions/max_length': 230.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 199.5, 'completions/min_terminated_length': 170.0, 'completions/max_terminated_length': 230.0, 'rewards/match_format_exactly/mean': 3.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 2.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 1.875, 'rewards/check_answer/std': 2.25, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 7.875, 'reward_std': 3.25, 'frac_reward_zero_std': 0.0, 'completion_length': 199.5, 'kl': 0.49495361000299454, 'epoch': 0.0}
{'train_runtime': 115.3203, 'train_samples_per_second': 0.347, 'train_steps_per_second': 0.087, 'train_loss': 0.0010731720190960913, 'epoch': 0.0}
[EP 0061] 1 | reward_mean=0.150 | 
*** stats:  {'episode_reward_mean': 0.15, 'episode_reward_last': 7.875, 'episode_reward_std_mean': 1.5543314933776855, 'episode_reward_trajectory': [-2.5, 3.0, -2.5, -0.625, -1.125, -2.5, -2.5, 4.875, -2.5, 7.875], 'rewards/match_format_exactly/mean/mean': 0.975, 'rewards/match_format_exactly/mean/last': 3.0, 'rewards/match_format_exactly/std/mean': 0.45, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.0375, 'rewards/match_format_approximately/mean/last': 2.0, 'rewards/match_format_approximately/std/mean': 0.675, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.125, 'rewards/check_answer/mean/last': 1.875, 'rewards/check_answer/std/mean': 0.55, 'rewards/check_answer/std/last': 2.25, 'rewards/check_numbers/mean/mean': 0.0875, 'rewards/check_numbers/mean/last': 1.0, 'rewards/check_numbers/std/mean': 0.2530776381492615, 'rewards/check_numbers/std/last': 1.0}
Curr reward  0.15
All rewards  100.7125
Cumulative rewards  [-22.275, 142.025, -1.025, -8.675, -9.3375]
Num plays  [6, 32, 8, 8, 8]
Mean rewards  [-3.7125, 4.43828125, -0.128125, -1.084375, -1.1671875]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  90.50966799  90.50966799  90.50966799  90.50966799]
sampled base index:  1
potentials:  [156.76734354  90.50966799  90.50966799  90.50966799  90.50966799]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.21s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.21s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.12s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.12s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.10s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.10s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.10s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.10s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.13s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.13s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.11s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.11s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.12s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.12s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.12s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.12s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:49<00:12, 12.13s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:49<00:12, 12.13s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.13s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.13s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.13s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.30s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward 0.15
wandb:      modelselection/base_2_episodic_reward 0.7125
wandb:      modelselection/base_3_episodic_reward -1.0375
wandb:      modelselection/base_4_episodic_reward -0.9375
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward 0.15
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_172407-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_172614-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0011, 'grad_norm': 0.03026416152715683, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.1421940475702286, 'epoch': 0.0}
{'loss': 0.0046, 'grad_norm': 3.438737630844116, 'learning_rate': 0.0001, 'num_tokens': 5996.0, 'completions/mean_length': 472.0, 'completions/min_length': 315.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 384.0, 'completions/min_terminated_length': 315.0, 'completions/max_terminated_length': 509.0, 'rewards/match_format_exactly/mean': 2.25, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 2.25, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 2.1213202476501465, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': 3.25, 'reward_std': 4.907477378845215, 'frac_reward_zero_std': 0.0, 'completion_length': 472.0, 'kl': 4.595027312636375, 'epoch': 0.0}
{'loss': 0.0012, 'grad_norm': 0.6574660539627075, 'learning_rate': 0.0001, 'num_tokens': 9432.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.875, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.875, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 736.0, 'kl': 1.152634859085083, 'epoch': 0.0}
{'loss': 0.0013, 'grad_norm': 1.0768862962722778, 'learning_rate': 0.0001, 'num_tokens': 12976.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -3.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -3.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 736.0, 'kl': 1.3196955025196075, 'epoch': 0.0}
{'loss': 0.0015, 'grad_norm': 0.011998088099062443, 'learning_rate': 0.0001, 'num_tokens': 16544.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 657.25, 'kl': 1.4951258599758148, 'epoch': 0.0}
{'loss': 0.0016, 'grad_norm': 0.019004248082637787, 'learning_rate': 0.0001, 'num_tokens': 20000.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.5663118660449982, 'epoch': 0.0}
{'loss': 0.0009, 'grad_norm': 0.08577094972133636, 'learning_rate': 0.0001, 'num_tokens': 23500.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.9498515576124191, 'epoch': 0.0}
{'loss': 0.0261, 'grad_norm': 17.477081298828125, 'learning_rate': 0.0001, 'num_tokens': 27008.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 26.089069604873657, 'epoch': 0.0}
{'loss': 0.002, 'grad_norm': 0.2089763879776001, 'learning_rate': 0.0001, 'num_tokens': 30476.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.9708029925823212, 'epoch': 0.0}
{'loss': 0.0015, 'grad_norm': 0.08891305327415466, 'learning_rate': 0.0001, 'num_tokens': 33844.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.5421511828899384, 'epoch': 0.0}
{'train_runtime': 122.9924, 'train_samples_per_second': 0.325, 'train_steps_per_second': 0.081, 'train_loss': 0.0041822825325652955, 'epoch': 0.0}
[EP 0062] 1 | reward_mean=-2.938 | 
*** stats:  {'episode_reward_mean': -2.9375, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.6523502767086029, 'episode_reward_trajectory': [-2.5, 3.25, -2.875, -3.25, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.225, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.15, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -3.175, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.3866025388240814, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.21213202476501464, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0125, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.09464847445487976, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -2.9375
All rewards  97.775
Cumulative rewards  [-22.275, 139.0875, -1.025, -8.675, -9.3375]
Num plays  [6, 33, 8, 8, 8]
Mean rewards  [-3.7125, 4.214772727272727, -0.128125, -1.084375, -1.1671875]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  91.91300234  90.50966799  90.50966799  90.50966799]
sampled base index:  2
potentials:  [156.76734354  91.91300234  90.50966799  90.50966799  90.50966799]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:08<01:14,  8.26s/it]                                               10%|â–ˆ         | 1/10 [00:08<01:14,  8.26s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:14<00:57,  7.16s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:14<00:57,  7.16s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:20<00:45,  6.47s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:20<00:45,  6.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:26<00:37,  6.21s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:26<00:37,  6.21s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:32<00:31,  6.35s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:32<00:31,  6.35s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:36<00:22,  5.60s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:36<00:22,  5.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:41<00:16,  5.36s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:41<00:16,  5.36s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:46<00:10,  5.28s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:46<00:10,  5.28s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:55<00:06,  6.31s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:55<00:06,  6.31s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.27s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.27s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  6.27s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  6.33s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -2.9375
wandb:      modelselection/base_2_episodic_reward 0.7125
wandb:      modelselection/base_3_episodic_reward -1.0375
wandb:      modelselection/base_4_episodic_reward -0.9375
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -2.9375
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_172614-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_172722-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0004, 'grad_norm': 0.39869022369384766, 'learning_rate': 1e-05, 'num_tokens': 2174.0, 'completions/mean_length': 377.5, 'completions/min_length': 237.0, 'completions/max_length': 454.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 377.5, 'completions/min_terminated_length': 237.0, 'completions/max_terminated_length': 454.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -0.5, 'reward_std': 0.9128709435462952, 'frac_reward_zero_std': 0.0, 'completion_length': 377.5, 'kl': 0.36076545948162675, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.405910849571228, 'learning_rate': 1e-05, 'num_tokens': 3409.0, 'completions/mean_length': 183.75, 'completions/min_length': 102.0, 'completions/max_length': 325.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 183.75, 'completions/min_terminated_length': 102.0, 'completions/max_terminated_length': 325.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 183.75, 'kl': 0.014472377486526966, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3029792606830597, 'learning_rate': 1e-05, 'num_tokens': 4739.0, 'completions/mean_length': 209.5, 'completions/min_length': 167.0, 'completions/max_length': 283.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 209.5, 'completions/min_terminated_length': 167.0, 'completions/max_terminated_length': 283.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 209.5, 'kl': 0.01757467514835298, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3468225300312042, 'learning_rate': 1e-05, 'num_tokens': 6267.0, 'completions/mean_length': 232.0, 'completions/min_length': 172.0, 'completions/max_length': 293.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 232.0, 'completions/min_terminated_length': 172.0, 'completions/max_terminated_length': 293.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 232.0, 'kl': 0.025167367421090603, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.26721274852752686, 'learning_rate': 1e-05, 'num_tokens': 7982.0, 'completions/mean_length': 272.75, 'completions/min_length': 240.0, 'completions/max_length': 347.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 272.75, 'completions/min_terminated_length': 240.0, 'completions/max_terminated_length': 347.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 272.75, 'kl': 0.011444520903751254, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0005529593327082694, 'learning_rate': 1e-05, 'num_tokens': 9192.0, 'completions/mean_length': 174.5, 'completions/min_length': 161.0, 'completions/max_length': 183.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 174.5, 'completions/min_terminated_length': 161.0, 'completions/max_terminated_length': 183.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 174.5, 'kl': 0.01716292859055102, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3985763192176819, 'learning_rate': 1e-05, 'num_tokens': 10542.0, 'completions/mean_length': 198.5, 'completions/min_length': 183.0, 'completions/max_length': 229.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 198.5, 'completions/min_terminated_length': 183.0, 'completions/max_terminated_length': 229.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 198.5, 'kl': 0.019217043882235885, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0005711177946068347, 'learning_rate': 1e-05, 'num_tokens': 11842.0, 'completions/mean_length': 184.0, 'completions/min_length': 145.0, 'completions/max_length': 246.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 184.0, 'completions/min_terminated_length': 145.0, 'completions/max_terminated_length': 246.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': 0.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 184.0, 'kl': 0.01646268554031849, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.3222754895687103, 'learning_rate': 1e-05, 'num_tokens': 13848.0, 'completions/mean_length': 370.5, 'completions/min_length': 248.0, 'completions/max_length': 491.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 370.5, 'completions/min_terminated_length': 248.0, 'completions/max_terminated_length': 491.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 0.8660253882408142, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': -0.25, 'reward_std': 1.658312439918518, 'frac_reward_zero_std': 0.0, 'completion_length': 370.5, 'kl': 0.06355206435546279, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4287147521972656, 'learning_rate': 1e-05, 'num_tokens': 15131.0, 'completions/mean_length': 214.75, 'completions/min_length': 161.0, 'completions/max_length': 314.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 214.75, 'completions/min_terminated_length': 161.0, 'completions/max_terminated_length': 314.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': -0.25, 'reward_std': 0.5, 'frac_reward_zero_std': 0.0, 'completion_length': 214.75, 'kl': 0.027883965289220214, 'epoch': 0.0}
{'train_runtime': 63.3162, 'train_samples_per_second': 0.632, 'train_steps_per_second': 0.158, 'train_loss': 5.737107512686635e-05, 'epoch': 0.0}
[EP 0063] 2 | reward_mean=0.800 | 
*** stats:  {'episode_reward_mean': 0.8, 'episode_reward_last': -0.25, 'episode_reward_std_mean': 0.7351959764957428, 'episode_reward_trajectory': [-0.5, 1.125, 1.625, 0.5, 1.625, 2.0, 1.625, 0.5, -0.25, -0.25], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.3125, 'rewards/match_format_approximately/mean/last': 0.125, 'rewards/match_format_approximately/std/mean': 0.24820507764816285, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.4875, 'rewards/check_numbers/mean/last': -0.375, 'rewards/check_numbers/std/mean': 0.581945151090622, 'rewards/check_numbers/std/last': 0.25}
Curr reward  0.8
All rewards  98.575
Cumulative rewards  [-22.275, 139.0875, -0.22499999999999987, -8.675, -9.3375]
Num plays  [6, 33, 9, 8, 8]
Mean rewards  [-3.7125, 4.214772727272727, -0.024999999999999984, -1.084375, -1.1671875]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  91.91300234  96.          90.50966799  90.50966799]
sampled base index:  3
potentials:  [156.76734354  91.91300234  96.          90.50966799  90.50966799]
sampled base index:  3
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.37s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.37s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:19<01:16,  9.53s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:19<01:16,  9.53s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:25<00:54,  7.79s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:25<00:54,  7.79s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:31<00:42,  7.07s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:31<00:42,  7.07s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:40<00:39,  7.90s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:40<00:39,  7.90s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:47<00:29,  7.44s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:47<00:29,  7.44s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:51<00:19,  6.40s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:51<00:19,  6.40s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:56<00:11,  5.96s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:56<00:11,  5.96s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:05<00:06,  6.92s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:05<00:06,  6.92s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:12<00:00,  6.71s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:12<00:00,  6.71s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:13<00:00,  6.71s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:13<00:00,  7.38s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -2.9375
wandb:      modelselection/base_2_episodic_reward 0.8
wandb:      modelselection/base_3_episodic_reward -1.0375
wandb:      modelselection/base_4_episodic_reward -0.9375
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 0.8
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_172722-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_172839-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.35236674547195435, 'learning_rate': 1e-06, 'num_tokens': 2144.0, 'completions/mean_length': 370.0, 'completions/min_length': 163.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 248.0, 'completions/min_terminated_length': 163.0, 'completions/max_terminated_length': 374.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.875, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.875, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 370.0, 'kl': 0.000858002866152674, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 5.744553345721215e-05, 'learning_rate': 1e-06, 'num_tokens': 3604.0, 'completions/mean_length': 240.0, 'completions/min_length': 142.0, 'completions/max_length': 406.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 240.0, 'completions/min_terminated_length': 142.0, 'completions/max_terminated_length': 406.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 240.0, 'kl': 0.0003368391808180604, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0006807040190324187, 'learning_rate': 1e-06, 'num_tokens': 4983.0, 'completions/mean_length': 221.75, 'completions/min_length': 154.0, 'completions/max_length': 282.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 221.75, 'completions/min_terminated_length': 154.0, 'completions/max_terminated_length': 282.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 221.75, 'kl': 0.0013756328335148282, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3462311327457428, 'learning_rate': 1e-06, 'num_tokens': 6595.0, 'completions/mean_length': 253.0, 'completions/min_length': 190.0, 'completions/max_length': 296.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 253.0, 'completions/min_terminated_length': 190.0, 'completions/max_terminated_length': 296.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 253.0, 'kl': 0.00028728707184200175, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3001295328140259, 'learning_rate': 1e-06, 'num_tokens': 8521.0, 'completions/mean_length': 325.5, 'completions/min_length': 234.0, 'completions/max_length': 527.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 325.5, 'completions/min_terminated_length': 234.0, 'completions/max_terminated_length': 527.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.375, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 325.5, 'kl': 0.0003438277453824412, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.40311843156814575, 'learning_rate': 1e-06, 'num_tokens': 9930.0, 'completions/mean_length': 224.25, 'completions/min_length': 134.0, 'completions/max_length': 335.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 224.25, 'completions/min_terminated_length': 134.0, 'completions/max_terminated_length': 335.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 224.25, 'kl': 0.0003122018970316276, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.8731654286384583, 'learning_rate': 1e-06, 'num_tokens': 11125.0, 'completions/mean_length': 159.75, 'completions/min_length': 124.0, 'completions/max_length': 180.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 159.75, 'completions/min_terminated_length': 124.0, 'completions/max_terminated_length': 180.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 159.75, 'kl': 0.0008616308186901733, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 2.831422352755908e-05, 'learning_rate': 1e-06, 'num_tokens': 12512.0, 'completions/mean_length': 205.75, 'completions/min_length': 178.0, 'completions/max_length': 228.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 205.75, 'completions/min_terminated_length': 178.0, 'completions/max_terminated_length': 228.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 205.75, 'kl': 0.0003145185219182167, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3028244972229004, 'learning_rate': 1e-06, 'num_tokens': 14354.0, 'completions/mean_length': 329.5, 'completions/min_length': 212.0, 'completions/max_length': 511.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 329.5, 'completions/min_terminated_length': 212.0, 'completions/max_terminated_length': 511.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.875, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 329.5, 'kl': 0.0004767697100760415, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.39344286918640137, 'learning_rate': 1e-06, 'num_tokens': 15799.0, 'completions/mean_length': 255.25, 'completions/min_length': 200.0, 'completions/max_length': 316.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 255.25, 'completions/min_terminated_length': 200.0, 'completions/max_terminated_length': 316.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -1.25, 'reward_std': 0.28867512941360474, 'frac_reward_zero_std': 0.0, 'completion_length': 255.25, 'kl': 0.0004596889848471619, 'epoch': 0.0}
{'train_runtime': 73.7796, 'train_samples_per_second': 0.542, 'train_steps_per_second': 0.136, 'train_loss': 5.562291136129716e-07, 'epoch': 0.0}
[EP 0064] 3 | reward_mean=-1.137 | 
*** stats:  {'episode_reward_mean': -1.1375, 'episode_reward_last': -1.25, 'episode_reward_std_mean': 0.7094325125217438, 'episode_reward_trajectory': [-2.875, -1.0, -1.0, -1.5, -0.375, -0.25, -0.25, -1.0, -1.875, -1.25], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.2625, 'rewards/match_format_approximately/mean/last': -1.0, 'rewards/match_format_approximately/std/mean': 0.44361406564712524, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.125, 'rewards/check_numbers/mean/last': -0.25, 'rewards/check_numbers/std/mean': 0.3386751294136047, 'rewards/check_numbers/std/last': 0.28867512941360474}
Curr reward  -1.1375
All rewards  97.4375
Cumulative rewards  [-22.275, 139.0875, -0.22499999999999987, -9.8125, -9.3375]
Num plays  [6, 33, 9, 9, 8]
Mean rewards  [-3.7125, 4.214772727272727, -0.024999999999999984, -1.0902777777777777, -1.1671875]
Balancing probabilities  [0, 0, 0, 1, 0]
Mis-Specification Test [6, 4, 5, 5, 5]
potentials:  [156.76734354  91.91300234  96.          96.          90.50966799]
sampled base index:  4
potentials:  [156.76734354  91.91300234  96.          96.          90.50966799]
sampled base index:  4
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.15s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.15s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:17<01:03,  7.95s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:17<01:03,  7.95s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:22<00:46,  6.63s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:22<00:46,  6.63s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:28<00:38,  6.38s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:28<00:38,  6.38s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:34<00:32,  6.40s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:34<00:32,  6.40s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:38<00:22,  5.59s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:38<00:22,  5.59s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:42<00:15,  5.05s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:42<00:15,  5.05s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:47<00:09,  4.96s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:47<00:09,  4.96s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:53<00:05,  5.20s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:53<00:05,  5.20s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:59<00:00,  5.64s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:59<00:00,  5.64s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  5.64s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  6.15s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_3_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -2.9375
wandb:      modelselection/base_2_episodic_reward 0.8
wandb:      modelselection/base_3_episodic_reward -1.1375
wandb:      modelselection/base_4_episodic_reward -0.9375
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.1375
wandb:       modelselection/selected_base_learner 3
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_172839-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_172945-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.4280533790588379, 'learning_rate': 1e-07, 'num_tokens': 2189.0, 'completions/mean_length': 381.25, 'completions/min_length': 209.0, 'completions/max_length': 715.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 381.25, 'completions/min_terminated_length': 209.0, 'completions/max_terminated_length': 715.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 381.25, 'kl': 0.0006145075312815607, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.40047314763069153, 'learning_rate': 1e-07, 'num_tokens': 3439.0, 'completions/mean_length': 187.5, 'completions/min_length': 136.0, 'completions/max_length': 232.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 187.5, 'completions/min_terminated_length': 136.0, 'completions/max_terminated_length': 232.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 187.5, 'kl': 0.0003773775097215548, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.6283550262451172, 'learning_rate': 1e-07, 'num_tokens': 4681.0, 'completions/mean_length': 187.5, 'completions/min_length': 135.0, 'completions/max_length': 239.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 187.5, 'completions/min_terminated_length': 135.0, 'completions/max_terminated_length': 239.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -1.25, 'reward_std': 0.28867512941360474, 'frac_reward_zero_std': 0.0, 'completion_length': 187.5, 'kl': 0.0005772652730229311, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.33045631647109985, 'learning_rate': 1e-07, 'num_tokens': 6303.0, 'completions/mean_length': 255.5, 'completions/min_length': 240.0, 'completions/max_length': 300.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 255.5, 'completions/min_terminated_length': 240.0, 'completions/max_terminated_length': 300.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.125, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 255.5, 'kl': 0.000529821976670064, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3995445668697357, 'learning_rate': 1e-07, 'num_tokens': 8016.0, 'completions/mean_length': 272.25, 'completions/min_length': 219.0, 'completions/max_length': 328.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 272.25, 'completions/min_terminated_length': 219.0, 'completions/max_terminated_length': 328.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -2.125, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 272.25, 'kl': 0.0003373282706888858, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5636712908744812, 'learning_rate': 1e-07, 'num_tokens': 9143.0, 'completions/mean_length': 153.75, 'completions/min_length': 119.0, 'completions/max_length': 168.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 153.75, 'completions/min_terminated_length': 119.0, 'completions/max_terminated_length': 168.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -1.25, 'reward_std': 0.28867512941360474, 'frac_reward_zero_std': 0.0, 'completion_length': 153.75, 'kl': 0.0003275354865763802, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.594707190990448, 'learning_rate': 1e-07, 'num_tokens': 10261.0, 'completions/mean_length': 140.5, 'completions/min_length': 123.0, 'completions/max_length': 161.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 140.5, 'completions/min_terminated_length': 123.0, 'completions/max_terminated_length': 161.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 140.5, 'kl': 0.0008395202530664392, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3431503176689148, 'learning_rate': 1e-07, 'num_tokens': 11650.0, 'completions/mean_length': 206.25, 'completions/min_length': 188.0, 'completions/max_length': 215.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 206.25, 'completions/min_terminated_length': 188.0, 'completions/max_terminated_length': 215.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 206.25, 'kl': 0.000326616813254077, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.30794739723205566, 'learning_rate': 1e-07, 'num_tokens': 13044.0, 'completions/mean_length': 217.5, 'completions/min_length': 139.0, 'completions/max_length': 285.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 217.5, 'completions/min_terminated_length': 139.0, 'completions/max_terminated_length': 285.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.375, 'reward_std': 1.8874585628509521, 'frac_reward_zero_std': 0.0, 'completion_length': 217.5, 'kl': 0.0003344072538311593, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 4.551031088340096e-05, 'learning_rate': 1e-07, 'num_tokens': 14635.0, 'completions/mean_length': 291.75, 'completions/min_length': 235.0, 'completions/max_length': 346.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 291.75, 'completions/min_terminated_length': 235.0, 'completions/max_terminated_length': 346.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': -1.5, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 291.75, 'kl': 0.0005167087583686225, 'epoch': 0.0}
{'train_runtime': 61.4713, 'train_samples_per_second': 0.651, 'train_steps_per_second': 0.163, 'train_loss': 4.71750303177032e-07, 'epoch': 0.0}
[EP 0065] 4 | reward_mean=-1.312 | 
*** stats:  {'episode_reward_mean': -1.3125, 'episode_reward_last': -1.5, 'episode_reward_std_mean': 0.8193037688732148, 'episode_reward_trajectory': [-2.5, -0.625, -1.25, -1.125, -2.125, -1.25, -0.75, -0.625, -1.375, -1.5], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.3375, 'rewards/match_format_approximately/mean/last': -1.0, 'rewards/match_format_approximately/std/mean': 0.4699489831924438, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.025, 'rewards/check_numbers/mean/last': -0.5, 'rewards/check_numbers/std/mean': 0.39433756470680237, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -1.3125
All rewards  96.125
Cumulative rewards  [-22.275, 139.0875, -0.22499999999999987, -9.8125, -10.65]
Num plays  [6, 33, 9, 9, 9]
Mean rewards  [-3.7125, 4.214772727272727, -0.024999999999999984, -1.0902777777777777, -1.1833333333333333]
Balancing probabilities  [0, 0, 0, 0, 1]
Mis-Specification Test [6, 4, 5, 5, 6]
potentials:  [156.76734354  91.91300234  96.          96.         192.        ]
sampled base index:  1
potentials:  [156.76734354  91.91300234  96.          96.         192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.37s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.37s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.30s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.30s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.28s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.28s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.28s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.28s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.31s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.31s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.30s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.30s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.31s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.31s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.30s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.30s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.29s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.29s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.29s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.29s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.29s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.48s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_4_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -2.9375
wandb:      modelselection/base_2_episodic_reward 0.8
wandb:      modelselection/base_3_episodic_reward -1.1375
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.3125
wandb:       modelselection/selected_base_learner 4
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_172945-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_173153-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0011, 'grad_norm': 0.05720242112874985, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.0840817093849182, 'epoch': 0.0}
{'loss': 0.0026, 'grad_norm': 0.4992349445819855, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 2.626315861940384, 'epoch': 0.0}
{'loss': 0.0073, 'grad_norm': 1.8405216932296753, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 7.281280755996704, 'epoch': 0.0}
{'loss': 0.0139, 'grad_norm': 7.246490478515625, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 678.0, 'kl': 13.871721506118774, 'epoch': 0.0}
{'loss': 0.0061, 'grad_norm': 0.2948355972766876, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 6.138450503349304, 'epoch': 0.0}
{'loss': 0.0023, 'grad_norm': 0.03708339110016823, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 2.2886720299720764, 'epoch': 0.0}
{'loss': 0.0024, 'grad_norm': 0.0928620845079422, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 2.3835248947143555, 'epoch': 0.0}
{'loss': 0.0022, 'grad_norm': 0.08298277109861374, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 2.249206066131592, 'epoch': 0.0}
{'loss': 0.0045, 'grad_norm': 1.1629999876022339, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 4.523498237133026, 'epoch': 0.0}
{'loss': 0.0029, 'grad_norm': 0.626494824886322, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 2.902616500854492, 'epoch': 0.0}
{'train_runtime': 124.8005, 'train_samples_per_second': 0.321, 'train_steps_per_second': 0.08, 'train_loss': 0.004534937103744596, 'epoch': 0.0}
[EP 0066] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  92.125
Cumulative rewards  [-22.275, 135.0875, -0.22499999999999987, -9.8125, -10.65]
Num plays  [6, 34, 9, 9, 9]
Mean rewards  [-3.7125, 3.9731617647058823, -0.024999999999999984, -1.0902777777777777, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 6]
potentials:  [156.76734354  93.29523032  96.          96.         192.        ]
sampled base index:  1
potentials:  [156.76734354  93.29523032  96.          96.         192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.35s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.35s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.28s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.28s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:26, 12.29s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:26, 12.29s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.28s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.28s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.25s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.25s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:48, 12.18s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:48, 12.18s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.18s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.18s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:37<00:24, 12.15s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:37<00:24, 12.15s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:49<00:12, 12.14s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:49<00:12, 12.14s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.13s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.13s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:03<00:00, 12.13s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:03<00:00, 12.36s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.8
wandb:      modelselection/base_3_episodic_reward -1.1375
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_173153-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_173401-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0024, 'grad_norm': 0.05313430353999138, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 2.3542560935020447, 'epoch': 0.0}
{'loss': 0.002, 'grad_norm': 0.027414750307798386, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.9991433918476105, 'epoch': 0.0}
{'loss': 0.0019, 'grad_norm': 0.015249242074787617, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.9195261001586914, 'epoch': 0.0}
{'loss': 0.0019, 'grad_norm': 0.010216981172561646, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.8563040494918823, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.01073179580271244, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.8488570153713226, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.0068517629988491535, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.7694862186908722, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.008264509961009026, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.7556786239147186, 'epoch': 0.0}
{'loss': 0.0019, 'grad_norm': 0.009348331019282341, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.902387946844101, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.010586440563201904, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.8406801223754883, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.007440680637955666, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.7900420427322388, 'epoch': 0.0}
{'train_runtime': 123.5629, 'train_samples_per_second': 0.324, 'train_steps_per_second': 0.081, 'train_loss': 0.0019036362296901642, 'epoch': 0.0}
[EP 0067] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  88.125
Cumulative rewards  [-22.275, 131.0875, -0.22499999999999987, -9.8125, -10.65]
Num plays  [6, 35, 9, 9, 9]
Mean rewards  [-3.7125, 3.745357142857143, -0.024999999999999984, -1.0902777777777777, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 6]
potentials:  [156.76734354  94.65727653  96.          96.         192.        ]
sampled base index:  1
potentials:  [156.76734354  94.65727653  96.          96.         192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.18s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.18s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.11s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.11s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.09s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.09s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.09s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.09s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.13s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.13s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.10s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.10s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.10s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.10s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.10s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.10s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.10s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.10s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.11s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.11s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.11s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.28s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.8
wandb:      modelselection/base_3_episodic_reward -1.1375
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_173401-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_173608-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0018, 'grad_norm': 0.00718875415623188, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.8019947409629822, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.007864941842854023, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.8347912430763245, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.006560945883393288, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.7801612317562103, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.008335083723068237, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.8434864580631256, 'epoch': 0.0}
{'loss': 0.0017, 'grad_norm': 0.004343575332313776, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.7082965672016144, 'epoch': 0.0}
{'loss': 0.002, 'grad_norm': 0.015297897160053253, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.9823387265205383, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.007863865233957767, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.7891739904880524, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.007135240361094475, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.8121030032634735, 'epoch': 0.0}
{'loss': 0.0017, 'grad_norm': 0.007409131620079279, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.7330836653709412, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.009810306131839752, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.7646808326244354, 'epoch': 0.0}
{'train_runtime': 122.8124, 'train_samples_per_second': 0.326, 'train_steps_per_second': 0.081, 'train_loss': 0.0018050111480988561, 'epoch': 0.0}
[EP 0068] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  84.125
Cumulative rewards  [-22.275, 127.0875, -0.22499999999999987, -9.8125, -10.65]
Num plays  [6, 36, 9, 9, 9]
Mean rewards  [-3.7125, 3.5302083333333334, -0.024999999999999984, -1.0902777777777777, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 6]
potentials:  [156.76734354  96.          96.          96.         192.        ]
sampled base index:  1
potentials:  [156.76734354  96.          96.          96.         192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.38s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.38s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.32s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.32s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:26, 12.32s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:26, 12.32s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.30s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.30s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.33s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.33s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.30s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.30s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.31s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.31s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.30s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.30s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.31s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.31s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:03<00:00, 12.29s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:03<00:00, 12.29s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.29s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.48s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.8
wandb:      modelselection/base_3_episodic_reward -1.1375
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_173608-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_173817-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0018, 'grad_norm': 0.006091749761253595, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.7574148178100586, 'epoch': 0.0}
{'loss': 0.0017, 'grad_norm': 0.0060302200727164745, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.6865885257720947, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.007761859335005283, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.8076336681842804, 'epoch': 0.0}
{'loss': 0.0017, 'grad_norm': 0.004559245426207781, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.6866259574890137, 'epoch': 0.0}
{'loss': 0.0017, 'grad_norm': 0.0033631413243710995, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.6533634662628174, 'epoch': 0.0}
{'loss': 0.0017, 'grad_norm': 0.00726564833894372, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.7493835985660553, 'epoch': 0.0}
{'loss': 0.0017, 'grad_norm': 0.006866760551929474, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.6591086983680725, 'epoch': 0.0}
{'loss': 0.0017, 'grad_norm': 0.005610731430351734, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.6834590137004852, 'epoch': 0.0}
{'loss': 0.0017, 'grad_norm': 0.005405515898019075, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.6964907944202423, 'epoch': 0.0}
{'loss': 0.0018, 'grad_norm': 0.010915097780525684, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.7940025627613068, 'epoch': 0.0}
{'train_runtime': 124.84, 'train_samples_per_second': 0.32, 'train_steps_per_second': 0.08, 'train_loss': 0.0017174072097986936, 'epoch': 0.0}
[EP 0069] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  80.125
Cumulative rewards  [-22.275, 123.0875, -0.22499999999999987, -9.8125, -10.65]
Num plays  [6, 37, 9, 9, 9]
Mean rewards  [-3.7125, 3.326689189189189, -0.024999999999999984, -1.0902777777777777, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 6]
potentials:  [156.76734354  97.32420048  96.          96.         192.        ]
sampled base index:  2
potentials:  [156.76734354  97.32420048  96.          96.         192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:07,  7.53s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:07,  7.53s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:13<00:51,  6.38s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:13<00:51,  6.38s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:40,  5.74s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:40,  5.74s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:35,  5.94s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:35,  5.94s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:32,  6.42s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:32,  6.42s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:35<00:22,  5.72s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:35<00:22,  5.72s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:41<00:17,  5.70s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:41<00:17,  5.70s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:47<00:11,  5.87s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:47<00:11,  5.87s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:53<00:05,  5.74s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:53<00:05,  5.74s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:58<00:00,  5.67s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:58<00:00,  5.67s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  5.67s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  6.07s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.8
wandb:      modelselection/base_3_episodic_reward -1.1375
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_173817-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_173921-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.4181422293186188, 'learning_rate': 1e-05, 'num_tokens': 1817.0, 'completions/mean_length': 288.25, 'completions/min_length': 231.0, 'completions/max_length': 403.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 288.25, 'completions/min_terminated_length': 231.0, 'completions/max_terminated_length': 403.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 288.25, 'kl': 0.007667974103242159, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3833925127983093, 'learning_rate': 1e-05, 'num_tokens': 3142.0, 'completions/mean_length': 206.25, 'completions/min_length': 153.0, 'completions/max_length': 273.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 206.25, 'completions/min_terminated_length': 153.0, 'completions/max_terminated_length': 273.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 206.25, 'kl': 0.034696331596933305, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5768890380859375, 'learning_rate': 1e-05, 'num_tokens': 4350.0, 'completions/mean_length': 179.0, 'completions/min_length': 129.0, 'completions/max_length': 231.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 179.0, 'completions/min_terminated_length': 129.0, 'completions/max_terminated_length': 231.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 179.0, 'kl': 0.02713500219397247, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3117179870605469, 'learning_rate': 1e-05, 'num_tokens': 6106.0, 'completions/mean_length': 289.0, 'completions/min_length': 251.0, 'completions/max_length': 321.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 289.0, 'completions/min_terminated_length': 251.0, 'completions/max_terminated_length': 321.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': -0.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 289.0, 'kl': 0.013538829050958157, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.35081490874290466, 'learning_rate': 1e-05, 'num_tokens': 7833.0, 'completions/mean_length': 275.75, 'completions/min_length': 216.0, 'completions/max_length': 385.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 275.75, 'completions/min_terminated_length': 216.0, 'completions/max_terminated_length': 385.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.125, 'reward_std': 1.75, 'frac_reward_zero_std': 0.0, 'completion_length': 275.75, 'kl': 0.010113575146533549, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5829665064811707, 'learning_rate': 1e-05, 'num_tokens': 8973.0, 'completions/mean_length': 157.0, 'completions/min_length': 112.0, 'completions/max_length': 192.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 157.0, 'completions/min_terminated_length': 112.0, 'completions/max_terminated_length': 192.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 157.0, 'kl': 0.01857218868099153, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0007451225537806749, 'learning_rate': 1e-05, 'num_tokens': 10208.0, 'completions/mean_length': 169.75, 'completions/min_length': 110.0, 'completions/max_length': 275.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 169.75, 'completions/min_terminated_length': 110.0, 'completions/max_terminated_length': 275.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 169.75, 'kl': 0.019621657207608223, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3315088450908661, 'learning_rate': 1e-05, 'num_tokens': 11712.0, 'completions/mean_length': 235.0, 'completions/min_length': 151.0, 'completions/max_length': 316.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 235.0, 'completions/min_terminated_length': 151.0, 'completions/max_terminated_length': 316.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 235.0, 'kl': 0.019141679164022207, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3972116708755493, 'learning_rate': 1e-05, 'num_tokens': 13012.0, 'completions/mean_length': 194.0, 'completions/min_length': 161.0, 'completions/max_length': 263.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 194.0, 'completions/min_terminated_length': 161.0, 'completions/max_terminated_length': 263.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 194.0, 'kl': 0.015657600481063128, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3715468645095825, 'learning_rate': 1e-05, 'num_tokens': 14085.0, 'completions/mean_length': 162.25, 'completions/min_length': 117.0, 'completions/max_length': 265.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 162.25, 'completions/min_terminated_length': 117.0, 'completions/max_terminated_length': 265.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 162.25, 'kl': 0.014205490588210523, 'epoch': 0.0}
{'train_runtime': 60.6808, 'train_samples_per_second': 0.659, 'train_steps_per_second': 0.165, 'train_loss': 1.8050949438475073e-05, 'epoch': 0.0}
[EP 0070] 2 | reward_mean=0.850 | 
*** stats:  {'episode_reward_mean': 0.85, 'episode_reward_last': 1.125, 'episode_reward_std_mean': 0.9673048973083496, 'episode_reward_trajectory': [-1.5, 1.625, 1.125, -0.25, 1.125, 1.5, 2.0, 0.75, 1.0, 1.125], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.2, 'rewards/match_format_approximately/mean/last': 0.125, 'rewards/match_format_approximately/std/mean': 0.36861406564712523, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.65, 'rewards/check_numbers/mean/last': 1.0, 'rewards/check_numbers/std/mean': 0.7301502287387848, 'rewards/check_numbers/std/last': 1.0}
Curr reward  0.85
All rewards  80.975
Cumulative rewards  [-22.275, 123.0875, 0.6250000000000001, -9.8125, -10.65]
Num plays  [6, 37, 10, 9, 9]
Mean rewards  [-3.7125, 3.326689189189189, 0.06250000000000001, -1.0902777777777777, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 4, 5, 5, 6]
potentials:  [156.76734354  97.32420048 101.19288513  96.         192.        ]
sampled base index:  3
potentials:  [156.76734354  97.32420048 101.19288513  96.         192.        ]
sampled base index:  3
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:05,  7.29s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:05,  7.29s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:18<01:15,  9.40s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:18<01:15,  9.40s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:52,  7.47s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:52,  7.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:29<00:42,  7.11s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:29<00:42,  7.11s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:35<00:33,  6.71s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:35<00:33,  6.71s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:40<00:23,  5.94s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:40<00:23,  5.94s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:45<00:16,  5.66s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:45<00:16,  5.66s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:50<00:11,  5.51s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:50<00:11,  5.51s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:57<00:05,  5.84s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:57<00:05,  5.84s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  5.52s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:01<00:00,  5.52s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:04<00:00,  5.52s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:04<00:00,  6.42s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.85
wandb:      modelselection/base_3_episodic_reward -1.1375
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 0.85
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_173921-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_174030-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.3953797221183777, 'learning_rate': 1e-06, 'num_tokens': 2065.0, 'completions/mean_length': 350.25, 'completions/min_length': 255.0, 'completions/max_length': 400.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 350.25, 'completions/min_terminated_length': 255.0, 'completions/max_terminated_length': 400.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -2.625, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 350.25, 'kl': 0.0008010966557776555, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3280111849308014, 'learning_rate': 1e-06, 'num_tokens': 3850.0, 'completions/mean_length': 321.25, 'completions/min_length': 161.0, 'completions/max_length': 648.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 321.25, 'completions/min_terminated_length': 161.0, 'completions/max_terminated_length': 648.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.0, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 321.25, 'kl': 0.00039112196100177243, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.8554751873016357, 'learning_rate': 1e-06, 'num_tokens': 5096.0, 'completions/mean_length': 188.5, 'completions/min_length': 114.0, 'completions/max_length': 253.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 188.5, 'completions/min_terminated_length': 114.0, 'completions/max_terminated_length': 253.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.375, 'reward_std': 1.6007810831069946, 'frac_reward_zero_std': 0.0, 'completion_length': 188.5, 'kl': 0.000513444156240439, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.2820892632007599, 'learning_rate': 1e-06, 'num_tokens': 6884.0, 'completions/mean_length': 297.0, 'completions/min_length': 254.0, 'completions/max_length': 349.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 297.0, 'completions/min_terminated_length': 254.0, 'completions/max_terminated_length': 349.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.75, 'reward_std': 0.5, 'frac_reward_zero_std': 0.0, 'completion_length': 297.0, 'kl': 0.00046527919766958803, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.37057986855506897, 'learning_rate': 1e-06, 'num_tokens': 8517.0, 'completions/mean_length': 252.25, 'completions/min_length': 205.0, 'completions/max_length': 307.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 252.25, 'completions/min_terminated_length': 205.0, 'completions/max_terminated_length': 307.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.875, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 252.25, 'kl': 0.0005006324863643385, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.38827234506607056, 'learning_rate': 1e-06, 'num_tokens': 9660.0, 'completions/mean_length': 157.75, 'completions/min_length': 115.0, 'completions/max_length': 203.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 157.75, 'completions/min_terminated_length': 115.0, 'completions/max_terminated_length': 203.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 157.75, 'kl': 0.0007175963910412975, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.49118924140930176, 'learning_rate': 1e-06, 'num_tokens': 11042.0, 'completions/mean_length': 206.5, 'completions/min_length': 167.0, 'completions/max_length': 246.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 206.5, 'completions/min_terminated_length': 167.0, 'completions/max_terminated_length': 246.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': -0.5, 'reward_std': 0.9128709435462952, 'frac_reward_zero_std': 0.0, 'completion_length': 206.5, 'kl': 0.0004834632491110824, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.46844542026519775, 'learning_rate': 1e-06, 'num_tokens': 12471.0, 'completions/mean_length': 216.25, 'completions/min_length': 174.0, 'completions/max_length': 253.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 216.25, 'completions/min_terminated_length': 174.0, 'completions/max_terminated_length': 253.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 216.25, 'kl': 0.00198343596275663, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.36694321036338806, 'learning_rate': 1e-06, 'num_tokens': 14013.0, 'completions/mean_length': 254.5, 'completions/min_length': 166.0, 'completions/max_length': 352.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 254.5, 'completions/min_terminated_length': 166.0, 'completions/max_terminated_length': 352.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 1.4361406564712524, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -0.875, 'reward_std': 1.5478479862213135, 'frac_reward_zero_std': 0.0, 'completion_length': 254.5, 'kl': 0.00042133098031627014, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.47005710005760193, 'learning_rate': 1e-06, 'num_tokens': 15055.0, 'completions/mean_length': 154.5, 'completions/min_length': 123.0, 'completions/max_length': 224.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 154.5, 'completions/min_terminated_length': 123.0, 'completions/max_terminated_length': 224.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.0, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 154.5, 'kl': 0.0007878784235799685, 'epoch': 0.0}
{'train_runtime': 64.1932, 'train_samples_per_second': 0.623, 'train_steps_per_second': 0.156, 'train_loss': 7.100403308868408e-07, 'epoch': 0.0}
[EP 0071] 3 | reward_mean=-1.000 | 
*** stats:  {'episode_reward_mean': -1.0, 'episode_reward_last': 0.0, 'episode_reward_std_mean': 1.0567021310329436, 'episode_reward_trajectory': [-2.625, -1.0, -0.375, -0.75, -1.875, -0.625, -0.5, -1.375, -0.875, 0.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.15, 'rewards/match_format_approximately/mean/last': -1.0, 'rewards/match_format_approximately/std/mean': 0.7910885572433471, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.15, 'rewards/check_numbers/mean/last': 1.0, 'rewards/check_numbers/std/mean': 0.5351185262203216, 'rewards/check_numbers/std/last': 1.0}
Curr reward  -1.0
All rewards  79.975
Cumulative rewards  [-22.275, 123.0875, 0.6250000000000001, -10.8125, -10.65]
Num plays  [6, 37, 10, 10, 9]
Mean rewards  [-3.7125, 3.326689189189189, 0.06250000000000001, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 0, 1, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354  97.32420048 101.19288513 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354  97.32420048 101.19288513 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.32s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.32s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.28s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.28s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.27s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.27s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.28s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.28s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.30s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.30s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:48, 12.21s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:48, 12.21s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.20s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.20s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:37<00:24, 12.17s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:37<00:24, 12.17s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:49<00:12, 12.17s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:49<00:12, 12.17s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.13s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.13s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:03<00:00, 12.13s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:03<00:00, 12.37s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_3_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.85
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1
wandb:       modelselection/selected_base_learner 3
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_174030-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_174238-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0017, 'grad_norm': 0.005460795946419239, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.680440217256546, 'epoch': 0.0}
{'loss': 0.0016, 'grad_norm': 0.004450088366866112, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.6004187762737274, 'epoch': 0.0}
{'loss': 0.0017, 'grad_norm': 0.006514886859804392, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.680489420890808, 'epoch': 0.0}
{'loss': 0.0016, 'grad_norm': 0.005127792712301016, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.607284665107727, 'epoch': 0.0}
{'loss': 0.0016, 'grad_norm': 0.0034272486809641123, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.579291045665741, 'epoch': 0.0}
{'loss': 0.0017, 'grad_norm': 0.005755471996963024, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.6521473824977875, 'epoch': 0.0}
{'loss': 0.0016, 'grad_norm': 0.0041998387314379215, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.5633597075939178, 'epoch': 0.0}
{'loss': 0.0016, 'grad_norm': 0.005530442576855421, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.5976999998092651, 'epoch': 0.0}
{'loss': 0.0016, 'grad_norm': 0.004977857694029808, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.6079679429531097, 'epoch': 0.0}
{'loss': 0.0016, 'grad_norm': 0.006518254056572914, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.6043877601623535, 'epoch': 0.0}
{'train_runtime': 123.7333, 'train_samples_per_second': 0.323, 'train_steps_per_second': 0.081, 'train_loss': 0.0016173487761989235, 'epoch': 0.0}
[EP 0072] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  75.975
Cumulative rewards  [-22.275, 119.0875, 0.6250000000000001, -10.8125, -10.65]
Num plays  [6, 38, 10, 10, 9]
Mean rewards  [-3.7125, 3.1338815789473684, 0.06250000000000001, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354  98.63062405 101.19288513 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354  98.63062405 101.19288513 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.34s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.34s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.29s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.29s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.28s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.28s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.28s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.28s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.30s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.30s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.28s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.28s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.29s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.29s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.29s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.29s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.29s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.29s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.29s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.29s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.29s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.47s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.85
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_174238-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_174447-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0015, 'grad_norm': 0.004477236419916153, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.5449531078338623, 'epoch': 0.0}
{'loss': 0.0015, 'grad_norm': 0.004964516032487154, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.5248109102249146, 'epoch': 0.0}
{'loss': 0.0015, 'grad_norm': 0.00455442676320672, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.5379263758659363, 'epoch': 0.0}
{'loss': 0.0016, 'grad_norm': 0.005678435787558556, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.6226803958415985, 'epoch': 0.0}
{'loss': 0.0015, 'grad_norm': 0.0032338586170226336, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.4824378192424774, 'epoch': 0.0}
{'loss': 0.0016, 'grad_norm': 0.005411510355770588, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.5583980083465576, 'epoch': 0.0}
{'loss': 0.0015, 'grad_norm': 0.006076429504901171, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.505625694990158, 'epoch': 0.0}
{'loss': 0.0015, 'grad_norm': 0.005072540603578091, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.499934196472168, 'epoch': 0.0}
{'loss': 0.0015, 'grad_norm': 0.005963441915810108, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.5032419562339783, 'epoch': 0.0}
{'loss': 0.0015, 'grad_norm': 0.00481822993606329, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.5019638538360596, 'epoch': 0.0}
{'train_runtime': 124.6715, 'train_samples_per_second': 0.321, 'train_steps_per_second': 0.08, 'train_loss': 0.0015281972941011191, 'epoch': 0.0}
[EP 0073] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  71.975
Cumulative rewards  [-22.275, 115.0875, 0.6250000000000001, -10.8125, -10.65]
Num plays  [6, 39, 10, 10, 9]
Mean rewards  [-3.7125, 2.9509615384615384, 0.06250000000000001, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354  99.91996797 101.19288513 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354  99.91996797 101.19288513 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.15s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.15s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.10s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.10s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.08s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.08s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.09s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.09s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.10s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.10s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.08s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.08s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.10s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.10s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.10s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.10s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.09s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.09s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.08s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.08s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.08s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.26s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.85
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_174447-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_174653-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0015, 'grad_norm': 0.004660216625779867, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.4749148488044739, 'epoch': 0.0}
{'loss': 0.0015, 'grad_norm': 0.004994304850697517, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.461650162935257, 'epoch': 0.0}
{'loss': 0.0015, 'grad_norm': 0.00853817444294691, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.4931138157844543, 'epoch': 0.0}
{'loss': 0.0015, 'grad_norm': 0.006771900691092014, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.5482282042503357, 'epoch': 0.0}
{'loss': 0.0014, 'grad_norm': 0.004971598740667105, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.383931815624237, 'epoch': 0.0}
{'loss': 0.0014, 'grad_norm': 0.0052908239886164665, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.4488319158554077, 'epoch': 0.0}
{'loss': 0.0014, 'grad_norm': 0.007288761902600527, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.4182669520378113, 'epoch': 0.0}
{'loss': 0.0013, 'grad_norm': 0.006563794333487749, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.3318405449390411, 'epoch': 0.0}
{'loss': 0.0013, 'grad_norm': 0.008218305185437202, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.304701328277588, 'epoch': 0.0}
{'loss': 0.0014, 'grad_norm': 0.008451412431895733, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.3555940985679626, 'epoch': 0.0}
{'train_runtime': 122.6272, 'train_samples_per_second': 0.326, 'train_steps_per_second': 0.082, 'train_loss': 0.0014221074641682207, 'epoch': 0.0}
[EP 0074] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  67.975
Cumulative rewards  [-22.275, 111.0875, 0.6250000000000001, -10.8125, -10.65]
Num plays  [6, 40, 10, 10, 9]
Mean rewards  [-3.7125, 2.7771875, 0.06250000000000001, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 101.19288513 101.19288513 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 101.19288513 101.19288513 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.33s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.33s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.31s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.31s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.28s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.28s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.29s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.29s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.30s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.30s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.28s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.28s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.28s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.28s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.29s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.29s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.29s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.29s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.29s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.29s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.29s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.47s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.85
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_174653-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_174907-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0012, 'grad_norm': 0.0077185495756566525, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.2100140154361725, 'epoch': 0.0}
{'loss': 0.0012, 'grad_norm': 0.009880305267870426, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.2203757464885712, 'epoch': 0.0}
{'loss': 0.0012, 'grad_norm': 0.007002155762165785, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.1638552248477936, 'epoch': 0.0}
{'loss': 0.0012, 'grad_norm': 0.01037564780563116, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.2282733917236328, 'epoch': 0.0}
{'loss': 0.0011, 'grad_norm': 0.009473007172346115, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.07582189142704, 'epoch': 0.0}
{'loss': 0.001, 'grad_norm': 0.008708847686648369, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.0012422800064087, 'epoch': 0.0}
{'loss': 0.001, 'grad_norm': 0.010351807810366154, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 1.009582668542862, 'epoch': 0.0}
{'loss': 0.0009, 'grad_norm': 0.007431649137288332, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.9046714752912521, 'epoch': 0.0}
{'loss': 0.0009, 'grad_norm': 0.007590450346469879, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.8788542449474335, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.008908749558031559, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.8419886231422424, 'epoch': 0.0}
{'train_runtime': 124.7018, 'train_samples_per_second': 0.321, 'train_steps_per_second': 0.08, 'train_loss': 0.0010534680215641857, 'epoch': 0.0}
[EP 0075] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  63.974999999999994
Cumulative rewards  [-22.275, 107.0875, 0.6250000000000001, -10.8125, -10.65]
Num plays  [6, 41, 10, 10, 9]
Mean rewards  [-3.7125, 2.611890243902439, 0.06250000000000001, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 102.4499878  101.19288513 202.38577025 192.        ]
sampled base index:  2
potentials:  [156.76734354 102.4499878  101.19288513 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.44s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.44s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:17<01:04,  8.12s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:17<01:04,  8.12s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:50,  7.26s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:23<00:50,  7.26s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:33<00:49,  8.33s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:33<00:49,  8.33s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:39<00:37,  7.49s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:39<00:37,  7.49s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:44<00:26,  6.55s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:44<00:26,  6.55s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:48<00:17,  5.71s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:48<00:17,  5.71s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:53<00:10,  5.39s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:53<00:10,  5.39s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:57<00:05,  5.20s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:57<00:05,  5.20s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:06<00:00,  6.17s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:06<00:00,  6.17s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:08<00:00,  6.17s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:08<00:00,  6.81s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.85
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_174907-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_175019-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.2526332437992096, 'learning_rate': 1e-05, 'num_tokens': 2379.0, 'completions/mean_length': 428.75, 'completions/min_length': 283.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 326.3333435058594, 'completions/min_terminated_length': 283.0, 'completions/max_terminated_length': 350.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': -0.25, 'reward_std': 0.5, 'frac_reward_zero_std': 0.0, 'completion_length': 428.75, 'kl': 0.006213628745172173, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3521234691143036, 'learning_rate': 1e-05, 'num_tokens': 3728.0, 'completions/mean_length': 212.25, 'completions/min_length': 179.0, 'completions/max_length': 239.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 212.25, 'completions/min_terminated_length': 179.0, 'completions/max_terminated_length': 239.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 212.25, 'kl': 0.015027479501441121, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.36596667766571045, 'learning_rate': 1e-05, 'num_tokens': 5063.0, 'completions/mean_length': 210.75, 'completions/min_length': 165.0, 'completions/max_length': 317.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 210.75, 'completions/min_terminated_length': 165.0, 'completions/max_terminated_length': 317.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 210.75, 'kl': 0.017571483738720417, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0007748460629954934, 'learning_rate': 1e-05, 'num_tokens': 7424.0, 'completions/mean_length': 440.25, 'completions/min_length': 253.0, 'completions/max_length': 582.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 440.25, 'completions/min_terminated_length': 253.0, 'completions/max_terminated_length': 582.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 440.25, 'kl': 0.019853265897836536, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3333602249622345, 'learning_rate': 1e-05, 'num_tokens': 9126.0, 'completions/mean_length': 269.5, 'completions/min_length': 236.0, 'completions/max_length': 299.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 269.5, 'completions/min_terminated_length': 236.0, 'completions/max_terminated_length': 299.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 269.5, 'kl': 0.02088831935543567, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.001204668078571558, 'learning_rate': 1e-05, 'num_tokens': 10393.0, 'completions/mean_length': 188.75, 'completions/min_length': 157.0, 'completions/max_length': 214.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 188.75, 'completions/min_terminated_length': 157.0, 'completions/max_terminated_length': 214.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 188.75, 'kl': 0.02999106957577169, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0011247635120525956, 'learning_rate': 1e-05, 'num_tokens': 11515.0, 'completions/mean_length': 141.5, 'completions/min_length': 118.0, 'completions/max_length': 164.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 141.5, 'completions/min_terminated_length': 118.0, 'completions/max_terminated_length': 164.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 141.5, 'kl': 0.03173520206473768, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.26979389786720276, 'learning_rate': 1e-05, 'num_tokens': 12796.0, 'completions/mean_length': 179.25, 'completions/min_length': 152.0, 'completions/max_length': 213.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 179.25, 'completions/min_terminated_length': 152.0, 'completions/max_terminated_length': 213.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 179.25, 'kl': 0.011804858455434442, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5764550566673279, 'learning_rate': 1e-05, 'num_tokens': 14030.0, 'completions/mean_length': 177.5, 'completions/min_length': 152.0, 'completions/max_length': 218.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 177.5, 'completions/min_terminated_length': 152.0, 'completions/max_terminated_length': 218.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.25, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 177.5, 'kl': 0.03606418939307332, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5306695699691772, 'learning_rate': 1e-05, 'num_tokens': 15339.0, 'completions/mean_length': 221.25, 'completions/min_length': 127.0, 'completions/max_length': 458.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 221.25, 'completions/min_terminated_length': 127.0, 'completions/max_terminated_length': 458.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 221.25, 'kl': 0.017121647601015866, 'epoch': 0.0}
{'train_runtime': 68.052, 'train_samples_per_second': 0.588, 'train_steps_per_second': 0.147, 'train_loss': 2.0635441615013406e-05, 'epoch': 0.0}
[EP 0076] 2 | reward_mean=1.125 | 
*** stats:  {'episode_reward_mean': 1.125, 'episode_reward_last': 1.125, 'episode_reward_std_mean': 0.7216253280639648, 'episode_reward_trajectory': [-0.25, 1.5, 1.5, 0.0, 1.0, 2.0, 2.0, 1.125, 1.25, 1.125], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.425, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.15, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.7, 'rewards/check_numbers/mean/last': 0.625, 'rewards/check_numbers/std/mean': 0.6216253280639649, 'rewards/check_numbers/std/last': 1.0307763814926147}
Curr reward  1.125
All rewards  65.1
Cumulative rewards  [-22.275, 107.0875, 1.75, -10.8125, -10.65]
Num plays  [6, 41, 11, 10, 9]
Mean rewards  [-3.7125, 2.611890243902439, 0.1590909090909091, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 102.4499878  106.13199329 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 102.4499878  106.13199329 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.14s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.14s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.09s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.09s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.07s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.07s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.08s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.08s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.10s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.10s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.09s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.09s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.11s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.11s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.12s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.12s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.13s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.13s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.12s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.12s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.12s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.28s/it]
wandb: updating run metadata
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.125
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.125
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_175019-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_175227-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0008, 'grad_norm': 0.008039426989853382, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.762324869632721, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.006985025014728308, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.7624385952949524, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.007942491210997105, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.77534019947052, 'epoch': 0.0}
{'loss': 0.0007, 'grad_norm': 0.005181608255952597, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.6851669102907181, 'epoch': 0.0}
{'loss': 0.0007, 'grad_norm': 0.006344370078295469, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.681962788105011, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.004862777888774872, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.5854081809520721, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.005914607085287571, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.6414054781198502, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.00509395869448781, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.5837982296943665, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.0053373100236058235, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.5489336550235748, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.003946593496948481, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.564613476395607, 'epoch': 0.0}
{'train_runtime': 122.8057, 'train_samples_per_second': 0.326, 'train_steps_per_second': 0.081, 'train_loss': 0.0006591392739210278, 'epoch': 0.0}
[EP 0077] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  61.099999999999994
Cumulative rewards  [-22.275, 103.0875, 1.75, -10.8125, -10.65]
Num plays  [6, 42, 11, 10, 9]
Mean rewards  [-3.7125, 2.4544642857142858, 0.1590909090909091, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 103.69185117 106.13199329 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 103.69185117 106.13199329 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.16s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.16s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.10s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.10s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.11s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.11s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.10s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.10s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.11s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.11s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.09s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.09s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.10s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.10s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.10s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.10s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.10s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.10s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.08s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.08s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.08s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.28s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.125
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_175227-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_175433-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0005, 'grad_norm': 0.004521588794887066, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.5059976205229759, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.005210538860410452, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.5256328135728836, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.004492717329412699, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.5079014971852303, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.0041646589525043964, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.47654756158590317, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.003220682730898261, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.4624832570552826, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.0032547139562666416, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.45101115107536316, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.0039248988032341, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.4589565023779869, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.003332131775096059, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.4383716434240341, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.004685374442487955, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.41467995941638947, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.00477443216368556, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.41730915755033493, 'epoch': 0.0}
{'train_runtime': 122.7802, 'train_samples_per_second': 0.326, 'train_steps_per_second': 0.081, 'train_loss': 0.0004658891499275342, 'epoch': 0.0}
[EP 0078] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  57.099999999999994
Cumulative rewards  [-22.275, 99.0875, 1.75, -10.8125, -10.65]
Num plays  [6, 43, 11, 10, 9]
Mean rewards  [-3.7125, 2.3043604651162792, 0.1590909090909091, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 104.91901639 106.13199329 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 104.91901639 106.13199329 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.32s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.32s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.27s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.27s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.21s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.21s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.17s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.17s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.15s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.15s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.12s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.12s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.11s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.11s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:37<00:24, 12.10s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:37<00:24, 12.10s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:49<00:12, 12.10s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:49<00:12, 12.10s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.08s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.08s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:03<00:00, 12.08s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:03<00:00, 12.31s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.125
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_175433-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_175640-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0004, 'grad_norm': 0.003336692228913307, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.39532265067100525, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.002964835613965988, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.4108038991689682, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.003860912751406431, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.41259845346212387, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.0021738845389336348, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3602680414915085, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.0019031441770493984, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.385232113301754, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.004455609247088432, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3840789571404457, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.0028016199357807636, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3982711508870125, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.0022724501322954893, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3764994889497757, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.002317217644304037, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.36158279329538345, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.002215866930782795, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.36126334220170975, 'epoch': 0.0}
{'train_runtime': 123.0742, 'train_samples_per_second': 0.325, 'train_steps_per_second': 0.081, 'train_loss': 0.0003845921135507524, 'epoch': 0.0}
[EP 0079] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  53.099999999999994
Cumulative rewards  [-22.275, 95.0875, 1.75, -10.8125, -10.65]
Num plays  [6, 44, 11, 10, 9]
Mean rewards  [-3.7125, 2.1610795454545455, 0.1590909090909091, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 106.13199329 106.13199329 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 106.13199329 106.13199329 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.33s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.33s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.27s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.27s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.26s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.26s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.26s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.26s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.28s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.28s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.26s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.26s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.26s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.26s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.26s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.26s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.25s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.25s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.24s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.24s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.24s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.43s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.125
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_175640-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_175848-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0004, 'grad_norm': 0.0019237359520047903, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.35946983098983765, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.002898037200793624, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3527694121003151, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.002793902764096856, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.38997428864240646, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.00210990640334785, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.34232695400714874, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.0034297513775527477, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.35519078373908997, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0018133778357878327, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.33981871604919434, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.001889641396701336, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.359958715736866, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0017898385412991047, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.34340113401412964, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0015468162018805742, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.33007803559303284, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.001431237324140966, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3245779350399971, 'epoch': 0.0}
{'train_runtime': 124.3092, 'train_samples_per_second': 0.322, 'train_steps_per_second': 0.08, 'train_loss': 0.00034975659509655087, 'epoch': 0.0}
[EP 0080] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  49.099999999999994
Cumulative rewards  [-22.275, 91.0875, 1.75, -10.8125, -10.65]
Num plays  [6, 45, 11, 10, 9]
Mean rewards  [-3.7125, 2.024166666666667, 0.1590909090909091, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 107.33126292 106.13199329 202.38577025 192.        ]
sampled base index:  2
potentials:  [156.76734354 107.33126292 106.13199329 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.25s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.25s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:17<01:03,  7.96s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:17<01:03,  7.96s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:43,  6.21s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:43,  6.21s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:30<00:43,  7.29s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:30<00:43,  7.29s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:38<00:38,  7.61s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:38<00:38,  7.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:26,  6.52s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:26,  6.52s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:47<00:18,  6.01s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:47<00:18,  6.01s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:52<00:11,  5.53s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:52<00:11,  5.53s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:03<00:07,  7.19s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:03<00:07,  7.19s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:07<00:00,  6.46s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:07<00:00,  6.46s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:09<00:00,  6.46s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:09<00:00,  6.97s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.125
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_175848-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_180002-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.28224217891693115, 'learning_rate': 1e-05, 'num_tokens': 2403.0, 'completions/mean_length': 434.75, 'completions/min_length': 296.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 334.3333435058594, 'completions/min_terminated_length': 296.0, 'completions/max_terminated_length': 363.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': -0.625, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 434.75, 'kl': 0.008990243193693459, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.33608731627464294, 'learning_rate': 1e-05, 'num_tokens': 3732.0, 'completions/mean_length': 207.25, 'completions/min_length': 179.0, 'completions/max_length': 239.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 207.25, 'completions/min_terminated_length': 179.0, 'completions/max_terminated_length': 239.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 207.25, 'kl': 0.014002424431964755, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00029314623679965734, 'learning_rate': 1e-05, 'num_tokens': 4922.0, 'completions/mean_length': 174.5, 'completions/min_length': 165.0, 'completions/max_length': 183.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 174.5, 'completions/min_terminated_length': 165.0, 'completions/max_terminated_length': 183.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 174.5, 'kl': 0.02053614309988916, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00015166135563049465, 'learning_rate': 1e-05, 'num_tokens': 6653.0, 'completions/mean_length': 282.75, 'completions/min_length': 158.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 282.75, 'completions/min_terminated_length': 158.0, 'completions/max_terminated_length': 512.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 282.75, 'kl': 0.010912957601249218, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.2946013808250427, 'learning_rate': 1e-05, 'num_tokens': 8493.0, 'completions/mean_length': 304.0, 'completions/min_length': 210.0, 'completions/max_length': 459.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 304.0, 'completions/min_terminated_length': 210.0, 'completions/max_terminated_length': 459.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 304.0, 'kl': 0.007550473092123866, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4488162696361542, 'learning_rate': 1e-05, 'num_tokens': 9681.0, 'completions/mean_length': 169.0, 'completions/min_length': 138.0, 'completions/max_length': 202.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 169.0, 'completions/min_terminated_length': 138.0, 'completions/max_terminated_length': 202.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 169.0, 'kl': 0.02774937218055129, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.47955116629600525, 'learning_rate': 1e-05, 'num_tokens': 10904.0, 'completions/mean_length': 166.75, 'completions/min_length': 110.0, 'completions/max_length': 238.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 166.75, 'completions/min_terminated_length': 110.0, 'completions/max_terminated_length': 238.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 166.75, 'kl': 0.026378983864560723, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.39352086186408997, 'learning_rate': 1e-05, 'num_tokens': 12146.0, 'completions/mean_length': 169.5, 'completions/min_length': 153.0, 'completions/max_length': 205.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 169.5, 'completions/min_terminated_length': 153.0, 'completions/max_terminated_length': 205.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': 0.625, 'reward_std': 0.9464846849441528, 'frac_reward_zero_std': 0.0, 'completion_length': 169.5, 'kl': 0.029073999729007483, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.2869720757007599, 'learning_rate': 1e-05, 'num_tokens': 13933.0, 'completions/mean_length': 315.75, 'completions/min_length': 188.0, 'completions/max_length': 642.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 315.75, 'completions/min_terminated_length': 188.0, 'completions/max_terminated_length': 642.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 0.875, 'reward_std': 2.25, 'frac_reward_zero_std': 0.0, 'completion_length': 315.75, 'kl': 0.02346340357325971, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4035849869251251, 'learning_rate': 1e-05, 'num_tokens': 14969.0, 'completions/mean_length': 153.0, 'completions/min_length': 125.0, 'completions/max_length': 230.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 153.0, 'completions/min_terminated_length': 125.0, 'completions/max_terminated_length': 230.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 153.0, 'kl': 0.030548062175512314, 'epoch': 0.0}
{'train_runtime': 69.7168, 'train_samples_per_second': 0.574, 'train_steps_per_second': 0.143, 'train_loss': 1.993032319660415e-05, 'epoch': 0.0}
[EP 0081] 2 | reward_mean=0.950 | 
*** stats:  {'episode_reward_mean': 0.95, 'episode_reward_last': 1.125, 'episode_reward_std_mean': 0.9631961584091187, 'episode_reward_trajectory': [-0.625, 1.5, 2.0, 0.0, 1.5, 1.5, 1.0, 0.625, 0.875, 1.125], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.35, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.3, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.6, 'rewards/check_numbers/mean/last': 0.625, 'rewards/check_numbers/std/mean': 0.7131961643695831, 'rewards/check_numbers/std/last': 1.0307763814926147}
Curr reward  0.95
All rewards  50.05
Cumulative rewards  [-22.275, 91.0875, 2.7, -10.8125, -10.65]
Num plays  [6, 45, 12, 10, 9]
Mean rewards  [-3.7125, 2.024166666666667, 0.225, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 107.33126292 110.85125168 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 107.33126292 110.85125168 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.31s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.31s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.26s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.26s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.24s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.24s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.25s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.25s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.27s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.27s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:48, 12.25s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:48, 12.25s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.25s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.25s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.24s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.24s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.25s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.25s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.24s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.24s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.24s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.42s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.95
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 0.95
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_180002-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_180211-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0003, 'grad_norm': 0.0015916904667392373, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.33008527010679245, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0014938546810299158, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.33079350739717484, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.002150108804926276, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3485957831144333, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0018844750011339784, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3110520541667938, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.001970800803974271, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3171628639101982, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.002011299831792712, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3191577419638634, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0012872437946498394, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3357243686914444, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0009796161903068423, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.32206473499536514, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0017081291880458593, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3095196858048439, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0016234995564445853, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3147706389427185, 'epoch': 0.0}
{'train_runtime': 124.2077, 'train_samples_per_second': 0.322, 'train_steps_per_second': 0.081, 'train_loss': 0.00032389268162660303, 'epoch': 0.0}
[EP 0082] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  46.05
Cumulative rewards  [-22.275, 87.0875, 2.7, -10.8125, -10.65]
Num plays  [6, 46, 12, 10, 9]
Mean rewards  [-3.7125, 1.8932065217391305, 0.225, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 108.51727973 110.85125168 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 108.51727973 110.85125168 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.42s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.42s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.34s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.34s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.28s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.28s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.29s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.29s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.28s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.28s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:48, 12.22s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:48, 12.22s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.18s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.18s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:37<00:24, 12.20s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:37<00:24, 12.20s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.22s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.22s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.23s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.23s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.23s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.42s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.95
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_180211-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_180419-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0003, 'grad_norm': 0.0014524973230436444, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3132285103201866, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0017121514538303018, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3247987776994705, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0014450378948822618, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.33088117837905884, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0012120718602091074, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.28840087354183197, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0012701944215223193, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3021925389766693, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0023099048994481564, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.301972933113575, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0018730497686192393, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.30883583426475525, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.001447730348445475, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3046196922659874, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0010891457786783576, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3009793870151043, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0009452528320252895, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.29384197294712067, 'epoch': 0.0}
{'train_runtime': 124.2221, 'train_samples_per_second': 0.322, 'train_steps_per_second': 0.081, 'train_loss': 0.0003069751866860315, 'epoch': 0.0}
[EP 0083] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  42.05
Cumulative rewards  [-22.275, 83.0875, 2.7, -10.8125, -10.65]
Num plays  [6, 47, 12, 10, 9]
Mean rewards  [-3.7125, 1.7678191489361703, 0.225, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 109.69047361 110.85125168 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 109.69047361 110.85125168 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.30s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.30s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.28s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.28s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.25s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.25s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.28s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.28s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.30s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.30s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.27s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.27s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.28s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.28s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.27s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.27s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.28s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.28s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.26s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.26s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.26s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.45s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.95
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_180419-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_180627-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0003, 'grad_norm': 0.0012452559312805533, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.30151552706956863, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0017829377902671695, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.31160347908735275, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0018793623894453049, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.31255970150232315, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.000932145572733134, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.27541008591651917, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0013256865786388516, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2916256785392761, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0021052416414022446, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2960340827703476, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0016817853320389986, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.30246303230524063, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.001201694831252098, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.29969487339258194, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0011259389575570822, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.29491879418492317, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0009545987122692168, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.28237420320510864, 'epoch': 0.0}
{'train_runtime': 124.5471, 'train_samples_per_second': 0.321, 'train_steps_per_second': 0.08, 'train_loss': 0.000296819960931316, 'epoch': 0.0}
[EP 0084] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  38.05
Cumulative rewards  [-22.275, 79.0875, 2.7, -10.8125, -10.65]
Num plays  [6, 48, 12, 10, 9]
Mean rewards  [-3.7125, 1.64765625, 0.225, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 110.85125168 110.85125168 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 110.85125168 110.85125168 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.30s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.30s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.26s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.26s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.24s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.24s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.25s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.25s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.28s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.28s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.26s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.26s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.28s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.28s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.27s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.27s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.29s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.29s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.28s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.28s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.28s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.46s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.95
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_180627-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_180836-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0003, 'grad_norm': 0.0012105482164770365, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.29182882234454155, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.001248419051989913, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.3000338524580002, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.00158192147500813, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.30786454677581787, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0008312931749969721, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.26422421634197235, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0011939750984311104, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2856864482164383, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0017952016787603498, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2814091444015503, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0016445930814370513, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.290669746696949, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0010830526007339358, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.29095546156167984, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0009449014323763549, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2885030433535576, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0008627237402833998, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.27089786529541016, 'epoch': 0.0}
{'train_runtime': 124.6314, 'train_samples_per_second': 0.321, 'train_steps_per_second': 0.08, 'train_loss': 0.0002872073237085715, 'epoch': 0.0}
[EP 0085] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  34.05
Cumulative rewards  [-22.275, 75.0875, 2.7, -10.8125, -10.65]
Num plays  [6, 49, 12, 10, 9]
Mean rewards  [-3.7125, 1.5323979591836736, 0.225, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 112.         110.85125168 202.38577025 192.        ]
sampled base index:  2
potentials:  [156.76734354 112.         110.85125168 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:08<01:17,  8.59s/it]                                               10%|â–ˆ         | 1/10 [00:08<01:17,  8.59s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:13<00:50,  6.33s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:13<00:50,  6.33s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:25<01:03,  9.08s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:25<01:03,  9.08s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:32<00:48,  8.11s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:32<00:48,  8.11s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:38<00:37,  7.41s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:38<00:37,  7.41s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:25,  6.35s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:25,  6.35s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:46<00:16,  5.65s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:46<00:16,  5.65s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:53<00:11,  5.77s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:53<00:11,  5.77s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:05<00:07,  7.83s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:05<00:07,  7.83s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:09<00:00,  6.63s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:09<00:00,  6.63s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:11<00:00,  6.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:11<00:00,  7.11s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.95
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_180836-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_180952-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.41226819157600403, 'learning_rate': 1e-05, 'num_tokens': 2117.0, 'completions/mean_length': 363.25, 'completions/min_length': 202.0, 'completions/max_length': 480.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 363.25, 'completions/min_terminated_length': 202.0, 'completions/max_terminated_length': 480.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 363.25, 'kl': 0.009676274959929287, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3831946849822998, 'learning_rate': 1e-05, 'num_tokens': 3358.0, 'completions/mean_length': 185.25, 'completions/min_length': 150.0, 'completions/max_length': 218.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 185.25, 'completions/min_terminated_length': 150.0, 'completions/max_terminated_length': 218.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 185.25, 'kl': 0.02088801353238523, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3090091943740845, 'learning_rate': 1e-05, 'num_tokens': 5050.0, 'completions/mean_length': 300.0, 'completions/min_length': 127.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 154.6666717529297, 'completions/min_terminated_length': 127.0, 'completions/max_terminated_length': 207.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 0.875, 'reward_std': 2.25, 'frac_reward_zero_std': 0.0, 'completion_length': 300.0, 'kl': 0.04531705961562693, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.26170575618743896, 'learning_rate': 1e-05, 'num_tokens': 6791.0, 'completions/mean_length': 285.25, 'completions/min_length': 248.0, 'completions/max_length': 347.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 285.25, 'completions/min_terminated_length': 248.0, 'completions/max_terminated_length': 347.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 285.25, 'kl': 0.019138151546940207, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.27108266949653625, 'learning_rate': 1e-05, 'num_tokens': 8537.0, 'completions/mean_length': 280.5, 'completions/min_length': 248.0, 'completions/max_length': 312.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 280.5, 'completions/min_terminated_length': 248.0, 'completions/max_terminated_length': 312.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 280.5, 'kl': 0.009378144517540932, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0005511244526132941, 'learning_rate': 1e-05, 'num_tokens': 9713.0, 'completions/mean_length': 166.0, 'completions/min_length': 123.0, 'completions/max_length': 189.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 166.0, 'completions/min_terminated_length': 123.0, 'completions/max_terminated_length': 189.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 166.0, 'kl': 0.015495164319872856, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4367774426937103, 'learning_rate': 1e-05, 'num_tokens': 10827.0, 'completions/mean_length': 139.5, 'completions/min_length': 122.0, 'completions/max_length': 181.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 139.5, 'completions/min_terminated_length': 122.0, 'completions/max_terminated_length': 181.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 139.5, 'kl': 0.015227718045935035, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.35387828946113586, 'learning_rate': 1e-05, 'num_tokens': 12348.0, 'completions/mean_length': 239.25, 'completions/min_length': 204.0, 'completions/max_length': 304.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 239.25, 'completions/min_terminated_length': 204.0, 'completions/max_terminated_length': 304.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 239.25, 'kl': 0.013723053969442844, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.31116983294487, 'learning_rate': 1e-05, 'num_tokens': 14346.0, 'completions/mean_length': 368.5, 'completions/min_length': 173.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 246.0, 'completions/min_terminated_length': 173.0, 'completions/max_terminated_length': 300.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 0.375, 'reward_std': 2.136000871658325, 'frac_reward_zero_std': 0.0, 'completion_length': 368.5, 'kl': 0.018795847077853978, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3875356614589691, 'learning_rate': 1e-05, 'num_tokens': 15342.0, 'completions/mean_length': 143.0, 'completions/min_length': 114.0, 'completions/max_length': 164.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 143.0, 'completions/min_terminated_length': 114.0, 'completions/max_terminated_length': 164.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 143.0, 'kl': 0.03317694668658078, 'epoch': 0.0}
{'train_runtime': 71.1348, 'train_samples_per_second': 0.562, 'train_steps_per_second': 0.141, 'train_loss': 2.0090286125196143e-05, 'epoch': 0.0}
[EP 0086] 2 | reward_mean=1.262 | 
*** stats:  {'episode_reward_mean': 1.2625, 'episode_reward_last': 1.5, 'episode_reward_std_mean': 1.1156726777553558, 'episode_reward_trajectory': [0.75, 1.5, 0.875, 1.0, 1.5, 2.0, 1.5, 1.625, 0.375, 1.5], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.35, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.3, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.9125, 'rewards/check_numbers/mean/last': 1.0, 'rewards/check_numbers/std/mean': 0.8551502287387848, 'rewards/check_numbers/std/last': 1.0}
Curr reward  1.2625
All rewards  35.3125
Cumulative rewards  [-22.275, 75.0875, 3.9625000000000004, -10.8125, -10.65]
Num plays  [6, 49, 13, 10, 9]
Mean rewards  [-3.7125, 1.5323979591836736, 0.30480769230769234, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 112.         115.37764081 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 112.         115.37764081 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.28s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.28s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:37, 12.24s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:37, 12.24s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.25s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.25s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.26s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.26s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.28s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.28s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.26s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.26s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.27s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.27s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.27s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.27s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.29s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.29s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.27s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.27s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.27s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.45s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.2625
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.2625
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_180952-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_181201-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0003, 'grad_norm': 0.0012803031131625175, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2835206873714924, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0013173898914828897, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.28836528211832047, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0014812585432082415, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.29414649307727814, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0007534329197369516, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2569756470620632, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0011021844111382961, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.27479077875614166, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0015944542828947306, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2710951194167137, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0017218580469489098, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2818073034286499, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0010883910581469536, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2773680314421654, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.000846201553940773, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2799035422503948, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0008154804818332195, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2614176943898201, 'epoch': 0.0}
{'train_runtime': 124.4736, 'train_samples_per_second': 0.321, 'train_steps_per_second': 0.08, 'train_loss': 0.0002769390761386603, 'epoch': 0.0}
[EP 0087] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  31.3125
Cumulative rewards  [-22.275, 71.0875, 3.9625000000000004, -10.8125, -10.65]
Num plays  [6, 50, 13, 10, 9]
Mean rewards  [-3.7125, 1.42175, 0.30480769230769234, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 113.13708499 115.37764081 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 113.13708499 115.37764081 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.35s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.35s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.27s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.27s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.25s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.25s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.27s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.27s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.30s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.30s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.29s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.29s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.29s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.29s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.30s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.30s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.30s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.30s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.28s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.28s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.28s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.48s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.2625
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_181201-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_181409-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0003, 'grad_norm': 0.0013570503797382116, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.27164143323898315, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0010780664160847664, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2748575881123543, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0014577879337593913, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.27975809946656227, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0007240905542857945, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.24976934492588043, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0009234410244971514, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.26859935373067856, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0014517944073304534, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.26303680986166, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0015586403897032142, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2720691151916981, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0010547396959736943, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.27122659608721733, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0008772622095420957, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2708377279341221, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0007713534287177026, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.26014359295368195, 'epoch': 0.0}
{'train_runtime': 124.758, 'train_samples_per_second': 0.321, 'train_steps_per_second': 0.08, 'train_loss': 0.0002681939775357023, 'epoch': 0.0}
[EP 0088] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  27.3125
Cumulative rewards  [-22.275, 67.0875, 3.9625000000000004, -10.8125, -10.65]
Num plays  [6, 51, 13, 10, 9]
Mean rewards  [-3.7125, 1.3154411764705884, 0.30480769230769234, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 114.26285486 115.37764081 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 114.26285486 115.37764081 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.11s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.11s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.09s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.09s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.07s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.07s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.09s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.09s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.09s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.09s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.10s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.10s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.09s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.09s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.10s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.10s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.09s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.09s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.09s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.09s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.09s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.26s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.2625
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_181409-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_181616-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0003, 'grad_norm': 0.001291236374527216, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.26104073971509933, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0009529634262435138, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.27088963985443115, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0012914122780784965, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.27100924402475357, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006939197774045169, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2438495084643364, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0009797940729185939, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2644815295934677, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0012179655022919178, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2552122473716736, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0015367119340226054, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.26643023639917374, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0010313780512660742, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2652098685503006, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0009035547845996916, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.26541559025645256, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0008001175592653453, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2467542067170143, 'epoch': 0.0}
{'train_runtime': 122.6071, 'train_samples_per_second': 0.326, 'train_steps_per_second': 0.082, 'train_loss': 0.0002610292984172702, 'epoch': 0.0}
[EP 0089] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  23.3125
Cumulative rewards  [-22.275, 63.087500000000006, 3.9625000000000004, -10.8125, -10.65]
Num plays  [6, 52, 13, 10, 9]
Mean rewards  [-3.7125, 1.213221153846154, 0.30480769230769234, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 115.37764081 115.37764081 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 115.37764081 115.37764081 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.12s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.12s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.09s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.09s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.09s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.09s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.10s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.10s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.12s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.12s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.11s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.11s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.11s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.11s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.11s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.11s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:49<00:12, 12.12s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:49<00:12, 12.12s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.10s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.10s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.10s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.28s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.2625
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_181616-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_181822-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.0012757835211232305, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.24934281408786774, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0010548726422712207, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2589453309774399, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0014118365943431854, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.25434357300400734, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006400771671906114, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23650898039340973, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0009586329106241465, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.25578072667121887, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0012392529752105474, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2481294721364975, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.001531484303995967, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.25868676230311394, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0012589767575263977, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2492762915790081, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.0008273215498775244, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.25516681000590324, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.000702756573446095, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23669952899217606, 'epoch': 0.0}
{'train_runtime': 122.8206, 'train_samples_per_second': 0.326, 'train_steps_per_second': 0.081, 'train_loss': 0.00025028804666362705, 'epoch': 0.0}
[EP 0090] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  19.3125
Cumulative rewards  [-22.275, 59.087500000000006, 3.9625000000000004, -10.8125, -10.65]
Num plays  [6, 53, 13, 10, 9]
Mean rewards  [-3.7125, 1.114858490566038, 0.30480769230769234, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 116.48175823 115.37764081 202.38577025 192.        ]
sampled base index:  2
potentials:  [156.76734354 116.48175823 115.37764081 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:08,  7.61s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:08,  7.61s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:13<00:51,  6.39s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:13<00:51,  6.39s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:41,  5.88s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:41,  5.88s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:35,  5.97s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:35,  5.97s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:31,  6.30s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:31,  6.30s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:35<00:22,  5.63s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:35<00:22,  5.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:39<00:14,  4.99s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:39<00:14,  4.99s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:44<00:09,  4.93s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:44<00:09,  4.93s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:48<00:04,  4.86s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:48<00:04,  4.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:56<00:00,  5.58s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:56<00:00,  5.58s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:57<00:00,  5.58s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:57<00:00,  5.78s/it]
wandb: updating run metadata
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.2625
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_181822-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_181924-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.00018716683553066105, 'learning_rate': 1e-05, 'num_tokens': 1939.0, 'completions/mean_length': 318.75, 'completions/min_length': 206.0, 'completions/max_length': 422.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 318.75, 'completions/min_terminated_length': 206.0, 'completions/max_terminated_length': 422.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 318.75, 'kl': 0.010569279780611396, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.43755608797073364, 'learning_rate': 1e-05, 'num_tokens': 3242.0, 'completions/mean_length': 200.75, 'completions/min_length': 163.0, 'completions/max_length': 278.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 200.75, 'completions/min_terminated_length': 163.0, 'completions/max_terminated_length': 278.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 200.75, 'kl': 0.01650608633644879, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4311072826385498, 'learning_rate': 1e-05, 'num_tokens': 4482.0, 'completions/mean_length': 187.0, 'completions/min_length': 113.0, 'completions/max_length': 261.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 187.0, 'completions/min_terminated_length': 113.0, 'completions/max_terminated_length': 261.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 187.0, 'kl': 0.031456907046958804, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4114704430103302, 'learning_rate': 1e-05, 'num_tokens': 6124.0, 'completions/mean_length': 260.5, 'completions/min_length': 188.0, 'completions/max_length': 320.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 260.5, 'completions/min_terminated_length': 188.0, 'completions/max_terminated_length': 320.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -0.5, 'reward_std': 1.3540064096450806, 'frac_reward_zero_std': 0.0, 'completion_length': 260.5, 'kl': 0.015202095964923501, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.270672082901001, 'learning_rate': 1e-05, 'num_tokens': 7962.0, 'completions/mean_length': 303.5, 'completions/min_length': 237.0, 'completions/max_length': 375.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 303.5, 'completions/min_terminated_length': 237.0, 'completions/max_terminated_length': 375.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 303.5, 'kl': 0.009588017943315208, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.001566748134791851, 'learning_rate': 1e-05, 'num_tokens': 9131.0, 'completions/mean_length': 164.25, 'completions/min_length': 125.0, 'completions/max_length': 197.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 164.25, 'completions/min_terminated_length': 125.0, 'completions/max_terminated_length': 197.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 164.25, 'kl': 0.032324594678357244, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5792598724365234, 'learning_rate': 1e-05, 'num_tokens': 10197.0, 'completions/mean_length': 127.5, 'completions/min_length': 94.0, 'completions/max_length': 150.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 127.5, 'completions/min_terminated_length': 94.0, 'completions/max_terminated_length': 150.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 127.5, 'kl': 0.023296290077269077, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.8177557587623596, 'learning_rate': 1e-05, 'num_tokens': 11524.0, 'completions/mean_length': 190.75, 'completions/min_length': 150.0, 'completions/max_length': 229.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 190.75, 'completions/min_terminated_length': 150.0, 'completions/max_terminated_length': 229.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': 0.125, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 190.75, 'kl': 0.1288665991742164, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3549460768699646, 'learning_rate': 1e-05, 'num_tokens': 12831.0, 'completions/mean_length': 195.75, 'completions/min_length': 169.0, 'completions/max_length': 222.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 195.75, 'completions/min_terminated_length': 169.0, 'completions/max_terminated_length': 222.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 195.75, 'kl': 0.013807297684252262, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4044055640697479, 'learning_rate': 1e-05, 'num_tokens': 14076.0, 'completions/mean_length': 205.25, 'completions/min_length': 134.0, 'completions/max_length': 392.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 205.25, 'completions/min_terminated_length': 134.0, 'completions/max_terminated_length': 392.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 205.25, 'kl': 0.02213482093065977, 'epoch': 0.0}
{'train_runtime': 57.788, 'train_samples_per_second': 0.692, 'train_steps_per_second': 0.173, 'train_loss': 3.0374615562323015e-05, 'epoch': 0.0}
[EP 0091] 2 | reward_mean=0.988 | 
*** stats:  {'episode_reward_mean': 0.9875, 'episode_reward_last': 1.5, 'episode_reward_std_mean': 0.816555917263031, 'episode_reward_trajectory': [0.0, 1.5, 1.5, -0.5, 1.125, 2.0, 1.125, 0.125, 1.5, 1.5], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.35, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.3, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.6375, 'rewards/check_numbers/mean/last': 1.0, 'rewards/check_numbers/std/mean': 0.631945151090622, 'rewards/check_numbers/std/last': 1.0}
Curr reward  0.9875
All rewards  20.3
Cumulative rewards  [-22.275, 59.087500000000006, 4.95, -10.8125, -10.65]
Num plays  [6, 53, 14, 10, 9]
Mean rewards  [-3.7125, 1.114858490566038, 0.3535714285714286, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 116.48175823 119.73303638 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 116.48175823 119.73303638 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.15s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.15s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.07s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.07s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.07s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.07s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.07s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.07s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.09s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.09s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.07s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.07s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.08s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.08s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.08s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.08s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.09s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.09s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.08s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.08s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.08s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.25s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.9875
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 0.9875
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_181924-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_182130-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.00120955565944314, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.24258092790842056, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0010407879017293453, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2493489645421505, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.001358358538709581, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.24666181951761246, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006894657271914184, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23304200544953346, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0008655605488456786, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.24927788227796555, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0013399588642641902, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2452668957412243, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0014847253914922476, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.24779440462589264, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0009809171315282583, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2360243946313858, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0007698127301409841, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.24282407388091087, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0007107245619408786, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2288588210940361, 'epoch': 0.0}
{'train_runtime': 122.5053, 'train_samples_per_second': 0.327, 'train_steps_per_second': 0.082, 'train_loss': 0.00024216803431045263, 'epoch': 0.0}
[EP 0092] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  16.3
Cumulative rewards  [-22.275, 55.087500000000006, 4.95, -10.8125, -10.65]
Num plays  [6, 54, 14, 10, 9]
Mean rewards  [-3.7125, 1.020138888888889, 0.3535714285714286, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 117.57550765 119.73303638 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 117.57550765 119.73303638 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.15s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.15s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.08s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.08s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.08s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.08s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.09s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.09s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.10s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.10s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.07s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.07s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.08s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.08s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.08s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.08s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.09s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.09s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.07s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.07s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.07s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.25s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.9875
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_182130-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_182337-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.0011661695316433907, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23623468354344368, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0008885319111868739, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.24227101728320122, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0012497266288846731, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23971709609031677, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006682495586574078, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.22787880897521973, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0008550503407604992, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2443055622279644, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0011946238810196519, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23657477647066116, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0015743859112262726, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.24376912042498589, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0010341544402763247, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2271679826080799, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0007585242274217308, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2395455501973629, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006929019000381231, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2242356836795807, 'epoch': 0.0}
{'train_runtime': 122.4965, 'train_samples_per_second': 0.327, 'train_steps_per_second': 0.082, 'train_loss': 0.00023617004335392268, 'epoch': 0.0}
[EP 0093] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  12.3
Cumulative rewards  [-22.275, 51.087500000000006, 4.95, -10.8125, -10.65]
Num plays  [6, 55, 14, 10, 9]
Mean rewards  [-3.7125, 0.9288636363636364, 0.3535714285714286, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 118.65917579 119.73303638 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 118.65917579 119.73303638 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.16s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.16s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.08s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.08s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.08s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.08s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.08s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.08s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.11s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.11s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.08s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.08s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.10s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.10s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.09s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.09s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.10s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.10s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.08s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.08s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.08s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.26s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.9875
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_182337-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_182543-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.0013059593038633466, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.22985892370343208, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0009267446002922952, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2343904860317707, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.001364814699627459, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23458123207092285, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0007042577490210533, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.22254760935902596, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0008403763640671968, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.24527962505817413, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0009369758190587163, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.22540873661637306, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0014281056355684996, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2404537983238697, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0011140175629407167, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2196885272860527, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0008570580976083875, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2405230663716793, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.000650911417324096, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.218136478215456, 'epoch': 0.0}
{'train_runtime': 122.6073, 'train_samples_per_second': 0.326, 'train_steps_per_second': 0.082, 'train_loss': 0.0002310868600034155, 'epoch': 0.0}
[EP 0094] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  8.3
Cumulative rewards  [-22.275, 47.087500000000006, 4.95, -10.8125, -10.65]
Num plays  [6, 56, 14, 10, 9]
Mean rewards  [-3.7125, 0.8408482142857144, 0.3535714285714286, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 119.73303638 119.73303638 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 119.73303638 119.73303638 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:48, 12.11s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:48, 12.11s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.10s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.10s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.11s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.11s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.09s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.09s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.12s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.12s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.09s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.09s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.10s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.10s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.11s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.11s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.11s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.11s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.10s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.10s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.10s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.27s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.9875
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_182543-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_182750-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.0011179513530805707, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2203429453074932, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0007818460580892861, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23289206251502037, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0013486177194863558, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23018530011177063, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006825149757787585, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.21360692754387856, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0010316944681107998, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.24024300277233124, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.00103873445186764, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2253209389746189, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.001280124532058835, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2330087274312973, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.001088093500584364, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.21506622433662415, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0009266563574783504, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23707515001296997, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006996066658757627, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.21488729864358902, 'epoch': 0.0}
{'train_runtime': 122.7291, 'train_samples_per_second': 0.326, 'train_steps_per_second': 0.081, 'train_loss': 0.00022626286518061532, 'epoch': 0.0}
[EP 0095] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  4.300000000000001
Cumulative rewards  [-22.275, 43.087500000000006, 4.95, -10.8125, -10.65]
Num plays  [6, 57, 14, 10, 9]
Mean rewards  [-3.7125, 0.755921052631579, 0.3535714285714286, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 120.79735096 119.73303638 202.38577025 192.        ]
sampled base index:  2
potentials:  [156.76734354 120.79735096 119.73303638 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:04,  7.20s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:04,  7.20s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:12<00:49,  6.19s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:12<00:49,  6.19s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:16<00:37,  5.29s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:16<00:37,  5.29s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:33,  5.51s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:33,  5.51s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:34<00:39,  7.94s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:34<00:39,  7.94s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:39<00:26,  6.70s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:39<00:26,  6.70s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:43<00:17,  5.99s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:43<00:17,  5.99s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:56<00:15,  7.98s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:56<00:15,  7.98s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:00<00:06,  6.85s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:00<00:06,  6.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:09<00:00,  7.60s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:09<00:00,  7.60s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:11<00:00,  7.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:11<00:00,  7.14s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.9875
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_182750-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_182905-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.40032869577407837, 'learning_rate': 1e-05, 'num_tokens': 2148.0, 'completions/mean_length': 371.0, 'completions/min_length': 325.0, 'completions/max_length': 393.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 363.66668701171875, 'completions/min_terminated_length': 325.0, 'completions/max_terminated_length': 393.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.75, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -1.375, 'reward_std': 2.25, 'frac_reward_zero_std': 0.0, 'completion_length': 356.75, 'kl': 0.009865584317594767, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.36053267121315, 'learning_rate': 1e-05, 'num_tokens': 3511.0, 'completions/mean_length': 215.75, 'completions/min_length': 173.0, 'completions/max_length': 274.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 215.75, 'completions/min_terminated_length': 173.0, 'completions/max_terminated_length': 274.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 1.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 215.75, 'kl': 0.04224352817982435, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00028673410997726023, 'learning_rate': 1e-05, 'num_tokens': 4591.0, 'completions/mean_length': 147.0, 'completions/min_length': 109.0, 'completions/max_length': 190.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 147.0, 'completions/min_terminated_length': 109.0, 'completions/max_terminated_length': 190.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 147.0, 'kl': 0.02135300962254405, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.1924639493227005, 'learning_rate': 1e-05, 'num_tokens': 6264.0, 'completions/mean_length': 268.25, 'completions/min_length': 234.0, 'completions/max_length': 302.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 268.25, 'completions/min_terminated_length': 234.0, 'completions/max_terminated_length': 302.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': 0.625, 'reward_std': 0.9464846849441528, 'frac_reward_zero_std': 0.0, 'completion_length': 268.25, 'kl': 0.010588980745524168, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.26315969228744507, 'learning_rate': 1e-05, 'num_tokens': 8440.0, 'completions/mean_length': 388.0, 'completions/min_length': 239.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 272.0, 'completions/min_terminated_length': 239.0, 'completions/max_terminated_length': 293.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 388.0, 'kl': 0.008335244143381715, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00048136708210222423, 'learning_rate': 1e-05, 'num_tokens': 9638.0, 'completions/mean_length': 171.5, 'completions/min_length': 135.0, 'completions/max_length': 194.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 171.5, 'completions/min_terminated_length': 135.0, 'completions/max_terminated_length': 194.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 171.5, 'kl': 0.015266912523657084, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4581625759601593, 'learning_rate': 1e-05, 'num_tokens': 10851.0, 'completions/mean_length': 164.25, 'completions/min_length': 125.0, 'completions/max_length': 209.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 164.25, 'completions/min_terminated_length': 125.0, 'completions/max_terminated_length': 209.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 164.25, 'kl': 0.022957246284931898, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.24175210297107697, 'learning_rate': 1e-05, 'num_tokens': 12751.0, 'completions/mean_length': 334.0, 'completions/min_length': 196.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 200.0, 'completions/min_terminated_length': 196.0, 'completions/max_terminated_length': 206.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.0, 'reward_std': 1.8708287477493286, 'frac_reward_zero_std': 0.0, 'completion_length': 334.0, 'kl': 0.012823959114030004, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.37869757413864136, 'learning_rate': 1e-05, 'num_tokens': 13976.0, 'completions/mean_length': 175.25, 'completions/min_length': 161.0, 'completions/max_length': 197.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 175.25, 'completions/min_terminated_length': 161.0, 'completions/max_terminated_length': 197.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.25, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 175.25, 'kl': 0.01729544927366078, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0013485712697729468, 'learning_rate': 1e-05, 'num_tokens': 15692.0, 'completions/mean_length': 323.0, 'completions/min_length': 190.0, 'completions/max_length': 541.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 323.0, 'completions/min_terminated_length': 190.0, 'completions/max_terminated_length': 541.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 323.0, 'kl': 0.02401537576224655, 'epoch': 0.0}
{'train_runtime': 71.3973, 'train_samples_per_second': 0.56, 'train_steps_per_second': 0.14, 'train_loss': 1.8473166528565342e-05, 'epoch': 0.0}
[EP 0096] 2 | reward_mean=0.863 | 
*** stats:  {'episode_reward_mean': 0.8625, 'episode_reward_last': 0.0, 'episode_reward_std_mean': 0.9472013950347901, 'episode_reward_trajectory': [-1.375, 1.625, 2.0, 0.625, 1.5, 2.0, 1.0, 0.0, 1.25, 0.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.125, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.45, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.7375, 'rewards/check_numbers/mean/last': -0.5, 'rewards/check_numbers/std/mean': 0.5467210650444031, 'rewards/check_numbers/std/last': 0.0}
Curr reward  0.8625
All rewards  5.1625000000000005
Cumulative rewards  [-22.275, 43.087500000000006, 5.8125, -10.8125, -10.65]
Num plays  [6, 57, 15, 10, 9]
Mean rewards  [-3.7125, 0.755921052631579, 0.3875, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 120.79735096 123.93546708 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 120.79735096 123.93546708 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.16s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.16s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.12s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.12s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.10s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.10s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.11s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.11s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.13s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.13s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.11s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.11s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.12s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.12s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.12s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.12s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:49<00:12, 12.12s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:49<00:12, 12.12s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.11s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.11s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.11s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.29s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.8625
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 0.8625
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_182905-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_183112-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.0010537076741456985, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.21562962979078293, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0007836453733034432, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2304965816438198, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0015652243746444583, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.24028995260596275, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006822171271778643, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2081790678203106, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0009756435174494982, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.2386612556874752, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0010633459314703941, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.22079696506261826, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.001134418766014278, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.22727422416210175, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0009632402798160911, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.21195821836590767, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0008063575951382518, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23320093005895615, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006447099149227142, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.21175223588943481, 'epoch': 0.0}
{'train_runtime': 122.875, 'train_samples_per_second': 0.326, 'train_steps_per_second': 0.081, 'train_loss': 0.00022382391471182929, 'epoch': 0.0}
[EP 0097] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  1.1625000000000005
Cumulative rewards  [-22.275, 39.087500000000006, 5.8125, -10.8125, -10.65]
Num plays  [6, 58, 15, 10, 9]
Mean rewards  [-3.7125, 0.6739224137931036, 0.3875, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 4, 5, 6, 6]
potentials:  [156.76734354 121.85236969 123.93546708 202.38577025 192.        ]
sampled base index:  1
potentials:  [156.76734354 121.85236969 123.93546708 202.38577025 192.        ]
sampled base index:  1
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.15s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.15s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:37, 12.14s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:37, 12.14s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.11s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.11s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.09s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.09s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.11s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.11s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.08s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.08s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.09s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.09s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.08s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.08s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.09s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.09s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.07s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.07s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.07s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.26s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.8625
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_183112-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_183320-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.0011999541893601418, 'learning_rate': 0.0001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.20757266134023666, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0009161350899375975, 'learning_rate': 0.0001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.22413212433457375, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0013249844778329134, 'learning_rate': 0.0001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23260857537388802, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0005738247418776155, 'learning_rate': 0.0001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.20386311039328575, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0011081546545028687, 'learning_rate': 0.0001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23484155535697937, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0010151034221053123, 'learning_rate': 0.0001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.21299926564097404, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0011551531497389078, 'learning_rate': 0.0001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23188845813274384, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0010556367924436927, 'learning_rate': 0.0001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.21140176057815552, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0008895163191482425, 'learning_rate': 0.0001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.23345836624503136, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.0006623220979236066, 'learning_rate': 0.0001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.20833305642008781, 'epoch': 0.0}
{'train_runtime': 122.6317, 'train_samples_per_second': 0.326, 'train_steps_per_second': 0.082, 'train_loss': 0.0002201099065132439, 'epoch': 0.0}
[EP 0098] 1 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  -2.8374999999999995
Cumulative rewards  [-22.275, 35.087500000000006, 5.8125, -10.8125, -10.65]
Num plays  [6, 59, 15, 10, 9]
Mean rewards  [-3.7125, 0.5947033898305085, 0.3875, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 1, 0, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [156.76734354 245.79666393 123.93546708 202.38577025 192.        ]
sampled base index:  2
potentials:  [156.76734354 245.79666393 123.93546708 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:08<01:16,  8.49s/it]                                               10%|â–ˆ         | 1/10 [00:08<01:16,  8.49s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:13<00:51,  6.47s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:13<00:51,  6.47s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:38,  5.47s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:38,  5.47s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:35,  5.95s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:35,  5.95s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:28,  5.67s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:28,  5.67s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:33<00:20,  5.10s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:33<00:20,  5.10s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:37<00:13,  4.62s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:37<00:13,  4.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:41<00:09,  4.51s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:41<00:09,  4.51s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:47<00:04,  4.98s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:47<00:04,  4.98s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:51<00:00,  4.67s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:51<00:00,  4.67s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:53<00:00,  4.67s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:53<00:00,  5.33s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_1_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 0.8625
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.0001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 1
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_183320-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_183417-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.488839328289032, 'learning_rate': 1e-05, 'num_tokens': 1955.0, 'completions/mean_length': 322.75, 'completions/min_length': 236.0, 'completions/max_length': 478.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 322.75, 'completions/min_terminated_length': 236.0, 'completions/max_terminated_length': 478.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -0.375, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 322.75, 'kl': 0.01671989867463708, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3690364360809326, 'learning_rate': 1e-05, 'num_tokens': 3217.0, 'completions/mean_length': 190.5, 'completions/min_length': 148.0, 'completions/max_length': 246.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 190.5, 'completions/min_terminated_length': 148.0, 'completions/max_terminated_length': 246.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 190.5, 'kl': 0.023967113811522722, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.8940414190292358, 'learning_rate': 1e-05, 'num_tokens': 4367.0, 'completions/mean_length': 164.5, 'completions/min_length': 148.0, 'completions/max_length': 192.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 164.5, 'completions/min_terminated_length': 148.0, 'completions/max_terminated_length': 192.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 164.5, 'kl': 0.0487996730953455, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.30249524116516113, 'learning_rate': 1e-05, 'num_tokens': 5995.0, 'completions/mean_length': 257.0, 'completions/min_length': 137.0, 'completions/max_length': 360.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 257.0, 'completions/min_terminated_length': 137.0, 'completions/max_terminated_length': 360.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': 0.125, 'reward_std': 0.25, 'frac_reward_zero_std': 0.0, 'completion_length': 257.0, 'kl': 0.019263697089627385, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3551085293292999, 'learning_rate': 1e-05, 'num_tokens': 7505.0, 'completions/mean_length': 221.5, 'completions/min_length': 207.0, 'completions/max_length': 249.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 221.5, 'completions/min_terminated_length': 207.0, 'completions/max_terminated_length': 249.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 221.5, 'kl': 0.017734028166159987, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0011155420215800405, 'learning_rate': 1e-05, 'num_tokens': 8645.0, 'completions/mean_length': 157.0, 'completions/min_length': 133.0, 'completions/max_length': 176.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 157.0, 'completions/min_terminated_length': 133.0, 'completions/max_terminated_length': 176.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 157.0, 'kl': 0.032029853435233235, 'epoch': 0.0}
{'loss': 0.0014, 'grad_norm': 0.6021101474761963, 'learning_rate': 1e-05, 'num_tokens': 9737.0, 'completions/mean_length': 134.0, 'completions/min_length': 124.0, 'completions/max_length': 148.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 134.0, 'completions/min_terminated_length': 124.0, 'completions/max_terminated_length': 148.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 134.0, 'kl': 1.3881326476112008, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3923535943031311, 'learning_rate': 1e-05, 'num_tokens': 10999.0, 'completions/mean_length': 174.5, 'completions/min_length': 150.0, 'completions/max_length': 193.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 174.5, 'completions/min_terminated_length': 150.0, 'completions/max_terminated_length': 193.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': 0.625, 'reward_std': 0.9464846849441528, 'frac_reward_zero_std': 0.0, 'completion_length': 174.5, 'kl': 0.01831985730677843, 'epoch': 0.0}
{'loss': 0.0015, 'grad_norm': 0.4004380404949188, 'learning_rate': 1e-05, 'num_tokens': 12460.0, 'completions/mean_length': 234.25, 'completions/min_length': 148.0, 'completions/max_length': 311.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 234.25, 'completions/min_terminated_length': 148.0, 'completions/max_terminated_length': 311.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.25, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 234.25, 'kl': 1.4765931151341647, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0013780439039692283, 'learning_rate': 1e-05, 'num_tokens': 13417.0, 'completions/mean_length': 133.25, 'completions/min_length': 110.0, 'completions/max_length': 171.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 133.25, 'completions/min_terminated_length': 110.0, 'completions/max_terminated_length': 171.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 133.25, 'kl': 0.03687539789825678, 'epoch': 0.0}
{'train_runtime': 53.2665, 'train_samples_per_second': 0.751, 'train_steps_per_second': 0.188, 'train_loss': 0.000307852258629282, 'epoch': 0.0}
[EP 0099] 2 | reward_mean=1.125 | 
*** stats:  {'episode_reward_mean': 1.125, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.816340172290802, 'episode_reward_trajectory': [-0.375, 1.5, 1.5, 0.125, 1.5, 2.0, 1.125, 0.625, 1.25, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.3875, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.225, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.7375, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.6227261126041412, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.125
All rewards  -1.7124999999999995
Cumulative rewards  [-22.275, 35.087500000000006, 6.9375, -10.8125, -10.65]
Num plays  [6, 59, 16, 10, 9]
Mean rewards  [-3.7125, 0.5947033898305085, 0.43359375, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [156.76734354 245.79666393 128.         202.38577025 192.        ]
sampled base index:  2
potentials:  [156.76734354 245.79666393 128.         202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:06,  7.35s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:06,  7.35s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:12<00:50,  6.31s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:12<00:50,  6.31s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:39,  5.57s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:39,  5.57s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:23<00:33,  5.56s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:23<00:33,  5.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:29,  5.95s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:29,  5.95s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:34<00:22,  5.60s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:34<00:22,  5.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:38<00:14,  4.90s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:38<00:14,  4.90s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:42<00:09,  4.79s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:42<00:09,  4.79s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:47<00:04,  4.86s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:47<00:04,  4.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:51<00:00,  4.58s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:51<00:00,  4.58s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:53<00:00,  4.58s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:53<00:00,  5.34s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.125
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.125
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_183417-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_183514-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.0002503451833035797, 'learning_rate': 1e-05, 'num_tokens': 1891.0, 'completions/mean_length': 306.75, 'completions/min_length': 249.0, 'completions/max_length': 400.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 306.75, 'completions/min_terminated_length': 249.0, 'completions/max_terminated_length': 400.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 306.75, 'kl': 0.013369913562200963, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.583657443523407, 'learning_rate': 1e-05, 'num_tokens': 3178.0, 'completions/mean_length': 196.75, 'completions/min_length': 158.0, 'completions/max_length': 281.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 196.75, 'completions/min_terminated_length': 158.0, 'completions/max_terminated_length': 281.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 1.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 196.75, 'kl': 0.026652713771909475, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0010626211296766996, 'learning_rate': 1e-05, 'num_tokens': 4328.0, 'completions/mean_length': 164.5, 'completions/min_length': 127.0, 'completions/max_length': 219.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 164.5, 'completions/min_terminated_length': 127.0, 'completions/max_terminated_length': 219.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 164.5, 'kl': 0.03417415078729391, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.42253872752189636, 'learning_rate': 1e-05, 'num_tokens': 5864.0, 'completions/mean_length': 234.0, 'completions/min_length': 176.0, 'completions/max_length': 279.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 234.0, 'completions/min_terminated_length': 176.0, 'completions/max_terminated_length': 279.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.875, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 234.0, 'kl': 0.13191275810822845, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0003070610691793263, 'learning_rate': 1e-05, 'num_tokens': 7542.0, 'completions/mean_length': 263.5, 'completions/min_length': 218.0, 'completions/max_length': 352.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 263.5, 'completions/min_terminated_length': 218.0, 'completions/max_terminated_length': 352.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 263.5, 'kl': 0.018935485975816846, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.003360363421961665, 'learning_rate': 1e-05, 'num_tokens': 8794.0, 'completions/mean_length': 185.0, 'completions/min_length': 150.0, 'completions/max_length': 235.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 185.0, 'completions/min_terminated_length': 150.0, 'completions/max_terminated_length': 235.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 185.0, 'kl': 0.05015839170664549, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5930058360099792, 'learning_rate': 1e-05, 'num_tokens': 9820.0, 'completions/mean_length': 117.5, 'completions/min_length': 94.0, 'completions/max_length': 137.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 117.5, 'completions/min_terminated_length': 94.0, 'completions/max_terminated_length': 137.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 117.5, 'kl': 0.03436817787587643, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.42009255290031433, 'learning_rate': 1e-05, 'num_tokens': 11065.0, 'completions/mean_length': 170.25, 'completions/min_length': 150.0, 'completions/max_length': 208.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 170.25, 'completions/min_terminated_length': 150.0, 'completions/max_terminated_length': 208.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 1.25, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 170.25, 'kl': 0.029769283952191472, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0003494427655823529, 'learning_rate': 1e-05, 'num_tokens': 12362.0, 'completions/mean_length': 193.25, 'completions/min_length': 159.0, 'completions/max_length': 242.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 193.25, 'completions/min_terminated_length': 159.0, 'completions/max_terminated_length': 242.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 193.25, 'kl': 0.022247185232117772, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0014997855760157108, 'learning_rate': 1e-05, 'num_tokens': 13319.0, 'completions/mean_length': 133.25, 'completions/min_length': 110.0, 'completions/max_length': 171.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 133.25, 'completions/min_terminated_length': 110.0, 'completions/max_terminated_length': 171.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 133.25, 'kl': 0.03979065082967281, 'epoch': 0.0}
{'train_runtime': 53.3977, 'train_samples_per_second': 0.749, 'train_steps_per_second': 0.187, 'train_loss': 4.013661982753547e-05, 'epoch': 0.0}
[EP 0100] 2 | reward_mean=1.525 | 
*** stats:  {'episode_reward_mean': 1.525, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.40521660447120667, 'episode_reward_trajectory': [0.0, 1.625, 2.0, 0.875, 2.0, 2.0, 1.5, 1.25, 2.0, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.425, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.15, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.1, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.2732050776481628, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.525
All rewards  -0.18749999999999956
Cumulative rewards  [-22.275, 35.087500000000006, 8.4625, -10.8125, -10.65]
Num plays  [6, 59, 17, 10, 9]
Mean rewards  [-3.7125, 0.5947033898305085, 0.49779411764705883, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [156.76734354 245.79666393 131.93938002 202.38577025 192.        ]
sampled base index:  2
potentials:  [156.76734354 245.79666393 131.93938002 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:11,  8.00s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:11,  8.00s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:12<00:46,  5.78s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:12<00:46,  5.78s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:40,  5.79s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:40,  5.79s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:23<00:33,  5.56s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:23<00:33,  5.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:28<00:27,  5.56s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:28<00:27,  5.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:32<00:20,  5.07s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:32<00:20,  5.07s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:38<00:15,  5.08s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:38<00:15,  5.08s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:43<00:10,  5.33s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:43<00:10,  5.33s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:49<00:05,  5.27s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:49<00:05,  5.27s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:52<00:00,  4.80s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:52<00:00,  4.80s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  4.80s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  5.46s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.525
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.525
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_183514-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_183612-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.4702613651752472, 'learning_rate': 1e-05, 'num_tokens': 1896.0, 'completions/mean_length': 308.0, 'completions/min_length': 246.0, 'completions/max_length': 445.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 308.0, 'completions/min_terminated_length': 246.0, 'completions/max_terminated_length': 445.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.75, 'reward_std': 0.8660253882408142, 'frac_reward_zero_std': 0.0, 'completion_length': 308.0, 'kl': 0.17453711805865169, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00038601193227805197, 'learning_rate': 1e-05, 'num_tokens': 3108.0, 'completions/mean_length': 178.0, 'completions/min_length': 144.0, 'completions/max_length': 191.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 178.0, 'completions/min_terminated_length': 144.0, 'completions/max_terminated_length': 191.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 178.0, 'kl': 0.02740509482100606, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.4404921531677246, 'learning_rate': 1e-05, 'num_tokens': 4448.0, 'completions/mean_length': 212.0, 'completions/min_length': 154.0, 'completions/max_length': 297.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 212.0, 'completions/min_terminated_length': 154.0, 'completions/max_terminated_length': 297.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 212.0, 'kl': 0.05396652640774846, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.34143009781837463, 'learning_rate': 1e-05, 'num_tokens': 5950.0, 'completions/mean_length': 225.5, 'completions/min_length': 190.0, 'completions/max_length': 258.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 225.5, 'completions/min_terminated_length': 190.0, 'completions/max_terminated_length': 258.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 225.5, 'kl': 0.019913651514798403, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0011874566553160548, 'learning_rate': 1e-05, 'num_tokens': 7631.0, 'completions/mean_length': 264.25, 'completions/min_length': 242.0, 'completions/max_length': 278.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 264.25, 'completions/min_terminated_length': 242.0, 'completions/max_terminated_length': 278.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 264.25, 'kl': 0.022099902387708426, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.5060674548149109, 'learning_rate': 1e-05, 'num_tokens': 8753.0, 'completions/mean_length': 152.5, 'completions/min_length': 108.0, 'completions/max_length': 184.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 152.5, 'completions/min_terminated_length': 108.0, 'completions/max_terminated_length': 184.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 152.5, 'kl': 0.06933706533163786, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5440454483032227, 'learning_rate': 1e-05, 'num_tokens': 9937.0, 'completions/mean_length': 157.0, 'completions/min_length': 109.0, 'completions/max_length': 246.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 157.0, 'completions/min_terminated_length': 109.0, 'completions/max_terminated_length': 246.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 157.0, 'kl': 0.02883407473564148, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.35026276111602783, 'learning_rate': 1e-05, 'num_tokens': 11414.0, 'completions/mean_length': 228.25, 'completions/min_length': 166.0, 'completions/max_length': 301.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 228.25, 'completions/min_terminated_length': 166.0, 'completions/max_terminated_length': 301.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': 0.625, 'reward_std': 0.9464846849441528, 'frac_reward_zero_std': 0.0, 'completion_length': 228.25, 'kl': 0.031005120370537043, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3996574282646179, 'learning_rate': 1e-05, 'num_tokens': 12718.0, 'completions/mean_length': 195.0, 'completions/min_length': 154.0, 'completions/max_length': 251.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 195.0, 'completions/min_terminated_length': 154.0, 'completions/max_terminated_length': 251.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 195.0, 'kl': 0.025119415018707514, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5072180032730103, 'learning_rate': 1e-05, 'num_tokens': 13749.0, 'completions/mean_length': 151.75, 'completions/min_length': 146.0, 'completions/max_length': 158.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 151.75, 'completions/min_terminated_length': 146.0, 'completions/max_terminated_length': 158.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 151.75, 'kl': 0.030278330203145742, 'epoch': 0.0}
{'train_runtime': 54.554, 'train_samples_per_second': 0.733, 'train_steps_per_second': 0.183, 'train_loss': 4.826594067708356e-05, 'epoch': 0.0}
[EP 0101] 2 | reward_mean=1.350 | 
*** stats:  {'episode_reward_mean': 1.35, 'episode_reward_last': 1.5, 'episode_reward_std_mean': 0.7997986972332001, 'episode_reward_trajectory': [0.75, 2.0, 1.5, 1.0, 2.0, 1.125, 1.5, 0.625, 1.5, 1.5], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.4625, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.075, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.8875, 'rewards/check_numbers/mean/last': 1.0, 'rewards/check_numbers/std/mean': 0.7967210650444031, 'rewards/check_numbers/std/last': 1.0}
Curr reward  1.35
All rewards  1.1625000000000005
Cumulative rewards  [-22.275, 35.087500000000006, 9.8125, -10.8125, -10.65]
Num plays  [6, 59, 18, 10, 9]
Mean rewards  [-3.7125, 0.5947033898305085, 0.5451388888888888, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [156.76734354 245.79666393 135.76450199 202.38577025 192.        ]
sampled base index:  2
potentials:  [156.76734354 245.79666393 135.76450199 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:09<01:26,  9.66s/it]                                               10%|â–ˆ         | 1/10 [00:09<01:26,  9.66s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:14<00:55,  6.98s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:14<00:55,  6.98s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:39,  5.64s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:39,  5.64s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:33,  5.55s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:33,  5.55s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:27,  5.57s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:27,  5.57s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:35<00:21,  5.46s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:35<00:21,  5.46s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:39<00:15,  5.14s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:39<00:15,  5.14s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:44<00:10,  5.09s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:44<00:10,  5.09s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:51<00:05,  5.53s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:51<00:05,  5.53s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:55<00:00,  5.06s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:55<00:00,  5.06s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:56<00:00,  5.06s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:56<00:00,  5.68s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.35
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.35
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_183612-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_183713-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.0009596286108717322, 'learning_rate': 1e-05, 'num_tokens': 2101.0, 'completions/mean_length': 359.25, 'completions/min_length': 182.0, 'completions/max_length': 565.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 359.25, 'completions/min_terminated_length': 182.0, 'completions/max_terminated_length': 565.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 359.25, 'kl': 0.02482056524604559, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5231688618659973, 'learning_rate': 1e-05, 'num_tokens': 3363.0, 'completions/mean_length': 190.5, 'completions/min_length': 157.0, 'completions/max_length': 248.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 190.5, 'completions/min_terminated_length': 157.0, 'completions/max_terminated_length': 248.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 190.5, 'kl': 0.027593699283897877, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0016635339707136154, 'learning_rate': 1e-05, 'num_tokens': 4507.0, 'completions/mean_length': 163.0, 'completions/min_length': 141.0, 'completions/max_length': 176.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 163.0, 'completions/min_terminated_length': 141.0, 'completions/max_terminated_length': 176.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 163.0, 'kl': 0.04828749131411314, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.39779385924339294, 'learning_rate': 1e-05, 'num_tokens': 6061.0, 'completions/mean_length': 238.5, 'completions/min_length': 213.0, 'completions/max_length': 270.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 238.5, 'completions/min_terminated_length': 213.0, 'completions/max_terminated_length': 270.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': 0.625, 'reward_std': 0.9464846849441528, 'frac_reward_zero_std': 0.0, 'completion_length': 238.5, 'kl': 0.04514548974111676, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0022591727320104837, 'learning_rate': 1e-05, 'num_tokens': 7677.0, 'completions/mean_length': 248.0, 'completions/min_length': 201.0, 'completions/max_length': 281.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 248.0, 'completions/min_terminated_length': 201.0, 'completions/max_terminated_length': 281.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 248.0, 'kl': 0.03562991553917527, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.6591837406158447, 'learning_rate': 1e-05, 'num_tokens': 8938.0, 'completions/mean_length': 187.25, 'completions/min_length': 143.0, 'completions/max_length': 257.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 187.25, 'completions/min_terminated_length': 143.0, 'completions/max_terminated_length': 257.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 187.25, 'kl': 0.17245703493244946, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.6945071220397949, 'learning_rate': 1e-05, 'num_tokens': 10174.0, 'completions/mean_length': 170.0, 'completions/min_length': 126.0, 'completions/max_length': 205.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 170.0, 'completions/min_terminated_length': 126.0, 'completions/max_terminated_length': 205.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 170.0, 'kl': 0.06218452798202634, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.4857019782066345, 'learning_rate': 1e-05, 'num_tokens': 11466.0, 'completions/mean_length': 182.0, 'completions/min_length': 117.0, 'completions/max_length': 240.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 182.0, 'completions/min_terminated_length': 117.0, 'completions/max_terminated_length': 240.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 182.0, 'kl': 0.09553230623714626, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5689239501953125, 'learning_rate': 1e-05, 'num_tokens': 13055.0, 'completions/mean_length': 266.25, 'completions/min_length': 166.0, 'completions/max_length': 348.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 266.25, 'completions/min_terminated_length': 166.0, 'completions/max_terminated_length': 348.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 266.25, 'kl': 0.03747808467596769, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.6337407827377319, 'learning_rate': 1e-05, 'num_tokens': 14066.0, 'completions/mean_length': 146.75, 'completions/min_length': 111.0, 'completions/max_length': 174.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 146.75, 'completions/min_terminated_length': 111.0, 'completions/max_terminated_length': 174.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 146.75, 'kl': 0.07582645863294601, 'epoch': 0.0}
{'train_runtime': 56.7675, 'train_samples_per_second': 0.705, 'train_steps_per_second': 0.176, 'train_loss': 6.249440048122779e-05, 'epoch': 0.0}
[EP 0102] 2 | reward_mean=1.125 | 
*** stats:  {'episode_reward_mean': 1.125, 'episode_reward_last': 1.5, 'episode_reward_std_mean': 0.6977261066436767, 'episode_reward_trajectory': [0.0, 1.5, 2.0, 0.625, 2.0, 1.5, 0.5, 1.125, 0.5, 1.5], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.5, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.625, 'rewards/check_numbers/mean/last': 1.0, 'rewards/check_numbers/std/mean': 0.6977261126041412, 'rewards/check_numbers/std/last': 1.0}
Curr reward  1.125
All rewards  2.2875000000000005
Cumulative rewards  [-22.275, 35.087500000000006, 10.9375, -10.8125, -10.65]
Num plays  [6, 59, 19, 10, 9]
Mean rewards  [-3.7125, 0.5947033898305085, 0.5756578947368421, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [156.76734354 245.79666393 139.48476619 202.38577025 192.        ]
sampled base index:  2
potentials:  [156.76734354 245.79666393 139.48476619 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:49, 12.19s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:49, 12.19s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:16<01:01,  7.63s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:16<01:01,  7.63s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:20<00:41,  5.86s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:20<00:41,  5.86s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:25<00:34,  5.71s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:25<00:34,  5.71s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:28,  5.68s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:28,  5.68s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:35<00:19,  5.00s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:35<00:19,  5.00s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:38<00:13,  4.60s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:38<00:13,  4.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:43<00:08,  4.47s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:43<00:08,  4.47s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:47<00:04,  4.38s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:47<00:04,  4.38s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:50<00:00,  4.11s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:50<00:00,  4.11s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:52<00:00,  4.11s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:52<00:00,  5.25s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.125
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.125
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_183713-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_183809-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.3834042251110077, 'learning_rate': 1e-05, 'num_tokens': 2290.0, 'completions/mean_length': 406.5, 'completions/min_length': 242.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 296.66668701171875, 'completions/min_terminated_length': 242.0, 'completions/max_terminated_length': 369.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': -0.125, 'reward_std': 1.8427786827087402, 'frac_reward_zero_std': 0.0, 'completion_length': 406.5, 'kl': 0.04905388969928026, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.6777134537696838, 'learning_rate': 1e-05, 'num_tokens': 3493.0, 'completions/mean_length': 175.75, 'completions/min_length': 137.0, 'completions/max_length': 205.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 175.75, 'completions/min_terminated_length': 137.0, 'completions/max_terminated_length': 205.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 175.75, 'kl': 0.25107916072010994, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.05700546130537987, 'learning_rate': 1e-05, 'num_tokens': 4535.0, 'completions/mean_length': 137.5, 'completions/min_length': 95.0, 'completions/max_length': 157.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 137.5, 'completions/min_terminated_length': 95.0, 'completions/max_terminated_length': 157.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 137.5, 'kl': 0.2350502535700798, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.6050489544868469, 'learning_rate': 1e-05, 'num_tokens': 5962.0, 'completions/mean_length': 206.75, 'completions/min_length': 183.0, 'completions/max_length': 272.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 206.75, 'completions/min_terminated_length': 183.0, 'completions/max_terminated_length': 272.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 206.75, 'kl': 0.02736938465386629, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00113638152834028, 'learning_rate': 1e-05, 'num_tokens': 7571.0, 'completions/mean_length': 246.25, 'completions/min_length': 211.0, 'completions/max_length': 283.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 246.25, 'completions/min_terminated_length': 211.0, 'completions/max_terminated_length': 283.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 246.25, 'kl': 0.0356926447711885, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0043448698706924915, 'learning_rate': 1e-05, 'num_tokens': 8622.0, 'completions/mean_length': 134.75, 'completions/min_length': 106.0, 'completions/max_length': 151.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 134.75, 'completions/min_terminated_length': 106.0, 'completions/max_terminated_length': 151.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 134.75, 'kl': 0.0674751321785152, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0030172693077474833, 'learning_rate': 1e-05, 'num_tokens': 9705.0, 'completions/mean_length': 131.75, 'completions/min_length': 123.0, 'completions/max_length': 157.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 131.75, 'completions/min_terminated_length': 123.0, 'completions/max_terminated_length': 157.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 131.75, 'kl': 0.06958150211721659, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.5349836945533752, 'learning_rate': 1e-05, 'num_tokens': 10976.0, 'completions/mean_length': 176.75, 'completions/min_length': 159.0, 'completions/max_length': 188.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 176.75, 'completions/min_terminated_length': 159.0, 'completions/max_terminated_length': 188.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 176.75, 'kl': 0.08644040487706661, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.5707169771194458, 'learning_rate': 1e-05, 'num_tokens': 12131.0, 'completions/mean_length': 157.75, 'completions/min_length': 139.0, 'completions/max_length': 186.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 157.75, 'completions/min_terminated_length': 139.0, 'completions/max_terminated_length': 186.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 157.75, 'kl': 0.10991696175187826, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.9148123860359192, 'learning_rate': 1e-05, 'num_tokens': 13036.0, 'completions/mean_length': 120.25, 'completions/min_length': 107.0, 'completions/max_length': 140.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 120.25, 'completions/min_terminated_length': 107.0, 'completions/max_terminated_length': 140.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 120.25, 'kl': 0.12117377668619156, 'epoch': 0.0}
{'train_runtime': 52.5177, 'train_samples_per_second': 0.762, 'train_steps_per_second': 0.19, 'train_loss': 0.0001052945364790503, 'epoch': 0.0}
[EP 0103] 2 | reward_mean=1.512 | 
*** stats:  {'episode_reward_mean': 1.5125, 'episode_reward_last': 1.125, 'episode_reward_std_mean': 0.6623555064201355, 'episode_reward_trajectory': [-0.125, 1.5, 2.0, 1.5, 2.0, 2.0, 2.0, 1.625, 1.5, 1.125], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.425, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.15, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.0875, 'rewards/check_numbers/mean/last': 0.625, 'rewards/check_numbers/std/mean': 0.5727261126041412, 'rewards/check_numbers/std/last': 1.0307763814926147}
Curr reward  1.5125
All rewards  3.8000000000000007
Cumulative rewards  [-22.275, 35.087500000000006, 12.45, -10.8125, -10.65]
Num plays  [6, 59, 20, 10, 9]
Mean rewards  [-3.7125, 0.5947033898305085, 0.6224999999999999, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [156.76734354 245.79666393 143.10835056 202.38577025 192.        ]
sampled base index:  2
potentials:  [156.76734354 245.79666393 143.10835056 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:11<01:47, 11.92s/it]                                               10%|â–ˆ         | 1/10 [00:11<01:47, 11.92s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:16<00:59,  7.50s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:16<00:59,  7.50s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:20<00:41,  5.90s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:20<00:41,  5.90s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:25<00:34,  5.76s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:25<00:34,  5.76s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:28,  5.72s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:31<00:28,  5.72s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:35<00:20,  5.14s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:35<00:20,  5.14s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:38<00:13,  4.57s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:38<00:13,  4.57s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:45<00:10,  5.08s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:45<00:10,  5.08s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:49<00:04,  4.87s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:49<00:04,  4.87s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:53<00:00,  4.48s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:53<00:00,  4.48s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  4.48s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  5.48s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.5125
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.5125
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_183809-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_183908-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.6438714861869812, 'learning_rate': 1e-05, 'num_tokens': 2562.0, 'completions/mean_length': 474.5, 'completions/min_length': 194.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.5, 'completions/mean_terminated_length': 213.0, 'completions/min_terminated_length': 194.0, 'completions/max_terminated_length': 232.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.7320507764816284, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.25, 'rewards/check_numbers/std': 0.28867512941360474, 'reward': -1.25, 'reward_std': 1.443375587463379, 'frac_reward_zero_std': 0.0, 'completion_length': 474.5, 'kl': 0.1391447428613901, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.6129060387611389, 'learning_rate': 1e-05, 'num_tokens': 3773.0, 'completions/mean_length': 177.75, 'completions/min_length': 163.0, 'completions/max_length': 201.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 177.75, 'completions/min_terminated_length': 163.0, 'completions/max_terminated_length': 201.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 177.75, 'kl': 0.7731744907796383, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.7431420683860779, 'learning_rate': 1e-05, 'num_tokens': 4914.0, 'completions/mean_length': 162.25, 'completions/min_length': 146.0, 'completions/max_length': 175.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 162.25, 'completions/min_terminated_length': 146.0, 'completions/max_terminated_length': 175.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.25, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 162.25, 'kl': 0.20107665099203587, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.3720749318599701, 'learning_rate': 1e-05, 'num_tokens': 6499.0, 'completions/mean_length': 246.25, 'completions/min_length': 216.0, 'completions/max_length': 279.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 246.25, 'completions/min_terminated_length': 216.0, 'completions/max_terminated_length': 279.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 246.25, 'kl': 0.08118661725893617, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.001682640053331852, 'learning_rate': 1e-05, 'num_tokens': 8143.0, 'completions/mean_length': 255.0, 'completions/min_length': 209.0, 'completions/max_length': 284.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 255.0, 'completions/min_terminated_length': 209.0, 'completions/max_terminated_length': 284.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 255.0, 'kl': 0.0503665441647172, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.030468614771962166, 'learning_rate': 1e-05, 'num_tokens': 9276.0, 'completions/mean_length': 155.25, 'completions/min_length': 138.0, 'completions/max_length': 174.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 155.25, 'completions/min_terminated_length': 138.0, 'completions/max_terminated_length': 174.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 155.25, 'kl': 0.23127892520278692, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0028314858209341764, 'learning_rate': 1e-05, 'num_tokens': 10314.0, 'completions/mean_length': 120.5, 'completions/min_length': 110.0, 'completions/max_length': 130.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 120.5, 'completions/min_terminated_length': 110.0, 'completions/max_terminated_length': 130.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 120.5, 'kl': 0.059767826460301876, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.6710611581802368, 'learning_rate': 1e-05, 'num_tokens': 11687.0, 'completions/mean_length': 202.25, 'completions/min_length': 140.0, 'completions/max_length': 310.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 202.25, 'completions/min_terminated_length': 140.0, 'completions/max_terminated_length': 310.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 202.25, 'kl': 0.10388870211318135, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.003912228625267744, 'learning_rate': 1e-05, 'num_tokens': 12828.0, 'completions/mean_length': 154.25, 'completions/min_length': 135.0, 'completions/max_length': 188.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 154.25, 'completions/min_terminated_length': 135.0, 'completions/max_terminated_length': 188.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 154.25, 'kl': 0.09476281609386206, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.002533788327127695, 'learning_rate': 1e-05, 'num_tokens': 13730.0, 'completions/mean_length': 119.5, 'completions/min_length': 94.0, 'completions/max_length': 135.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 119.5, 'completions/min_terminated_length': 94.0, 'completions/max_terminated_length': 135.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 119.5, 'kl': 0.0649271896108985, 'epoch': 0.0}
{'train_runtime': 54.805, 'train_samples_per_second': 0.73, 'train_steps_per_second': 0.182, 'train_loss': 0.00017995383786910678, 'epoch': 0.0}
[EP 0104] 2 | reward_mean=1.350 | 
*** stats:  {'episode_reward_mean': 1.35, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.5943375587463379, 'episode_reward_trajectory': [-1.25, 1.5, 1.25, 0.5, 2.0, 2.0, 2.0, 1.5, 2.0, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.3125, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.24820507764816285, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.0375, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.4038675129413605, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.35
All rewards  5.15
Cumulative rewards  [-22.275, 35.087500000000006, 13.799999999999999, -10.8125, -10.65]
Num plays  [6, 59, 21, 10, 9]
Mean rewards  [-3.7125, 0.5947033898305085, 0.6571428571428571, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [156.76734354 245.79666393 146.64242224 202.38577025 192.        ]
sampled base index:  2
potentials:  [156.76734354 245.79666393 146.64242224 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.39s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.39s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:17<01:06,  8.32s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:17<01:06,  8.32s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:22<00:47,  6.76s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:22<00:47,  6.76s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:30<00:41,  6.95s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:30<00:41,  6.95s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:38<00:37,  7.42s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:38<00:37,  7.42s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:25,  6.26s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:25,  6.26s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:46<00:16,  5.49s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:46<00:16,  5.49s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:50<00:10,  5.15s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:50<00:10,  5.15s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:56<00:05,  5.41s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:56<00:05,  5.41s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  4.93s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  4.93s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:02<00:00,  4.93s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:02<00:00,  6.21s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.35
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.35
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_183908-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_184013-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.4255484938621521, 'learning_rate': 1e-05, 'num_tokens': 2141.0, 'completions/mean_length': 369.25, 'completions/min_length': 212.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 247.0, 'completions/min_terminated_length': 212.0, 'completions/max_terminated_length': 312.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': -0.125, 'reward_std': 1.8427786827087402, 'frac_reward_zero_std': 0.0, 'completion_length': 369.25, 'kl': 0.048072305507957935, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.03871126100420952, 'learning_rate': 1e-05, 'num_tokens': 3390.0, 'completions/mean_length': 187.25, 'completions/min_length': 133.0, 'completions/max_length': 261.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 187.25, 'completions/min_terminated_length': 133.0, 'completions/max_terminated_length': 261.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 187.25, 'kl': 0.38861719239503145, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.058833107352256775, 'learning_rate': 1e-05, 'num_tokens': 4566.0, 'completions/mean_length': 171.0, 'completions/min_length': 131.0, 'completions/max_length': 224.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 171.0, 'completions/min_terminated_length': 131.0, 'completions/max_terminated_length': 224.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 171.0, 'kl': 0.2037218138575554, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.5911499857902527, 'learning_rate': 1e-05, 'num_tokens': 6273.0, 'completions/mean_length': 276.75, 'completions/min_length': 221.0, 'completions/max_length': 384.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 276.75, 'completions/min_terminated_length': 221.0, 'completions/max_terminated_length': 384.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 276.75, 'kl': 0.36206317972391844, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.41449370980262756, 'learning_rate': 1e-05, 'num_tokens': 8333.0, 'completions/mean_length': 359.0, 'completions/min_length': 237.0, 'completions/max_length': 459.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 359.0, 'completions/min_terminated_length': 237.0, 'completions/max_terminated_length': 459.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 359.0, 'kl': 0.07947713136672974, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.01982896775007248, 'learning_rate': 1e-05, 'num_tokens': 9370.0, 'completions/mean_length': 131.25, 'completions/min_length': 102.0, 'completions/max_length': 162.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 131.25, 'completions/min_terminated_length': 102.0, 'completions/max_terminated_length': 162.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 131.25, 'kl': 0.21685403864830732, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 1.3228247165679932, 'learning_rate': 1e-05, 'num_tokens': 10437.0, 'completions/mean_length': 127.75, 'completions/min_length': 91.0, 'completions/max_length': 157.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 127.75, 'completions/min_terminated_length': 91.0, 'completions/max_terminated_length': 157.0, 'rewards/match_format_exactly/mean': 0.75, 'rewards/match_format_exactly/std': 1.5, 'rewards/match_format_approximately/mean': 0.875, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': -0.375, 'rewards/check_answer/std': 0.75, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 2.25, 'reward_std': 2.0615527629852295, 'frac_reward_zero_std': 0.0, 'completion_length': 127.75, 'kl': 0.3112699780613184, 'epoch': 0.0}
{'loss': 0.0059, 'grad_norm': 3.050499677658081, 'learning_rate': 1e-05, 'num_tokens': 11684.0, 'completions/mean_length': 170.75, 'completions/min_length': 141.0, 'completions/max_length': 191.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 170.75, 'completions/min_terminated_length': 141.0, 'completions/max_terminated_length': 191.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 170.75, 'kl': 5.857184685766697, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.9066362380981445, 'learning_rate': 1e-05, 'num_tokens': 13068.0, 'completions/mean_length': 215.0, 'completions/min_length': 147.0, 'completions/max_length': 296.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 215.0, 'completions/min_terminated_length': 147.0, 'completions/max_terminated_length': 296.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 215.0, 'kl': 0.22331698425114155, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00237427675165236, 'learning_rate': 1e-05, 'num_tokens': 14068.0, 'completions/mean_length': 144.0, 'completions/min_length': 128.0, 'completions/max_length': 154.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 144.0, 'completions/min_terminated_length': 128.0, 'completions/max_terminated_length': 154.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 144.0, 'kl': 0.06113819405436516, 'epoch': 0.0}
{'train_runtime': 62.1295, 'train_samples_per_second': 0.644, 'train_steps_per_second': 0.161, 'train_loss': 0.0007751712706522085, 'epoch': 0.0}
[EP 0105] 2 | reward_mean=1.512 | 
*** stats:  {'episode_reward_mean': 1.5125, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.7059031963348389, 'episode_reward_trajectory': [-0.125, 2.0, 2.0, 1.0, 0.5, 2.0, 2.25, 2.0, 1.5, 2.0], 'rewards/match_format_exactly/mean/mean': 0.075, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.15, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.4625, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.225, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': -0.0375, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.075, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.0125, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.5101185262203216, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.5125
All rewards  6.6625000000000005
Cumulative rewards  [-22.275, 35.087500000000006, 15.312499999999998, -10.8125, -10.65]
Num plays  [6, 59, 22, 10, 9]
Mean rewards  [-3.7125, 0.5947033898305085, 0.6960227272727272, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [156.76734354 245.79666393 150.09330431 202.38577025 192.        ]
sampled base index:  2
potentials:  [156.76734354 245.79666393 150.09330431 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:09,  7.71s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:09,  7.71s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:14<00:55,  6.88s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:14<00:55,  6.88s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:40,  5.77s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:40,  5.77s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:34,  5.74s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:34,  5.74s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:28,  5.70s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:28,  5.70s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:33<00:20,  5.16s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:33<00:20,  5.16s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:38<00:14,  4.96s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:38<00:14,  4.96s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:43<00:09,  4.86s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:43<00:09,  4.86s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:50<00:05,  5.75s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:50<00:05,  5.75s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  5.24s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  5.24s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:56<00:00,  5.24s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:56<00:00,  5.66s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: uploading summary, console lines 7-7
wandb: uploading console lines 10-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.5125
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.5125
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_184013-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_184216-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.6426971554756165, 'learning_rate': 1e-05, 'num_tokens': 1791.0, 'completions/mean_length': 281.75, 'completions/min_length': 200.0, 'completions/max_length': 415.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 281.75, 'completions/min_terminated_length': 200.0, 'completions/max_terminated_length': 415.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 281.75, 'kl': 0.08572571352124214, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.3883425295352936, 'learning_rate': 1e-05, 'num_tokens': 3203.0, 'completions/mean_length': 228.0, 'completions/min_length': 166.0, 'completions/max_length': 319.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 228.0, 'completions/min_terminated_length': 166.0, 'completions/max_terminated_length': 319.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 228.0, 'kl': 0.06273968238383532, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0008240123279392719, 'learning_rate': 1e-05, 'num_tokens': 4330.0, 'completions/mean_length': 158.75, 'completions/min_length': 135.0, 'completions/max_length': 193.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 158.75, 'completions/min_terminated_length': 135.0, 'completions/max_terminated_length': 193.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 158.75, 'kl': 0.06400969158858061, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.010397916659712791, 'learning_rate': 1e-05, 'num_tokens': 5881.0, 'completions/mean_length': 237.75, 'completions/min_length': 181.0, 'completions/max_length': 279.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 237.75, 'completions/min_terminated_length': 181.0, 'completions/max_terminated_length': 279.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 237.75, 'kl': 0.07037361897528172, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4993104040622711, 'learning_rate': 1e-05, 'num_tokens': 7415.0, 'completions/mean_length': 227.5, 'completions/min_length': 188.0, 'completions/max_length': 271.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 227.5, 'completions/min_terminated_length': 188.0, 'completions/max_terminated_length': 271.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 227.5, 'kl': 0.041995600797235966, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.003778001992031932, 'learning_rate': 1e-05, 'num_tokens': 8510.0, 'completions/mean_length': 145.75, 'completions/min_length': 121.0, 'completions/max_length': 170.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 145.75, 'completions/min_terminated_length': 121.0, 'completions/max_terminated_length': 170.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 145.75, 'kl': 0.07926011411473155, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0022730266209691763, 'learning_rate': 1e-05, 'num_tokens': 9693.0, 'completions/mean_length': 156.75, 'completions/min_length': 117.0, 'completions/max_length': 199.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 156.75, 'completions/min_terminated_length': 117.0, 'completions/max_terminated_length': 199.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 156.75, 'kl': 0.08900256082415581, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.9224992394447327, 'learning_rate': 1e-05, 'num_tokens': 10975.0, 'completions/mean_length': 179.5, 'completions/min_length': 152.0, 'completions/max_length': 206.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 179.5, 'completions/min_terminated_length': 152.0, 'completions/max_terminated_length': 206.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 179.5, 'kl': 0.28976885695010424, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.5267534852027893, 'learning_rate': 1e-05, 'num_tokens': 12322.0, 'completions/mean_length': 205.75, 'completions/min_length': 96.0, 'completions/max_length': 414.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 205.75, 'completions/min_terminated_length': 96.0, 'completions/max_terminated_length': 414.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 205.75, 'kl': 0.09163493011146784, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.596982479095459, 'learning_rate': 1e-05, 'num_tokens': 13355.0, 'completions/mean_length': 152.25, 'completions/min_length': 122.0, 'completions/max_length': 169.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 152.25, 'completions/min_terminated_length': 122.0, 'completions/max_terminated_length': 169.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 152.25, 'kl': 0.08848197478801012, 'epoch': 0.0}
{'train_runtime': 56.6037, 'train_samples_per_second': 0.707, 'train_steps_per_second': 0.177, 'train_loss': 9.629313572077081e-05, 'epoch': 0.0}
[EP 0106] 2 | reward_mean=1.575 | 
*** stats:  {'episode_reward_mean': 1.575, 'episode_reward_last': 1.125, 'episode_reward_std_mean': 0.6216253280639649, 'episode_reward_trajectory': [1.0, 1.5, 2.0, 2.0, 1.5, 2.0, 2.0, 1.125, 1.5, 1.125], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.4625, 'rewards/match_format_approximately/mean/last': 0.125, 'rewards/match_format_approximately/std/mean': 0.075, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.1125, 'rewards/check_numbers/mean/last': 1.0, 'rewards/check_numbers/std/mean': 0.6185476899147033, 'rewards/check_numbers/std/last': 1.0}
Curr reward  1.575
All rewards  8.2375
Cumulative rewards  [-22.275, 35.087500000000006, 16.8875, -10.8125, -10.65]
Num plays  [6, 59, 23, 10, 9]
Mean rewards  [-3.7125, 0.5947033898305085, 0.7342391304347826, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [156.76734354 245.79666393 153.46660875 202.38577025 192.        ]
sampled base index:  2
potentials:  [156.76734354 245.79666393 153.46660875 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:03,  7.08s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:03,  7.08s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:11<00:44,  5.58s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:11<00:44,  5.58s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:16<00:36,  5.18s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:16<00:36,  5.18s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:33,  5.56s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:33,  5.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:28<00:28,  5.67s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:28<00:28,  5.67s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:32<00:20,  5.05s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:32<00:20,  5.05s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:36<00:14,  4.87s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:36<00:14,  4.87s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:42<00:10,  5.11s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:42<00:10,  5.11s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:46<00:04,  4.94s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:46<00:04,  4.94s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:51<00:00,  4.72s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:51<00:00,  4.72s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:52<00:00,  4.72s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:52<00:00,  5.28s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.575
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.575
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_184216-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_184313-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.5681321024894714, 'learning_rate': 1e-05, 'num_tokens': 1772.0, 'completions/mean_length': 277.0, 'completions/min_length': 212.0, 'completions/max_length': 372.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 277.0, 'completions/min_terminated_length': 212.0, 'completions/max_terminated_length': 372.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 277.0, 'kl': 0.08912118896842003, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.003926962614059448, 'learning_rate': 1e-05, 'num_tokens': 2924.0, 'completions/mean_length': 163.0, 'completions/min_length': 115.0, 'completions/max_length': 200.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 163.0, 'completions/min_terminated_length': 115.0, 'completions/max_terminated_length': 200.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 163.0, 'kl': 0.060245055705308914, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00497219804674387, 'learning_rate': 1e-05, 'num_tokens': 4075.0, 'completions/mean_length': 164.75, 'completions/min_length': 123.0, 'completions/max_length': 210.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 164.75, 'completions/min_terminated_length': 123.0, 'completions/max_terminated_length': 210.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 164.75, 'kl': 0.12833307683467865, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.442140132188797, 'learning_rate': 1e-05, 'num_tokens': 5770.0, 'completions/mean_length': 273.75, 'completions/min_length': 228.0, 'completions/max_length': 314.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 273.75, 'completions/min_terminated_length': 228.0, 'completions/max_terminated_length': 314.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 273.75, 'kl': 0.048590111546218395, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00227021099999547, 'learning_rate': 1e-05, 'num_tokens': 7384.0, 'completions/mean_length': 247.5, 'completions/min_length': 197.0, 'completions/max_length': 288.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 247.5, 'completions/min_terminated_length': 197.0, 'completions/max_terminated_length': 288.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 247.5, 'kl': 0.06501811277121305, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0011169454082846642, 'learning_rate': 1e-05, 'num_tokens': 8436.0, 'completions/mean_length': 135.0, 'completions/min_length': 115.0, 'completions/max_length': 153.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 135.0, 'completions/min_terminated_length': 115.0, 'completions/max_terminated_length': 153.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 135.0, 'kl': 0.057170262560248375, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.656691312789917, 'learning_rate': 1e-05, 'num_tokens': 9526.0, 'completions/mean_length': 133.5, 'completions/min_length': 98.0, 'completions/max_length': 195.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 133.5, 'completions/min_terminated_length': 98.0, 'completions/max_terminated_length': 195.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 133.5, 'kl': 0.06744487676769495, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.6619223952293396, 'learning_rate': 1e-05, 'num_tokens': 10892.0, 'completions/mean_length': 200.5, 'completions/min_length': 133.0, 'completions/max_length': 274.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 200.5, 'completions/min_terminated_length': 133.0, 'completions/max_terminated_length': 274.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 200.5, 'kl': 0.08338686171919107, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0009034167160280049, 'learning_rate': 1e-05, 'num_tokens': 12110.0, 'completions/mean_length': 173.5, 'completions/min_length': 132.0, 'completions/max_length': 201.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 173.5, 'completions/min_terminated_length': 132.0, 'completions/max_terminated_length': 201.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 173.5, 'kl': 0.05370688671246171, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.6089066863059998, 'learning_rate': 1e-05, 'num_tokens': 13171.0, 'completions/mean_length': 159.25, 'completions/min_length': 134.0, 'completions/max_length': 180.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 159.25, 'completions/min_terminated_length': 134.0, 'completions/max_terminated_length': 180.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 159.25, 'kl': 0.23669066838920116, 'epoch': 0.0}
{'train_runtime': 52.7636, 'train_samples_per_second': 0.758, 'train_steps_per_second': 0.19, 'train_loss': 8.896127110347152e-05, 'epoch': 0.0}
[EP 0107] 2 | reward_mean=1.550 | 
*** stats:  {'episode_reward_mean': 1.55, 'episode_reward_last': 1.5, 'episode_reward_std_mean': 0.5, 'episode_reward_trajectory': [0.5, 2.0, 2.0, 0.5, 2.0, 2.0, 1.5, 1.5, 2.0, 1.5], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.5, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.05, 'rewards/check_numbers/mean/last': 1.0, 'rewards/check_numbers/std/mean': 0.5, 'rewards/check_numbers/std/last': 1.0}
Curr reward  1.55
All rewards  9.787500000000001
Cumulative rewards  [-22.275, 35.087500000000006, 18.4375, -10.8125, -10.65]
Num plays  [6, 59, 24, 10, 9]
Mean rewards  [-3.7125, 0.5947033898305085, 0.7682291666666666, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [156.76734354 245.79666393 156.76734354 202.38577025 192.        ]
sampled base index:  0
potentials:  [156.76734354 245.79666393 156.76734354 202.38577025 192.        ]
sampled base index:  0
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.35s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.35s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.29s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.29s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.27s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.27s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.27s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.27s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.29s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.29s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.28s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.28s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.28s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.28s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.28s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.28s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.28s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.28s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.27s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.27s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.27s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.46s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.55
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.55
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_184313-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_184521-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.00023945012071635574, 'learning_rate': 0.001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.06102527119219303, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00017863005632534623, 'learning_rate': 0.001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.05586558301001787, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0009121168404817581, 'learning_rate': 0.001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.06786877382546663, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00015517712745349854, 'learning_rate': 0.001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.04315036069601774, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00031153581221587956, 'learning_rate': 0.001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.05462430324405432, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00018787200679071248, 'learning_rate': 0.001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.05236433073878288, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00014442545943893492, 'learning_rate': 0.001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.05761035066097975, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00018484186148270965, 'learning_rate': 0.001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.051402974873781204, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00021165958605706692, 'learning_rate': 0.001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.04738133680075407, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00017962591664399952, 'learning_rate': 0.001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.049151163548231125, 'epoch': 0.0}
{'train_runtime': 124.5884, 'train_samples_per_second': 0.321, 'train_steps_per_second': 0.08, 'train_loss': 5.404444818850607e-05, 'epoch': 0.0}
[EP 0108] 0 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  5.787500000000001
Cumulative rewards  [-26.275, 35.087500000000006, 18.4375, -10.8125, -10.65]
Num plays  [7, 59, 24, 10, 9]
Mean rewards  [-3.7535714285714286, 0.5947033898305085, 0.7682291666666666, -1.08125, -1.1833333333333333]
Balancing probabilities  [1, 0, 0, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [169.32808391 245.79666393 156.76734354 202.38577025 192.        ]
sampled base index:  2
potentials:  [169.32808391 245.79666393 156.76734354 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:05<00:51,  5.76s/it]                                               10%|â–ˆ         | 1/10 [00:05<00:51,  5.76s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:11<00:44,  5.60s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:11<00:44,  5.60s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:35,  5.02s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:35,  5.02s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:20<00:30,  5.02s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:20<00:30,  5.02s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:26<00:26,  5.38s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:26<00:26,  5.38s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:31<00:20,  5.11s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:31<00:20,  5.11s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:34<00:13,  4.62s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:34<00:13,  4.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:39<00:09,  4.64s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:39<00:09,  4.64s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:44<00:04,  4.73s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:44<00:04,  4.73s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:48<00:00,  4.49s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:48<00:00,  4.49s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:50<00:00,  4.49s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:50<00:00,  5.01s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_0_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.55
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 0
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_184521-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_184615-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.651420533657074, 'learning_rate': 1e-05, 'num_tokens': 1602.0, 'completions/mean_length': 234.5, 'completions/min_length': 212.0, 'completions/max_length': 278.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 234.5, 'completions/min_terminated_length': 212.0, 'completions/max_terminated_length': 278.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 234.5, 'kl': 0.13366771396249533, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.5055708289146423, 'learning_rate': 1e-05, 'num_tokens': 2931.0, 'completions/mean_length': 207.25, 'completions/min_length': 174.0, 'completions/max_length': 262.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 207.25, 'completions/min_terminated_length': 174.0, 'completions/max_terminated_length': 262.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 207.25, 'kl': 0.06730820331722498, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0019854444544762373, 'learning_rate': 1e-05, 'num_tokens': 4102.0, 'completions/mean_length': 169.75, 'completions/min_length': 159.0, 'completions/max_length': 186.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 169.75, 'completions/min_terminated_length': 159.0, 'completions/max_terminated_length': 186.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 169.75, 'kl': 0.06711388565599918, 'epoch': 0.0}
{'loss': 0.001, 'grad_norm': 0.4836786985397339, 'learning_rate': 1e-05, 'num_tokens': 5532.0, 'completions/mean_length': 207.5, 'completions/min_length': 178.0, 'completions/max_length': 231.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 207.5, 'completions/min_terminated_length': 178.0, 'completions/max_terminated_length': 231.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 207.5, 'kl': 1.0288462773896754, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00110341003164649, 'learning_rate': 1e-05, 'num_tokens': 7254.0, 'completions/mean_length': 274.5, 'completions/min_length': 256.0, 'completions/max_length': 298.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 274.5, 'completions/min_terminated_length': 256.0, 'completions/max_terminated_length': 298.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 274.5, 'kl': 0.041124031879007816, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0028957389295101166, 'learning_rate': 1e-05, 'num_tokens': 8448.0, 'completions/mean_length': 170.5, 'completions/min_length': 132.0, 'completions/max_length': 203.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 170.5, 'completions/min_terminated_length': 132.0, 'completions/max_terminated_length': 203.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 170.5, 'kl': 0.08443823643028736, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.025585303083062172, 'learning_rate': 1e-05, 'num_tokens': 9501.0, 'completions/mean_length': 124.25, 'completions/min_length': 109.0, 'completions/max_length': 134.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 124.25, 'completions/min_terminated_length': 109.0, 'completions/max_terminated_length': 134.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 124.25, 'kl': 0.2619846221059561, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.36439448595046997, 'learning_rate': 1e-05, 'num_tokens': 10870.0, 'completions/mean_length': 201.25, 'completions/min_length': 187.0, 'completions/max_length': 208.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 201.25, 'completions/min_terminated_length': 187.0, 'completions/max_terminated_length': 208.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': 0.875, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 201.25, 'kl': 0.03211514884606004, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.011356369592249393, 'learning_rate': 1e-05, 'num_tokens': 12107.0, 'completions/mean_length': 178.25, 'completions/min_length': 150.0, 'completions/max_length': 223.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 178.25, 'completions/min_terminated_length': 150.0, 'completions/max_terminated_length': 223.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 178.25, 'kl': 0.1871544672176242, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.019143052399158478, 'learning_rate': 1e-05, 'num_tokens': 12974.0, 'completions/mean_length': 110.75, 'completions/min_length': 81.0, 'completions/max_length': 160.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 110.75, 'completions/min_terminated_length': 81.0, 'completions/max_terminated_length': 160.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 110.75, 'kl': 0.21017701923847198, 'epoch': 0.0}
{'train_runtime': 50.0563, 'train_samples_per_second': 0.799, 'train_steps_per_second': 0.2, 'train_loss': 0.00021138599222467747, 'epoch': 0.0}
[EP 0109] 2 | reward_mean=1.637 | 
*** stats:  {'episode_reward_mean': 1.6375, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.375, 'episode_reward_trajectory': [0.5, 1.5, 2.0, 1.5, 2.0, 2.0, 2.0, 0.875, 2.0, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.5, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.1375, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.375, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.6375
All rewards  7.425000000000002
Cumulative rewards  [-26.275, 35.087500000000006, 20.075, -10.8125, -10.65]
Num plays  [7, 59, 25, 10, 9]
Mean rewards  [-3.7535714285714286, 0.5947033898305085, 0.8029999999999999, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [169.32808391 245.79666393 160.         202.38577025 192.        ]
sampled base index:  2
potentials:  [169.32808391 245.79666393 160.         202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:05,  7.30s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:05,  7.30s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:12<00:48,  6.12s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:12<00:48,  6.12s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:16<00:36,  5.25s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:16<00:36,  5.25s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:23<00:34,  5.68s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:23<00:34,  5.68s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:28<00:28,  5.65s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:28<00:28,  5.65s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:32<00:20,  5.12s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:32<00:20,  5.12s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:36<00:14,  4.79s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:36<00:14,  4.79s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:41<00:09,  4.87s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:41<00:09,  4.87s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:48<00:05,  5.50s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:48<00:05,  5.50s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:52<00:00,  5.04s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:52<00:00,  5.04s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  5.04s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  5.46s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.6375
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.6375
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_184615-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_184713-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.6350302696228027, 'learning_rate': 1e-05, 'num_tokens': 1812.0, 'completions/mean_length': 287.0, 'completions/min_length': 212.0, 'completions/max_length': 388.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 287.0, 'completions/min_terminated_length': 212.0, 'completions/max_terminated_length': 388.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 287.0, 'kl': 0.16249232459813356, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.49487224221229553, 'learning_rate': 1e-05, 'num_tokens': 3193.0, 'completions/mean_length': 220.25, 'completions/min_length': 161.0, 'completions/max_length': 250.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 220.25, 'completions/min_terminated_length': 161.0, 'completions/max_terminated_length': 250.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 220.25, 'kl': 0.0601257486268878, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.002862143563106656, 'learning_rate': 1e-05, 'num_tokens': 4305.0, 'completions/mean_length': 155.0, 'completions/min_length': 116.0, 'completions/max_length': 177.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 155.0, 'completions/min_terminated_length': 116.0, 'completions/max_terminated_length': 177.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 155.0, 'kl': 0.08045908156782389, 'epoch': 0.0}
{'loss': 0.0007, 'grad_norm': 0.6818373799324036, 'learning_rate': 1e-05, 'num_tokens': 5851.0, 'completions/mean_length': 236.5, 'completions/min_length': 181.0, 'completions/max_length': 322.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 236.5, 'completions/min_terminated_length': 181.0, 'completions/max_terminated_length': 322.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 236.5, 'kl': 0.697030883282423, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0037859799340367317, 'learning_rate': 1e-05, 'num_tokens': 7471.0, 'completions/mean_length': 249.0, 'completions/min_length': 230.0, 'completions/max_length': 268.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 249.0, 'completions/min_terminated_length': 230.0, 'completions/max_terminated_length': 268.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 249.0, 'kl': 0.08922120928764343, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.002814690815284848, 'learning_rate': 1e-05, 'num_tokens': 8527.0, 'completions/mean_length': 136.0, 'completions/min_length': 108.0, 'completions/max_length': 169.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 136.0, 'completions/min_terminated_length': 108.0, 'completions/max_terminated_length': 169.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 136.0, 'kl': 0.09454530477523804, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.017159560695290565, 'learning_rate': 1e-05, 'num_tokens': 9661.0, 'completions/mean_length': 144.5, 'completions/min_length': 132.0, 'completions/max_length': 168.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 144.5, 'completions/min_terminated_length': 132.0, 'completions/max_terminated_length': 168.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 144.5, 'kl': 0.26128306053578854, 'epoch': 0.0}
{'loss': 0.001, 'grad_norm': 0.13807058334350586, 'learning_rate': 1e-05, 'num_tokens': 10978.0, 'completions/mean_length': 188.25, 'completions/min_length': 139.0, 'completions/max_length': 233.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 188.25, 'completions/min_terminated_length': 139.0, 'completions/max_terminated_length': 233.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 188.25, 'kl': 0.9529437972232699, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.003889264538884163, 'learning_rate': 1e-05, 'num_tokens': 12420.0, 'completions/mean_length': 229.5, 'completions/min_length': 169.0, 'completions/max_length': 360.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 229.5, 'completions/min_terminated_length': 169.0, 'completions/max_terminated_length': 360.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 229.5, 'kl': 0.06865818239748478, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.010796522721648216, 'learning_rate': 1e-05, 'num_tokens': 13397.0, 'completions/mean_length': 138.25, 'completions/min_length': 120.0, 'completions/max_length': 164.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 138.25, 'completions/min_terminated_length': 120.0, 'completions/max_terminated_length': 164.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 138.25, 'kl': 0.15949729084968567, 'epoch': 0.0}
{'train_runtime': 54.6262, 'train_samples_per_second': 0.732, 'train_steps_per_second': 0.183, 'train_loss': 0.0002626263172714971, 'epoch': 0.0}
[EP 0110] 2 | reward_mean=1.762 | 
*** stats:  {'episode_reward_mean': 1.7625, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.3185476899147034, 'episode_reward_trajectory': [1.0, 1.5, 2.0, 1.125, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.5, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.2625, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.3185476899147034, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.7625
All rewards  9.187500000000002
Cumulative rewards  [-26.275, 35.087500000000006, 21.8375, -10.8125, -10.65]
Num plays  [7, 59, 26, 10, 9]
Mean rewards  [-3.7535714285714286, 0.5947033898305085, 0.8399038461538461, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [169.32808391 245.79666393 163.16862443 202.38577025 192.        ]
sampled base index:  2
potentials:  [169.32808391 245.79666393 163.16862443 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.43s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.43s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:16<01:02,  7.78s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:16<01:02,  7.78s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:43,  6.16s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:43,  6.16s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:26<00:34,  5.80s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:26<00:34,  5.80s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:37<00:39,  7.81s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:37<00:39,  7.81s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:26,  6.67s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:42<00:26,  6.67s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:45<00:17,  5.68s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:45<00:17,  5.68s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:50<00:10,  5.31s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:50<00:10,  5.31s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:59<00:06,  6.36s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:59<00:06,  6.36s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  5.61s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:03<00:00,  5.61s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:04<00:00,  5.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:04<00:00,  6.47s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.7625
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.7625
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_184713-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_184822-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0007, 'grad_norm': 0.5854072570800781, 'learning_rate': 1e-05, 'num_tokens': 2202.0, 'completions/mean_length': 384.5, 'completions/min_length': 212.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 267.3333435058594, 'completions/min_terminated_length': 212.0, 'completions/max_terminated_length': 305.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': -0.125, 'reward_std': 1.8427786827087402, 'frac_reward_zero_std': 0.0, 'completion_length': 384.5, 'kl': 0.7344620488584042, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 1.0042870044708252, 'learning_rate': 1e-05, 'num_tokens': 3434.0, 'completions/mean_length': 183.0, 'completions/min_length': 146.0, 'completions/max_length': 198.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 183.0, 'completions/min_terminated_length': 146.0, 'completions/max_terminated_length': 198.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 183.0, 'kl': 0.13652658788487315, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.008961505256593227, 'learning_rate': 1e-05, 'num_tokens': 4571.0, 'completions/mean_length': 161.25, 'completions/min_length': 148.0, 'completions/max_length': 179.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 161.25, 'completions/min_terminated_length': 148.0, 'completions/max_terminated_length': 179.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 161.25, 'kl': 0.12532398756593466, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.5506682395935059, 'learning_rate': 1e-05, 'num_tokens': 6035.0, 'completions/mean_length': 216.0, 'completions/min_length': 170.0, 'completions/max_length': 248.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 216.0, 'completions/min_terminated_length': 170.0, 'completions/max_terminated_length': 248.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 216.0, 'kl': 0.16648956388235092, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.14053915441036224, 'learning_rate': 1e-05, 'num_tokens': 8093.0, 'completions/mean_length': 358.5, 'completions/min_length': 249.0, 'completions/max_length': 666.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 358.5, 'completions/min_terminated_length': 249.0, 'completions/max_terminated_length': 666.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 358.5, 'kl': 0.7622222295030951, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.006575330160558224, 'learning_rate': 1e-05, 'num_tokens': 9250.0, 'completions/mean_length': 161.25, 'completions/min_length': 139.0, 'completions/max_length': 193.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 161.25, 'completions/min_terminated_length': 139.0, 'completions/max_terminated_length': 193.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 161.25, 'kl': 0.12236115103587508, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.007974838837981224, 'learning_rate': 1e-05, 'num_tokens': 10290.0, 'completions/mean_length': 121.0, 'completions/min_length': 103.0, 'completions/max_length': 137.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 121.0, 'completions/min_terminated_length': 103.0, 'completions/max_terminated_length': 137.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 121.0, 'kl': 0.11307297646999359, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.6130357384681702, 'learning_rate': 1e-05, 'num_tokens': 11550.0, 'completions/mean_length': 174.0, 'completions/min_length': 139.0, 'completions/max_length': 196.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 174.0, 'completions/min_terminated_length': 139.0, 'completions/max_terminated_length': 196.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.875, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 174.0, 'kl': 0.2889401772990823, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.7925245761871338, 'learning_rate': 1e-05, 'num_tokens': 13131.0, 'completions/mean_length': 264.25, 'completions/min_length': 125.0, 'completions/max_length': 482.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 264.25, 'completions/min_terminated_length': 125.0, 'completions/max_terminated_length': 482.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 264.25, 'kl': 0.18624106422066689, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.003790593473240733, 'learning_rate': 1e-05, 'num_tokens': 14141.0, 'completions/mean_length': 146.5, 'completions/min_length': 138.0, 'completions/max_length': 157.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 146.5, 'completions/min_terminated_length': 138.0, 'completions/max_terminated_length': 157.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 146.5, 'kl': 0.09083531331270933, 'epoch': 0.0}
{'train_runtime': 64.7288, 'train_samples_per_second': 0.618, 'train_steps_per_second': 0.154, 'train_loss': 0.00027265648386674, 'epoch': 0.0}
[EP 0111] 2 | reward_mean=1.488 | 
*** stats:  {'episode_reward_mean': 1.4875, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.6309695720672608, 'episode_reward_trajectory': [-0.125, 1.5, 2.0, 1.125, 2.0, 2.0, 2.0, 0.875, 1.5, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.3875, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.225, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.1, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.4843286514282227, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.4875
All rewards  10.675000000000002
Cumulative rewards  [-26.275, 35.087500000000006, 23.325, -10.8125, -10.65]
Num plays  [7, 59, 27, 10, 9]
Mean rewards  [-3.7535714285714286, 0.5947033898305085, 0.8638888888888888, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [169.32808391 245.79666393 166.27687753 202.38577025 192.        ]
sampled base index:  2
potentials:  [169.32808391 245.79666393 166.27687753 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:05<00:49,  5.52s/it]                                               10%|â–ˆ         | 1/10 [00:05<00:49,  5.52s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:10<00:42,  5.25s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:10<00:42,  5.25s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:35,  5.03s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:35,  5.03s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:21<00:32,  5.35s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:21<00:32,  5.35s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:27<00:27,  5.59s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:27<00:27,  5.59s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:32<00:21,  5.43s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:32<00:21,  5.43s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:35<00:14,  4.85s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:35<00:14,  4.85s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:40<00:09,  4.87s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:40<00:09,  4.87s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:49<00:05,  5.98s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:49<00:05,  5.98s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:53<00:00,  5.36s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:53<00:00,  5.36s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  5.36s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  5.50s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: uploading console lines 11-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.4875
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.4875
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_184822-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_184921-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0004, 'grad_norm': 1.1985716819763184, 'learning_rate': 1e-05, 'num_tokens': 1576.0, 'completions/mean_length': 228.0, 'completions/min_length': 207.0, 'completions/max_length': 262.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 228.0, 'completions/min_terminated_length': 207.0, 'completions/max_terminated_length': 262.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 228.0, 'kl': 0.41313008591532707, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.01954427734017372, 'learning_rate': 1e-05, 'num_tokens': 2861.0, 'completions/mean_length': 196.25, 'completions/min_length': 170.0, 'completions/max_length': 235.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 196.25, 'completions/min_terminated_length': 170.0, 'completions/max_terminated_length': 235.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 196.25, 'kl': 0.19935280084609985, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0025049576070159674, 'learning_rate': 1e-05, 'num_tokens': 4120.0, 'completions/mean_length': 191.75, 'completions/min_length': 172.0, 'completions/max_length': 214.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 191.75, 'completions/min_terminated_length': 172.0, 'completions/max_terminated_length': 214.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 191.75, 'kl': 0.07768457010388374, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.5176001787185669, 'learning_rate': 1e-05, 'num_tokens': 5785.0, 'completions/mean_length': 266.25, 'completions/min_length': 247.0, 'completions/max_length': 290.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 266.25, 'completions/min_terminated_length': 247.0, 'completions/max_terminated_length': 290.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 266.25, 'kl': 0.24426268227398396, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.003553899470716715, 'learning_rate': 1e-05, 'num_tokens': 7477.0, 'completions/mean_length': 267.0, 'completions/min_length': 219.0, 'completions/max_length': 299.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 267.0, 'completions/min_terminated_length': 219.0, 'completions/max_terminated_length': 299.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 267.0, 'kl': 0.06541632860898972, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.003993854857981205, 'learning_rate': 1e-05, 'num_tokens': 8653.0, 'completions/mean_length': 166.0, 'completions/min_length': 140.0, 'completions/max_length': 237.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 166.0, 'completions/min_terminated_length': 140.0, 'completions/max_terminated_length': 237.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 166.0, 'kl': 0.09730343520641327, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.003208399284631014, 'learning_rate': 1e-05, 'num_tokens': 9682.0, 'completions/mean_length': 118.25, 'completions/min_length': 93.0, 'completions/max_length': 137.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 118.25, 'completions/min_terminated_length': 93.0, 'completions/max_terminated_length': 137.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 118.25, 'kl': 0.10311170667409897, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.002796769607812166, 'learning_rate': 1e-05, 'num_tokens': 10947.0, 'completions/mean_length': 175.25, 'completions/min_length': 136.0, 'completions/max_length': 224.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 175.25, 'completions/min_terminated_length': 136.0, 'completions/max_terminated_length': 224.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 175.25, 'kl': 0.08535885065793991, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.6618800759315491, 'learning_rate': 1e-05, 'num_tokens': 12640.0, 'completions/mean_length': 292.25, 'completions/min_length': 217.0, 'completions/max_length': 465.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 292.25, 'completions/min_terminated_length': 217.0, 'completions/max_terminated_length': 465.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 292.25, 'kl': 0.12277274578809738, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.01286911591887474, 'learning_rate': 1e-05, 'num_tokens': 13647.0, 'completions/mean_length': 145.75, 'completions/min_length': 112.0, 'completions/max_length': 160.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 145.75, 'completions/min_terminated_length': 112.0, 'completions/max_terminated_length': 160.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 145.75, 'kl': 0.24565338715910912, 'epoch': 0.0}
{'train_runtime': 54.9707, 'train_samples_per_second': 0.728, 'train_steps_per_second': 0.182, 'train_loss': 0.0001654001636779867, 'epoch': 0.0}
[EP 0112] 2 | reward_mean=1.650 | 
*** stats:  {'episode_reward_mean': 1.65, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.3, 'episode_reward_trajectory': [0.5, 2.0, 2.0, 0.5, 2.0, 2.0, 2.0, 2.0, 1.5, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.5, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.15, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.3, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.65
All rewards  12.325000000000003
Cumulative rewards  [-26.275, 35.087500000000006, 24.974999999999998, -10.8125, -10.65]
Num plays  [7, 59, 28, 10, 9]
Mean rewards  [-3.7535714285714286, 0.5947033898305085, 0.8919642857142857, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [169.32808391 245.79666393 169.32808391 202.38577025 192.        ]
sampled base index:  0
potentials:  [169.32808391 245.79666393 169.32808391 202.38577025 192.        ]
sampled base index:  0
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.29s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.29s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.27s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.27s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.26s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.26s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.27s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.27s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.28s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.28s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.26s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.26s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.27s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:25<00:36, 12.27s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.27s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.27s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.27s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.27s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.25s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.25s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.25s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.43s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.65
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.65
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_184921-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_185129-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.00016818358562886715, 'learning_rate': 0.001, 'num_tokens': 3608.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.053515891544520855, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00022517205798067153, 'learning_rate': 0.001, 'num_tokens': 7052.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.061578018590807915, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0011919066309928894, 'learning_rate': 0.001, 'num_tokens': 10488.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.06543212290853262, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0001639717083889991, 'learning_rate': 0.001, 'num_tokens': 14032.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.039752558805048466, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0001789897942217067, 'learning_rate': 0.001, 'num_tokens': 17600.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.04883832857012749, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0003086641081608832, 'learning_rate': 0.001, 'num_tokens': 21056.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.05982687324285507, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00026078184600919485, 'learning_rate': 0.001, 'num_tokens': 24556.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.05568900424987078, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00038469425635412335, 'learning_rate': 0.001, 'num_tokens': 28064.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.05238515231758356, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0002804994583129883, 'learning_rate': 0.001, 'num_tokens': 31532.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.04379214532673359, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0003455221885815263, 'learning_rate': 0.001, 'num_tokens': 34900.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.05234932526946068, 'epoch': 0.0}
{'train_runtime': 124.3205, 'train_samples_per_second': 0.322, 'train_steps_per_second': 0.08, 'train_loss': 5.3315946206566875e-05, 'epoch': 0.0}
[EP 0113] 0 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  8.325000000000003
Cumulative rewards  [-30.275, 35.087500000000006, 24.974999999999998, -10.8125, -10.65]
Num plays  [8, 59, 28, 10, 9]
Mean rewards  [-3.784375, 0.5947033898305085, 0.8919642857142857, -1.08125, -1.1833333333333333]
Balancing probabilities  [1, 0, 0, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [181.01933598 245.79666393 169.32808391 202.38577025 192.        ]
sampled base index:  2
potentials:  [181.01933598 245.79666393 169.32808391 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:08<01:13,  8.13s/it]                                               10%|â–ˆ         | 1/10 [00:08<01:13,  8.13s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:13<00:51,  6.50s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:13<00:51,  6.50s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:38,  5.48s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:38,  5.48s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:35,  5.88s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:35,  5.88s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:30<00:30,  6.18s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:30<00:30,  6.18s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:35<00:21,  5.47s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:35<00:21,  5.47s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:39<00:15,  5.11s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:39<00:15,  5.11s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:44<00:10,  5.06s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:44<00:10,  5.06s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:48<00:04,  4.89s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:48<00:04,  4.89s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:53<00:00,  4.81s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:53<00:00,  4.81s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:55<00:00,  4.81s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:55<00:00,  5.52s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_0_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.65
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 0
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_185129-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_185228-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0288, 'grad_norm': 12.070236206054688, 'learning_rate': 1e-05, 'num_tokens': 1940.0, 'completions/mean_length': 319.0, 'completions/min_length': 228.0, 'completions/max_length': 447.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 319.0, 'completions/min_terminated_length': 228.0, 'completions/max_terminated_length': 447.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 319.0, 'kl': 28.77801663428545, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.022774262353777885, 'learning_rate': 1e-05, 'num_tokens': 3223.0, 'completions/mean_length': 195.75, 'completions/min_length': 149.0, 'completions/max_length': 254.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 195.75, 'completions/min_terminated_length': 149.0, 'completions/max_terminated_length': 254.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 195.75, 'kl': 0.15388248488307, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.012709269300103188, 'learning_rate': 1e-05, 'num_tokens': 4371.0, 'completions/mean_length': 164.0, 'completions/min_length': 129.0, 'completions/max_length': 182.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 164.0, 'completions/min_terminated_length': 129.0, 'completions/max_terminated_length': 182.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 164.0, 'kl': 0.15397020988166332, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.7319744229316711, 'learning_rate': 1e-05, 'num_tokens': 6060.0, 'completions/mean_length': 272.25, 'completions/min_length': 200.0, 'completions/max_length': 333.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 272.25, 'completions/min_terminated_length': 200.0, 'completions/max_terminated_length': 333.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 272.25, 'kl': 0.12489884160459042, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0014915895881131291, 'learning_rate': 1e-05, 'num_tokens': 7817.0, 'completions/mean_length': 283.25, 'completions/min_length': 255.0, 'completions/max_length': 347.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 283.25, 'completions/min_terminated_length': 255.0, 'completions/max_terminated_length': 347.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 283.25, 'kl': 0.038091293070465326, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.000670460460241884, 'learning_rate': 1e-05, 'num_tokens': 8922.0, 'completions/mean_length': 148.25, 'completions/min_length': 128.0, 'completions/max_length': 169.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 148.25, 'completions/min_terminated_length': 128.0, 'completions/max_terminated_length': 169.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 148.25, 'kl': 0.05061362823471427, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.8226699829101562, 'learning_rate': 1e-05, 'num_tokens': 10068.0, 'completions/mean_length': 147.5, 'completions/min_length': 121.0, 'completions/max_length': 186.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 147.5, 'completions/min_terminated_length': 121.0, 'completions/max_terminated_length': 186.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 147.5, 'kl': 0.10773980151861906, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0011181674199178815, 'learning_rate': 1e-05, 'num_tokens': 11410.0, 'completions/mean_length': 194.5, 'completions/min_length': 167.0, 'completions/max_length': 228.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 194.5, 'completions/min_terminated_length': 167.0, 'completions/max_terminated_length': 228.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 194.5, 'kl': 0.06257351581007242, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.007122666575014591, 'learning_rate': 1e-05, 'num_tokens': 12669.0, 'completions/mean_length': 183.75, 'completions/min_length': 174.0, 'completions/max_length': 196.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 183.75, 'completions/min_terminated_length': 174.0, 'completions/max_terminated_length': 196.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 183.75, 'kl': 0.09968730434775352, 'epoch': 0.0}
{'loss': 0.0012, 'grad_norm': 0.6422393918037415, 'learning_rate': 1e-05, 'num_tokens': 13794.0, 'completions/mean_length': 175.25, 'completions/min_length': 131.0, 'completions/max_length': 209.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 175.25, 'completions/min_terminated_length': 131.0, 'completions/max_terminated_length': 209.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 175.25, 'kl': 1.216122261248529, 'epoch': 0.0}
{'train_runtime': 55.187, 'train_samples_per_second': 0.725, 'train_steps_per_second': 0.181, 'train_loss': 0.0030785645129071783, 'epoch': 0.0}
[EP 0114] 2 | reward_mean=1.650 | 
*** stats:  {'episode_reward_mean': 1.65, 'episode_reward_last': 1.5, 'episode_reward_std_mean': 0.4154700517654419, 'episode_reward_trajectory': [0.5, 2.0, 2.0, 1.0, 2.0, 2.0, 1.5, 2.0, 2.0, 1.5], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.5, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.15, 'rewards/check_numbers/mean/last': 1.0, 'rewards/check_numbers/std/mean': 0.4154700517654419, 'rewards/check_numbers/std/last': 1.0}
Curr reward  1.65
All rewards  9.975000000000003
Cumulative rewards  [-30.275, 35.087500000000006, 26.624999999999996, -10.8125, -10.65]
Num plays  [8, 59, 29, 10, 9]
Mean rewards  [-3.784375, 0.5947033898305085, 0.918103448275862, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [181.01933598 245.79666393 172.32527383 202.38577025 192.        ]
sampled base index:  2
potentials:  [181.01933598 245.79666393 172.32527383 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:03,  7.10s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:03,  7.10s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:15<01:02,  7.84s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:15<01:02,  7.84s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:41,  6.00s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:41,  6.00s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:33,  5.61s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:33,  5.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:28,  5.61s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:28,  5.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:34<00:20,  5.20s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:34<00:20,  5.20s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:38<00:14,  4.77s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:38<00:14,  4.77s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:42<00:09,  4.76s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:42<00:09,  4.76s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:47<00:04,  4.82s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:47<00:04,  4.82s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:52<00:00,  4.73s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:52<00:00,  4.73s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  4.73s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  5.41s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.65
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.65
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_185228-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_185326-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.008060968481004238, 'learning_rate': 1e-05, 'num_tokens': 1956.0, 'completions/mean_length': 323.0, 'completions/min_length': 270.0, 'completions/max_length': 376.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 323.0, 'completions/min_terminated_length': 270.0, 'completions/max_terminated_length': 376.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 323.0, 'kl': 0.1888430006802082, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.6493281722068787, 'learning_rate': 1e-05, 'num_tokens': 3378.0, 'completions/mean_length': 230.5, 'completions/min_length': 150.0, 'completions/max_length': 457.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 230.5, 'completions/min_terminated_length': 150.0, 'completions/max_terminated_length': 457.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 230.5, 'kl': 0.28239660151302814, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.9795058965682983, 'learning_rate': 1e-05, 'num_tokens': 4413.0, 'completions/mean_length': 135.75, 'completions/min_length': 124.0, 'completions/max_length': 148.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 135.75, 'completions/min_terminated_length': 124.0, 'completions/max_terminated_length': 148.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 135.75, 'kl': 0.20962416008114815, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.010144325904548168, 'learning_rate': 1e-05, 'num_tokens': 5859.0, 'completions/mean_length': 211.5, 'completions/min_length': 198.0, 'completions/max_length': 230.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 211.5, 'completions/min_terminated_length': 198.0, 'completions/max_terminated_length': 230.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 211.5, 'kl': 0.1344584207981825, 'epoch': 0.0}
{'loss': 0.0016, 'grad_norm': 0.5428280830383301, 'learning_rate': 1e-05, 'num_tokens': 7497.0, 'completions/mean_length': 253.5, 'completions/min_length': 221.0, 'completions/max_length': 269.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 253.5, 'completions/min_terminated_length': 221.0, 'completions/max_terminated_length': 269.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 1.25, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 253.5, 'kl': 1.5586474686861038, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.002216227585449815, 'learning_rate': 1e-05, 'num_tokens': 8681.0, 'completions/mean_length': 168.0, 'completions/min_length': 128.0, 'completions/max_length': 192.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 168.0, 'completions/min_terminated_length': 128.0, 'completions/max_terminated_length': 192.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 168.0, 'kl': 0.08889423217624426, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0035614881198853254, 'learning_rate': 1e-05, 'num_tokens': 9788.0, 'completions/mean_length': 137.75, 'completions/min_length': 131.0, 'completions/max_length': 154.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 137.75, 'completions/min_terminated_length': 131.0, 'completions/max_terminated_length': 154.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 137.75, 'kl': 0.08364109043031931, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.39412304759025574, 'learning_rate': 1e-05, 'num_tokens': 11090.0, 'completions/mean_length': 184.5, 'completions/min_length': 155.0, 'completions/max_length': 213.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 184.5, 'completions/min_terminated_length': 155.0, 'completions/max_terminated_length': 213.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 184.5, 'kl': 0.07295312453061342, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.007541461382061243, 'learning_rate': 1e-05, 'num_tokens': 12385.0, 'completions/mean_length': 192.75, 'completions/min_length': 176.0, 'completions/max_length': 225.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 192.75, 'completions/min_terminated_length': 176.0, 'completions/max_terminated_length': 225.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 192.75, 'kl': 0.10398011282086372, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.004203577991575003, 'learning_rate': 1e-05, 'num_tokens': 13359.0, 'completions/mean_length': 137.5, 'completions/min_length': 86.0, 'completions/max_length': 199.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 137.5, 'completions/min_terminated_length': 86.0, 'completions/max_terminated_length': 199.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 137.5, 'kl': 0.12238874658942223, 'epoch': 0.0}
{'train_runtime': 54.0986, 'train_samples_per_second': 0.739, 'train_steps_per_second': 0.185, 'train_loss': 0.00028458744200179356, 'epoch': 0.0}
[EP 0115] 2 | reward_mean=1.587 | 
*** stats:  {'episode_reward_mean': 1.5875, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.425, 'episode_reward_trajectory': [0.0, 1.5, 1.5, 2.0, 1.25, 2.0, 2.0, 1.625, 2.0, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.425, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.15, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.1625, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.275, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.5875
All rewards  11.562500000000004
Cumulative rewards  [-30.275, 35.087500000000006, 28.212499999999995, -10.8125, -10.65]
Num plays  [8, 59, 30, 10, 9]
Mean rewards  [-3.784375, 0.5947033898305085, 0.9404166666666665, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [181.01933598 245.79666393 175.2712184  202.38577025 192.        ]
sampled base index:  2
potentials:  [181.01933598 245.79666393 175.2712184  202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:06<00:57,  6.40s/it]                                               10%|â–ˆ         | 1/10 [00:06<00:57,  6.40s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:10<00:41,  5.25s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:10<00:41,  5.25s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:33,  4.78s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:33,  4.78s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:34,  5.70s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:34,  5.70s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:28<00:29,  5.82s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:28<00:29,  5.82s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:32<00:21,  5.33s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:32<00:21,  5.33s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:36<00:14,  4.78s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:36<00:14,  4.78s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:40<00:09,  4.67s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:40<00:09,  4.67s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:50<00:06,  6.34s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:50<00:06,  6.34s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:55<00:00,  5.83s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:55<00:00,  5.83s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:57<00:00,  5.83s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:57<00:00,  5.71s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.5875
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.5875
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_185326-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_185427-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.00805073231458664, 'learning_rate': 1e-05, 'num_tokens': 1694.0, 'completions/mean_length': 257.5, 'completions/min_length': 198.0, 'completions/max_length': 326.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 257.5, 'completions/min_terminated_length': 198.0, 'completions/max_terminated_length': 326.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 257.5, 'kl': 0.18951183557510376, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0018215208547189832, 'learning_rate': 1e-05, 'num_tokens': 2887.0, 'completions/mean_length': 173.25, 'completions/min_length': 145.0, 'completions/max_length': 194.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 173.25, 'completions/min_terminated_length': 145.0, 'completions/max_terminated_length': 194.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 173.25, 'kl': 0.06542523764073849, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.6311199069023132, 'learning_rate': 1e-05, 'num_tokens': 4052.0, 'completions/mean_length': 168.25, 'completions/min_length': 154.0, 'completions/max_length': 179.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 168.25, 'completions/min_terminated_length': 154.0, 'completions/max_terminated_length': 179.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 168.25, 'kl': 0.09424104634672403, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.031474169343709946, 'learning_rate': 1e-05, 'num_tokens': 5648.0, 'completions/mean_length': 249.0, 'completions/min_length': 161.0, 'completions/max_length': 375.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 249.0, 'completions/min_terminated_length': 161.0, 'completions/max_terminated_length': 375.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 249.0, 'kl': 0.2252966808155179, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.7839102745056152, 'learning_rate': 1e-05, 'num_tokens': 7377.0, 'completions/mean_length': 276.25, 'completions/min_length': 257.0, 'completions/max_length': 301.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 276.25, 'completions/min_terminated_length': 257.0, 'completions/max_terminated_length': 301.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 276.25, 'kl': 0.06466157548129559, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.005372037645429373, 'learning_rate': 1e-05, 'num_tokens': 8624.0, 'completions/mean_length': 183.75, 'completions/min_length': 179.0, 'completions/max_length': 190.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 183.75, 'completions/min_terminated_length': 179.0, 'completions/max_terminated_length': 190.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 183.75, 'kl': 0.06676531909033656, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0007874536677263677, 'learning_rate': 1e-05, 'num_tokens': 9679.0, 'completions/mean_length': 124.75, 'completions/min_length': 118.0, 'completions/max_length': 138.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 124.75, 'completions/min_terminated_length': 118.0, 'completions/max_terminated_length': 138.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 124.75, 'kl': 0.05612310208380222, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 0.7240671515464783, 'learning_rate': 1e-05, 'num_tokens': 10877.0, 'completions/mean_length': 158.5, 'completions/min_length': 145.0, 'completions/max_length': 191.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 158.5, 'completions/min_terminated_length': 145.0, 'completions/max_terminated_length': 191.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 1.125, 'reward_std': 1.0307763814926147, 'frac_reward_zero_std': 0.0, 'completion_length': 158.5, 'kl': 0.5798303140327334, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.6590149402618408, 'learning_rate': 1e-05, 'num_tokens': 12678.0, 'completions/mean_length': 319.25, 'completions/min_length': 150.0, 'completions/max_length': 580.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 319.25, 'completions/min_terminated_length': 150.0, 'completions/max_terminated_length': 580.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 319.25, 'kl': 0.14594730734825134, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.008633681572973728, 'learning_rate': 1e-05, 'num_tokens': 13697.0, 'completions/mean_length': 148.75, 'completions/min_length': 103.0, 'completions/max_length': 212.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 148.75, 'completions/min_terminated_length': 103.0, 'completions/max_terminated_length': 212.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 148.75, 'kl': 0.16358505934476852, 'epoch': 0.0}
{'train_runtime': 57.1287, 'train_samples_per_second': 0.7, 'train_steps_per_second': 0.175, 'train_loss': 0.00016513966911588796, 'epoch': 0.0}
[EP 0116] 2 | reward_mean=1.512 | 
*** stats:  {'episode_reward_mean': 1.5125, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.41854768991470337, 'episode_reward_trajectory': [0.0, 2.0, 1.5, 2.0, 1.5, 2.0, 2.0, 1.125, 1.0, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.5, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.0125, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.41854768991470337, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.5125
All rewards  13.075000000000003
Cumulative rewards  [-30.275, 35.087500000000006, 29.724999999999994, -10.8125, -10.65]
Num plays  [8, 59, 31, 10, 9]
Mean rewards  [-3.784375, 0.5947033898305085, 0.9588709677419353, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [181.01933598 245.79666393 178.16845961 202.38577025 192.        ]
sampled base index:  2
potentials:  [181.01933598 245.79666393 178.16845961 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:06<01:01,  6.85s/it]                                               10%|â–ˆ         | 1/10 [00:06<01:01,  6.85s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:11<00:45,  5.75s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:11<00:45,  5.75s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:34,  4.93s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:34,  4.93s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:33,  5.54s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:33,  5.54s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:28<00:28,  5.74s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:28<00:28,  5.74s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:32<00:20,  5.15s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:32<00:20,  5.15s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:36<00:14,  4.74s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:36<00:14,  4.74s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:40<00:09,  4.59s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:40<00:09,  4.59s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:45<00:04,  4.72s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:45<00:04,  4.72s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:49<00:00,  4.42s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:49<00:00,  4.42s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:51<00:00,  4.42s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:51<00:00,  5.11s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.5125
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.5125
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_185427-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_185522-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.7256025075912476, 'learning_rate': 1e-05, 'num_tokens': 1868.0, 'completions/mean_length': 301.0, 'completions/min_length': 261.0, 'completions/max_length': 360.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 301.0, 'completions/min_terminated_length': 261.0, 'completions/max_terminated_length': 360.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.125, 'rewards/check_numbers/std': 0.9464847445487976, 'reward': -0.125, 'reward_std': 1.8427786827087402, 'frac_reward_zero_std': 0.0, 'completion_length': 301.0, 'kl': 0.12764043733477592, 'epoch': 0.0}
{'loss': 0.0017, 'grad_norm': 1.4128872156143188, 'learning_rate': 1e-05, 'num_tokens': 3190.0, 'completions/mean_length': 205.5, 'completions/min_length': 169.0, 'completions/max_length': 233.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 205.5, 'completions/min_terminated_length': 169.0, 'completions/max_terminated_length': 233.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 205.5, 'kl': 1.699940862134099, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0031081896740943193, 'learning_rate': 1e-05, 'num_tokens': 4293.0, 'completions/mean_length': 152.75, 'completions/min_length': 133.0, 'completions/max_length': 164.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 152.75, 'completions/min_terminated_length': 133.0, 'completions/max_terminated_length': 164.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 152.75, 'kl': 0.09611816611140966, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.6008687615394592, 'learning_rate': 1e-05, 'num_tokens': 5928.0, 'completions/mean_length': 258.75, 'completions/min_length': 192.0, 'completions/max_length': 332.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 258.75, 'completions/min_terminated_length': 192.0, 'completions/max_terminated_length': 332.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 258.75, 'kl': 0.14714965503662825, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.02007594332098961, 'learning_rate': 1e-05, 'num_tokens': 7659.0, 'completions/mean_length': 276.75, 'completions/min_length': 256.0, 'completions/max_length': 307.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 276.75, 'completions/min_terminated_length': 256.0, 'completions/max_terminated_length': 307.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 276.75, 'kl': 0.19295370392501354, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.01368475891649723, 'learning_rate': 1e-05, 'num_tokens': 8793.0, 'completions/mean_length': 155.5, 'completions/min_length': 151.0, 'completions/max_length': 160.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 155.5, 'completions/min_terminated_length': 151.0, 'completions/max_terminated_length': 160.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 155.5, 'kl': 0.12466294411569834, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 1.9695850610733032, 'learning_rate': 1e-05, 'num_tokens': 9890.0, 'completions/mean_length': 135.25, 'completions/min_length': 111.0, 'completions/max_length': 156.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 135.25, 'completions/min_terminated_length': 111.0, 'completions/max_terminated_length': 156.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 135.25, 'kl': 0.1766850147396326, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00562095083296299, 'learning_rate': 1e-05, 'num_tokens': 11079.0, 'completions/mean_length': 156.25, 'completions/min_length': 134.0, 'completions/max_length': 180.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 156.25, 'completions/min_terminated_length': 134.0, 'completions/max_terminated_length': 180.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 156.25, 'kl': 0.1039991332218051, 'epoch': 0.0}
{'loss': 0.0064, 'grad_norm': 3.894578456878662, 'learning_rate': 1e-05, 'num_tokens': 12477.0, 'completions/mean_length': 218.5, 'completions/min_length': 192.0, 'completions/max_length': 231.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 218.5, 'completions/min_terminated_length': 192.0, 'completions/max_terminated_length': 231.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 218.5, 'kl': 6.40893167629838, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 1.3003960847854614, 'learning_rate': 1e-05, 'num_tokens': 13425.0, 'completions/mean_length': 131.0, 'completions/min_length': 110.0, 'completions/max_length': 146.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 131.0, 'completions/min_terminated_length': 110.0, 'completions/max_terminated_length': 146.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 131.0, 'kl': 0.09166395757347345, 'epoch': 0.0}
{'train_runtime': 51.0628, 'train_samples_per_second': 0.783, 'train_steps_per_second': 0.196, 'train_loss': 0.0009169811950414441, 'epoch': 0.0}
[EP 0117] 2 | reward_mean=1.488 | 
*** stats:  {'episode_reward_mean': 1.4875, 'episode_reward_last': 1.5, 'episode_reward_std_mean': 0.584277868270874, 'episode_reward_trajectory': [-0.125, 1.5, 2.0, 0.5, 2.0, 2.0, 1.5, 2.0, 2.0, 1.5], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.425, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.15, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.0625, 'rewards/check_numbers/mean/last': 1.0, 'rewards/check_numbers/std/mean': 0.49464847445487975, 'rewards/check_numbers/std/last': 1.0}
Curr reward  1.4875
All rewards  14.562500000000004
Cumulative rewards  [-30.275, 35.087500000000006, 31.212499999999995, -10.8125, -10.65]
Num plays  [8, 59, 32, 10, 9]
Mean rewards  [-3.784375, 0.5947033898305085, 0.9753906249999998, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [181.01933598 245.79666393 181.01933598 202.38577025 192.        ]
sampled base index:  0
potentials:  [181.01933598 245.79666393 181.01933598 202.38577025 192.        ]
sampled base index:  0
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.35s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.35s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.27s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:38, 12.27s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.28s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:25, 12.28s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.27s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:49<01:13, 12.27s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.30s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:01<01:01, 12.30s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.28s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:13<00:49, 12.28s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.29s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:26<00:36, 12.29s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.28s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:38<00:24, 12.28s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.28s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:50<00:12, 12.28s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.26s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.26s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.26s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:04<00:00, 12.45s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.4875
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.4875
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_185522-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_185730-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.000340212689479813, 'learning_rate': 0.001, 'num_tokens': 3171.0, 'completions/mean_length': 626.75, 'completions/min_length': 299.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 299.0, 'completions/min_terminated_length': 299.0, 'completions/max_terminated_length': 299.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 626.75, 'kl': 0.06510313227772713, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00018854641530197114, 'learning_rate': 0.001, 'num_tokens': 6615.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.056395186111330986, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0002788105048239231, 'learning_rate': 0.001, 'num_tokens': 10051.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.05003589019179344, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00017452221072744578, 'learning_rate': 0.001, 'num_tokens': 13595.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.038520549423992634, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0001757503196131438, 'learning_rate': 0.001, 'num_tokens': 17163.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.04955053050071001, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00024353299522772431, 'learning_rate': 0.001, 'num_tokens': 20619.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.059575751423835754, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00019518350018188357, 'learning_rate': 0.001, 'num_tokens': 24119.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.052126954309642315, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0002778104681055993, 'learning_rate': 0.001, 'num_tokens': 27627.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.04717155359685421, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00033449128386564553, 'learning_rate': 0.001, 'num_tokens': 31095.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.04248933121562004, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0003214529133401811, 'learning_rate': 0.001, 'num_tokens': 34463.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.05185131821781397, 'epoch': 0.0}
{'train_runtime': 124.5117, 'train_samples_per_second': 0.321, 'train_steps_per_second': 0.08, 'train_loss': 5.128202246851288e-05, 'epoch': 0.0}
[EP 0118] 0 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  10.562500000000004
Cumulative rewards  [-34.275, 35.087500000000006, 31.212499999999995, -10.8125, -10.65]
Num plays  [9, 59, 32, 10, 9]
Mean rewards  [-3.808333333333333, 0.5947033898305085, 0.9753906249999998, -1.08125, -1.1833333333333333]
Balancing probabilities  [1, 0, 0, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [192.         245.79666393 181.01933598 202.38577025 192.        ]
sampled base index:  2
potentials:  [192.         245.79666393 181.01933598 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:06<00:55,  6.14s/it]                                               10%|â–ˆ         | 1/10 [00:06<00:55,  6.14s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:11<00:43,  5.45s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:11<00:43,  5.45s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:33,  4.81s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:33,  4.81s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:20<00:30,  5.14s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:20<00:30,  5.14s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:27<00:27,  5.59s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:27<00:27,  5.59s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:31<00:20,  5.16s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:31<00:20,  5.16s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:35<00:14,  4.67s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:35<00:14,  4.67s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:39<00:09,  4.66s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:39<00:09,  4.66s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:45<00:04,  4.88s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:45<00:04,  4.88s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:49<00:00,  4.76s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:49<00:00,  4.76s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:51<00:00,  4.76s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:51<00:00,  5.14s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_0_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.4875
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 0
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_185730-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_185826-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0004, 'grad_norm': 0.7736100554466248, 'learning_rate': 1e-05, 'num_tokens': 1705.0, 'completions/mean_length': 260.25, 'completions/min_length': 208.0, 'completions/max_length': 317.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 260.25, 'completions/min_terminated_length': 208.0, 'completions/max_terminated_length': 317.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 260.25, 'kl': 0.3957395739853382, 'epoch': 0.0}
{'loss': 7.0303, 'grad_norm': 3760.156494140625, 'learning_rate': 1e-05, 'num_tokens': 2967.0, 'completions/mean_length': 190.5, 'completions/min_length': 168.0, 'completions/max_length': 239.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 190.5, 'completions/min_terminated_length': 168.0, 'completions/max_terminated_length': 239.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 190.5, 'kl': 7030.283432569355, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.00719261122867465, 'learning_rate': 1e-05, 'num_tokens': 4084.0, 'completions/mean_length': 156.25, 'completions/min_length': 142.0, 'completions/max_length': 178.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 156.25, 'completions/min_terminated_length': 142.0, 'completions/max_terminated_length': 178.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 156.25, 'kl': 0.16063017398118973, 'epoch': 0.0}
{'loss': 1.9433, 'grad_norm': 1111.3463134765625, 'learning_rate': 1e-05, 'num_tokens': 5476.0, 'completions/mean_length': 198.0, 'completions/min_length': 151.0, 'completions/max_length': 280.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 198.0, 'completions/min_terminated_length': 151.0, 'completions/max_terminated_length': 280.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 198.0, 'kl': 1943.2674027010798, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0024767995346337557, 'learning_rate': 1e-05, 'num_tokens': 7155.0, 'completions/mean_length': 263.75, 'completions/min_length': 226.0, 'completions/max_length': 328.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 263.75, 'completions/min_terminated_length': 226.0, 'completions/max_terminated_length': 328.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 263.75, 'kl': 0.09491037484258413, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0031912168487906456, 'learning_rate': 1e-05, 'num_tokens': 8353.0, 'completions/mean_length': 171.5, 'completions/min_length': 151.0, 'completions/max_length': 190.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 171.5, 'completions/min_terminated_length': 151.0, 'completions/max_terminated_length': 190.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 171.5, 'kl': 0.09031632076948881, 'epoch': 0.0}
{'loss': 0.0005, 'grad_norm': 0.9942046403884888, 'learning_rate': 1e-05, 'num_tokens': 9439.0, 'completions/mean_length': 132.5, 'completions/min_length': 121.0, 'completions/max_length': 144.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 132.5, 'completions/min_terminated_length': 121.0, 'completions/max_terminated_length': 144.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 132.5, 'kl': 0.49182636477053165, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.01237152423709631, 'learning_rate': 1e-05, 'num_tokens': 10678.0, 'completions/mean_length': 168.75, 'completions/min_length': 126.0, 'completions/max_length': 210.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 168.75, 'completions/min_terminated_length': 126.0, 'completions/max_terminated_length': 210.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 168.75, 'kl': 0.12863700464367867, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.004670874215662479, 'learning_rate': 1e-05, 'num_tokens': 12099.0, 'completions/mean_length': 224.25, 'completions/min_length': 188.0, 'completions/max_length': 257.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 224.25, 'completions/min_terminated_length': 188.0, 'completions/max_terminated_length': 257.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 224.25, 'kl': 0.1004874687641859, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.004110603593289852, 'learning_rate': 1e-05, 'num_tokens': 13112.0, 'completions/mean_length': 147.25, 'completions/min_length': 111.0, 'completions/max_length': 202.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 147.25, 'completions/min_terminated_length': 111.0, 'completions/max_terminated_length': 202.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 147.25, 'kl': 0.12187572941184044, 'epoch': 0.0}
{'train_runtime': 51.368, 'train_samples_per_second': 0.779, 'train_steps_per_second': 0.195, 'train_loss': 0.8975136276931153, 'epoch': 0.0}
[EP 0119] 2 | reward_mean=1.800 | 
*** stats:  {'episode_reward_mean': 1.8, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.2, 'episode_reward_trajectory': [0.5, 2.0, 2.0, 2.0, 2.0, 2.0, 1.5, 2.0, 2.0, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.5, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.3, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.2, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.8
All rewards  12.362500000000004
Cumulative rewards  [-34.275, 35.087500000000006, 33.012499999999996, -10.8125, -10.65]
Num plays  [9, 59, 33, 10, 9]
Mean rewards  [-3.808333333333333, 0.5947033898305085, 1.0003787878787878, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [192.         245.79666393 183.82600469 202.38577025 192.        ]
sampled base index:  2
potentials:  [192.         245.79666393 183.82600469 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:51, 12.37s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:51, 12.37s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:17<01:04,  8.11s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:17<01:04,  8.11s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:43,  6.19s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:21<00:43,  6.19s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:26<00:35,  5.85s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:26<00:35,  5.85s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:35<00:34,  6.87s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:35<00:34,  6.87s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:39<00:23,  5.87s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:39<00:23,  5.87s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:43<00:16,  5.40s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:43<00:16,  5.40s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:49<00:10,  5.35s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:49<00:10,  5.35s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:54<00:05,  5.34s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:54<00:05,  5.34s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:58<00:00,  4.96s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:58<00:00,  4.96s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  4.96s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:00<00:00,  6.02s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.8
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.8
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_185826-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_185929-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0003, 'grad_norm': 0.7002833485603333, 'learning_rate': 1e-05, 'num_tokens': 2409.0, 'completions/mean_length': 436.25, 'completions/min_length': 263.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 336.3333435058594, 'completions/min_terminated_length': 263.0, 'completions/max_terminated_length': 389.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.25, 'rewards/match_format_approximately/std': 1.5, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.375, 'rewards/check_numbers/std': 0.25, 'reward': -0.625, 'reward_std': 1.25, 'frac_reward_zero_std': 0.0, 'completion_length': 436.25, 'kl': 0.2834692280739546, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0015885086031630635, 'learning_rate': 1e-05, 'num_tokens': 3708.0, 'completions/mean_length': 199.75, 'completions/min_length': 155.0, 'completions/max_length': 243.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 199.75, 'completions/min_terminated_length': 155.0, 'completions/max_terminated_length': 243.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 199.75, 'kl': 0.0742230610921979, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.006103586405515671, 'learning_rate': 1e-05, 'num_tokens': 4813.0, 'completions/mean_length': 153.25, 'completions/min_length': 146.0, 'completions/max_length': 161.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 153.25, 'completions/min_terminated_length': 146.0, 'completions/max_terminated_length': 161.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 153.25, 'kl': 0.1339371670037508, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.5826627016067505, 'learning_rate': 1e-05, 'num_tokens': 6354.0, 'completions/mean_length': 235.25, 'completions/min_length': 194.0, 'completions/max_length': 258.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 235.25, 'completions/min_terminated_length': 194.0, 'completions/max_terminated_length': 258.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 235.25, 'kl': 0.07283905055373907, 'epoch': 0.0}
{'loss': 0.0019, 'grad_norm': 0.7807981371879578, 'learning_rate': 1e-05, 'num_tokens': 8260.0, 'completions/mean_length': 320.5, 'completions/min_length': 254.0, 'completions/max_length': 482.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 320.5, 'completions/min_terminated_length': 254.0, 'completions/max_terminated_length': 482.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 320.5, 'kl': 1.9380608825013041, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.03191491588950157, 'learning_rate': 1e-05, 'num_tokens': 9403.0, 'completions/mean_length': 157.75, 'completions/min_length': 150.0, 'completions/max_length': 164.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 157.75, 'completions/min_terminated_length': 150.0, 'completions/max_terminated_length': 164.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 157.75, 'kl': 0.308801980689168, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.7156242728233337, 'learning_rate': 1e-05, 'num_tokens': 10529.0, 'completions/mean_length': 142.5, 'completions/min_length': 116.0, 'completions/max_length': 196.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 142.5, 'completions/min_terminated_length': 116.0, 'completions/max_terminated_length': 196.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 142.5, 'kl': 0.12610593531280756, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0023872223682701588, 'learning_rate': 1e-05, 'num_tokens': 11901.0, 'completions/mean_length': 202.0, 'completions/min_length': 172.0, 'completions/max_length': 252.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 202.0, 'completions/min_terminated_length': 172.0, 'completions/max_terminated_length': 252.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 202.0, 'kl': 0.08231031894683838, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.6450604796409607, 'learning_rate': 1e-05, 'num_tokens': 13315.0, 'completions/mean_length': 222.5, 'completions/min_length': 159.0, 'completions/max_length': 256.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 222.5, 'completions/min_terminated_length': 159.0, 'completions/max_terminated_length': 256.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 222.5, 'kl': 0.08872919529676437, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0010719209676608443, 'learning_rate': 1e-05, 'num_tokens': 14280.0, 'completions/mean_length': 135.25, 'completions/min_length': 110.0, 'completions/max_length': 177.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 135.25, 'completions/min_terminated_length': 110.0, 'completions/max_terminated_length': 177.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 135.25, 'kl': 0.0868600569665432, 'epoch': 0.0}
{'train_runtime': 60.1999, 'train_samples_per_second': 0.664, 'train_steps_per_second': 0.166, 'train_loss': 0.0003195398719981313, 'epoch': 0.0}
[EP 0120] 2 | reward_mean=1.337 | 
*** stats:  {'episode_reward_mean': 1.3375, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.5559401035308837, 'episode_reward_trajectory': [-0.625, 2.0, 2.0, 0.5, 1.0, 2.0, 1.5, 2.0, 1.0, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.425, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.15, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.9125, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.45594010353088377, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.3375
All rewards  13.700000000000005
Cumulative rewards  [-34.275, 35.087500000000006, 34.349999999999994, -10.8125, -10.65]
Num plays  [9, 59, 34, 10, 9]
Mean rewards  [-3.808333333333333, 0.5947033898305085, 1.0102941176470586, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [192.         245.79666393 186.59046064 202.38577025 192.        ]
sampled base index:  2
potentials:  [192.         245.79666393 186.59046064 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:06<01:01,  6.88s/it]                                               10%|â–ˆ         | 1/10 [00:06<01:01,  6.88s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:12<00:49,  6.15s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:12<00:49,  6.15s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:16<00:36,  5.22s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:16<00:36,  5.22s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:32,  5.43s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:32,  5.43s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:27<00:26,  5.37s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:27<00:26,  5.37s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:31<00:19,  4.93s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:31<00:19,  4.93s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:35<00:13,  4.57s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:35<00:13,  4.57s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:40<00:09,  4.56s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:40<00:09,  4.56s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:49<00:06,  6.06s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:49<00:06,  6.06s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:53<00:00,  5.49s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:53<00:00,  5.49s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:55<00:00,  5.49s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:55<00:00,  5.53s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.3375
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.3375
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_185929-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_190028-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0003, 'grad_norm': 0.060403332114219666, 'learning_rate': 1e-05, 'num_tokens': 1826.0, 'completions/mean_length': 290.5, 'completions/min_length': 241.0, 'completions/max_length': 370.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 290.5, 'completions/min_terminated_length': 241.0, 'completions/max_terminated_length': 370.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 290.5, 'kl': 0.341219549998641, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.01656080223619938, 'learning_rate': 1e-05, 'num_tokens': 3220.0, 'completions/mean_length': 223.5, 'completions/min_length': 189.0, 'completions/max_length': 286.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 223.5, 'completions/min_terminated_length': 189.0, 'completions/max_terminated_length': 286.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 223.5, 'kl': 0.13529817573726177, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0035408250987529755, 'learning_rate': 1e-05, 'num_tokens': 4383.0, 'completions/mean_length': 167.75, 'completions/min_length': 157.0, 'completions/max_length': 183.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 167.75, 'completions/min_terminated_length': 157.0, 'completions/max_terminated_length': 183.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 167.75, 'kl': 0.09215808380395174, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.002416549250483513, 'learning_rate': 1e-05, 'num_tokens': 5924.0, 'completions/mean_length': 235.25, 'completions/min_length': 175.0, 'completions/max_length': 297.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 235.25, 'completions/min_terminated_length': 175.0, 'completions/max_terminated_length': 297.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 235.25, 'kl': 0.06609927676618099, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0014035322237759829, 'learning_rate': 1e-05, 'num_tokens': 7544.0, 'completions/mean_length': 249.0, 'completions/min_length': 244.0, 'completions/max_length': 259.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 249.0, 'completions/min_terminated_length': 244.0, 'completions/max_terminated_length': 259.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 249.0, 'kl': 0.0708405626937747, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0006439855205826461, 'learning_rate': 1e-05, 'num_tokens': 8675.0, 'completions/mean_length': 154.75, 'completions/min_length': 120.0, 'completions/max_length': 180.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 154.75, 'completions/min_terminated_length': 120.0, 'completions/max_terminated_length': 180.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 154.75, 'kl': 0.049076409079134464, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0022732827346771955, 'learning_rate': 1e-05, 'num_tokens': 9785.0, 'completions/mean_length': 138.5, 'completions/min_length': 111.0, 'completions/max_length': 164.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 138.5, 'completions/min_terminated_length': 111.0, 'completions/max_terminated_length': 164.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 138.5, 'kl': 0.07089695706963539, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.000542876310646534, 'learning_rate': 1e-05, 'num_tokens': 11092.0, 'completions/mean_length': 185.75, 'completions/min_length': 151.0, 'completions/max_length': 211.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 185.75, 'completions/min_terminated_length': 151.0, 'completions/max_terminated_length': 211.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 185.75, 'kl': 0.054251677356660366, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.7253671288490295, 'learning_rate': 1e-05, 'num_tokens': 12700.0, 'completions/mean_length': 271.0, 'completions/min_length': 157.0, 'completions/max_length': 541.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 271.0, 'completions/min_terminated_length': 157.0, 'completions/max_terminated_length': 541.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 271.0, 'kl': 0.18110399972647429, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.007057391572743654, 'learning_rate': 1e-05, 'num_tokens': 13744.0, 'completions/mean_length': 155.0, 'completions/min_length': 131.0, 'completions/max_length': 191.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 155.0, 'completions/min_terminated_length': 131.0, 'completions/max_terminated_length': 191.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 155.0, 'kl': 0.13956344407051802, 'epoch': 0.0}
{'train_runtime': 55.3303, 'train_samples_per_second': 0.723, 'train_steps_per_second': 0.181, 'train_loss': 0.00012005277785647195, 'epoch': 0.0}
[EP 0121] 2 | reward_mean=1.750 | 
*** stats:  {'episode_reward_mean': 1.75, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.1, 'episode_reward_trajectory': [0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.5, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.5, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.25, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.1, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.75
All rewards  15.450000000000005
Cumulative rewards  [-34.275, 35.087500000000006, 36.099999999999994, -10.8125, -10.65]
Num plays  [9, 59, 35, 10, 9]
Mean rewards  [-3.808333333333333, 0.5947033898305085, 1.0314285714285714, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [192.         245.79666393 189.31455306 202.38577025 192.        ]
sampled base index:  2
potentials:  [192.         245.79666393 189.31455306 202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:05<00:52,  5.82s/it]                                               10%|â–ˆ         | 1/10 [00:05<00:52,  5.82s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:10<00:42,  5.30s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:10<00:42,  5.30s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:35,  5.06s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:35,  5.06s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:21<00:32,  5.40s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:21<00:32,  5.40s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:28<00:29,  5.85s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:28<00:29,  5.85s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:32<00:21,  5.40s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:32<00:21,  5.40s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:36<00:14,  4.85s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:36<00:14,  4.85s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:41<00:09,  4.81s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:41<00:09,  4.81s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:45<00:04,  4.61s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:45<00:04,  4.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:48<00:00,  4.25s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:48<00:00,  4.25s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:50<00:00,  4.25s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:50<00:00,  5.03s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.75
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.75
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_190028-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_190122-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.00204675761051476, 'learning_rate': 1e-05, 'num_tokens': 1691.0, 'completions/mean_length': 256.75, 'completions/min_length': 245.0, 'completions/max_length': 288.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 256.75, 'completions/min_terminated_length': 245.0, 'completions/max_terminated_length': 288.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 256.75, 'kl': 0.09302869066596031, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0018287441926077008, 'learning_rate': 1e-05, 'num_tokens': 2989.0, 'completions/mean_length': 199.5, 'completions/min_length': 159.0, 'completions/max_length': 231.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 199.5, 'completions/min_terminated_length': 159.0, 'completions/max_terminated_length': 231.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 199.5, 'kl': 0.0688332300633192, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 1.0059139728546143, 'learning_rate': 1e-05, 'num_tokens': 4147.0, 'completions/mean_length': 166.5, 'completions/min_length': 147.0, 'completions/max_length': 219.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 166.5, 'completions/min_terminated_length': 147.0, 'completions/max_terminated_length': 219.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 166.5, 'kl': 0.1518914345651865, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.45267194509506226, 'learning_rate': 1e-05, 'num_tokens': 5734.0, 'completions/mean_length': 246.75, 'completions/min_length': 216.0, 'completions/max_length': 298.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 246.75, 'completions/min_terminated_length': 216.0, 'completions/max_terminated_length': 298.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 246.75, 'kl': 0.057571967132389545, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.026789043098688126, 'learning_rate': 1e-05, 'num_tokens': 7508.0, 'completions/mean_length': 287.5, 'completions/min_length': 267.0, 'completions/max_length': 345.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 287.5, 'completions/min_terminated_length': 267.0, 'completions/max_terminated_length': 345.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 287.5, 'kl': 0.13034998159855604, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.02323523536324501, 'learning_rate': 1e-05, 'num_tokens': 8767.0, 'completions/mean_length': 186.75, 'completions/min_length': 169.0, 'completions/max_length': 204.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 186.75, 'completions/min_terminated_length': 169.0, 'completions/max_terminated_length': 204.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 186.75, 'kl': 0.14088703505694866, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.9529958367347717, 'learning_rate': 1e-05, 'num_tokens': 9834.0, 'completions/mean_length': 127.75, 'completions/min_length': 116.0, 'completions/max_length': 147.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 127.75, 'completions/min_terminated_length': 116.0, 'completions/max_terminated_length': 147.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 127.75, 'kl': 0.1481042681261897, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0006749539170414209, 'learning_rate': 1e-05, 'num_tokens': 11109.0, 'completions/mean_length': 177.75, 'completions/min_length': 153.0, 'completions/max_length': 216.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 177.75, 'completions/min_terminated_length': 153.0, 'completions/max_terminated_length': 216.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 177.75, 'kl': 0.0508219450712204, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.018468046560883522, 'learning_rate': 1e-05, 'num_tokens': 12215.0, 'completions/mean_length': 145.5, 'completions/min_length': 112.0, 'completions/max_length': 180.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 145.5, 'completions/min_terminated_length': 112.0, 'completions/max_terminated_length': 180.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 145.5, 'kl': 0.29762021265923977, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.038722310215234756, 'learning_rate': 1e-05, 'num_tokens': 13126.0, 'completions/mean_length': 121.75, 'completions/min_length': 105.0, 'completions/max_length': 128.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 121.75, 'completions/min_terminated_length': 105.0, 'completions/max_terminated_length': 128.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 121.75, 'kl': 0.44713326543569565, 'epoch': 0.0}
{'train_runtime': 50.3436, 'train_samples_per_second': 0.795, 'train_steps_per_second': 0.199, 'train_loss': 0.0001586279926414136, 'epoch': 0.0}
[EP 0122] 2 | reward_mean=1.600 | 
*** stats:  {'episode_reward_mean': 1.6, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.3154700517654419, 'episode_reward_trajectory': [0.0, 2.0, 1.0, 1.5, 2.0, 2.0, 1.5, 2.0, 2.0, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.5, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.1, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.3154700517654419, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.6
All rewards  17.050000000000004
Cumulative rewards  [-34.275, 35.087500000000006, 37.699999999999996, -10.8125, -10.65]
Num plays  [9, 59, 36, 10, 9]
Mean rewards  [-3.808333333333333, 0.5947033898305085, 1.047222222222222, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [192.         245.79666393 192.         202.38577025 192.        ]
sampled base index:  0
potentials:  [192.         245.79666393 192.         202.38577025 192.        ]
sampled base index:  0
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:48, 12.10s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:48, 12.10s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.09s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.09s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.06s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.06s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.07s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.07s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.08s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:00<01:00, 12.08s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.07s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:12<00:48, 12.07s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.06s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:24<00:36, 12.06s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.06s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:36<00:24, 12.06s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.06s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:48<00:12, 12.06s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.05s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:00<00:00, 12.05s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.05s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.23s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.6
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.6
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_190122-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_190329-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.00026358061586506665, 'learning_rate': 0.001, 'num_tokens': 3171.0, 'completions/mean_length': 626.75, 'completions/min_length': 299.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.75, 'completions/mean_terminated_length': 299.0, 'completions/min_terminated_length': 299.0, 'completions/max_terminated_length': 299.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 626.75, 'kl': 0.06439259741455317, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00017128040781244636, 'learning_rate': 0.001, 'num_tokens': 6615.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.05151845142245293, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0002017458900809288, 'learning_rate': 0.001, 'num_tokens': 10051.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.0502123786136508, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00011964704026468098, 'learning_rate': 0.001, 'num_tokens': 13595.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.03750984836369753, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00013955746544525027, 'learning_rate': 0.001, 'num_tokens': 17163.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.053594181314110756, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0001751190284267068, 'learning_rate': 0.001, 'num_tokens': 20619.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.0476616770029068, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.00017677372670732439, 'learning_rate': 0.001, 'num_tokens': 24119.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.049894414842128754, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.000267887458903715, 'learning_rate': 0.001, 'num_tokens': 27627.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.04520917125046253, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.0002648628142196685, 'learning_rate': 0.001, 'num_tokens': 31095.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.040405938401818275, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.00021627105888910592, 'learning_rate': 0.001, 'num_tokens': 34463.0, 'completions/mean_length': 736.0, 'completions/min_length': 736.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -4.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -4.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 736.0, 'kl': 0.05035493988543749, 'epoch': 0.0}
{'train_runtime': 122.2965, 'train_samples_per_second': 0.327, 'train_steps_per_second': 0.082, 'train_loss': 4.9075362039729956e-05, 'epoch': 0.0}
[EP 0123] 0 | reward_mean=-4.000 | 
*** stats:  {'episode_reward_mean': -4.0, 'episode_reward_last': -4.0, 'episode_reward_std_mean': 0.0, 'episode_reward_trajectory': [-4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -4.0, 'rewards/match_format_approximately/mean/last': -4.0, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.0, 'rewards/check_numbers/mean/last': 0.0, 'rewards/check_numbers/std/mean': 0.0, 'rewards/check_numbers/std/last': 0.0}
Curr reward  -4.0
All rewards  13.050000000000004
Cumulative rewards  [-38.275, 35.087500000000006, 37.699999999999996, -10.8125, -10.65]
Num plays  [10, 59, 36, 10, 9]
Mean rewards  [-3.8274999999999997, 0.5947033898305085, 1.047222222222222, -1.08125, -1.1833333333333333]
Balancing probabilities  [1, 0, 0, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [202.38577025 245.79666393 192.         202.38577025 192.        ]
sampled base index:  2
potentials:  [202.38577025 245.79666393 192.         202.38577025 192.        ]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:03,  7.04s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:03,  7.04s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:14<00:56,  7.08s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:14<00:56,  7.08s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:41,  5.96s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:18<00:41,  5.96s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:35,  5.98s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:24<00:35,  5.98s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:30<00:29,  5.81s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:30<00:29,  5.81s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:34<00:21,  5.28s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:34<00:21,  5.28s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:37<00:14,  4.68s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:37<00:14,  4.68s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:42<00:09,  4.62s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:42<00:09,  4.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:50<00:05,  5.82s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:50<00:05,  5.82s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  5.23s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  5.23s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:56<00:00,  5.23s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:56<00:00,  5.65s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_0_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.6
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 0.001
wandb: modelselection/metalearner_episodic_reward -4
wandb:       modelselection/selected_base_learner 0
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_190329-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_190429-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.6177299618721008, 'learning_rate': 1e-05, 'num_tokens': 1891.0, 'completions/mean_length': 306.75, 'completions/min_length': 229.0, 'completions/max_length': 384.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 306.75, 'completions/min_terminated_length': 229.0, 'completions/max_terminated_length': 384.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 306.75, 'kl': 0.13021002896130085, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.6100417375564575, 'learning_rate': 1e-05, 'num_tokens': 3292.0, 'completions/mean_length': 225.25, 'completions/min_length': 148.0, 'completions/max_length': 386.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 225.25, 'completions/min_terminated_length': 148.0, 'completions/max_terminated_length': 386.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 225.25, 'kl': 0.08028717897832394, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.06414012610912323, 'learning_rate': 1e-05, 'num_tokens': 4466.0, 'completions/mean_length': 170.5, 'completions/min_length': 136.0, 'completions/max_length': 217.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 170.5, 'completions/min_terminated_length': 136.0, 'completions/max_terminated_length': 217.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 170.5, 'kl': 0.4445445016026497, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0015721097588539124, 'learning_rate': 1e-05, 'num_tokens': 6085.0, 'completions/mean_length': 254.75, 'completions/min_length': 176.0, 'completions/max_length': 315.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 254.75, 'completions/min_terminated_length': 176.0, 'completions/max_terminated_length': 315.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 254.75, 'kl': 0.057804882526397705, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.5597125291824341, 'learning_rate': 1e-05, 'num_tokens': 7647.0, 'completions/mean_length': 234.5, 'completions/min_length': 202.0, 'completions/max_length': 276.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 234.5, 'completions/min_terminated_length': 202.0, 'completions/max_terminated_length': 276.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 234.5, 'kl': 0.13002356328070164, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.9300751090049744, 'learning_rate': 1e-05, 'num_tokens': 8853.0, 'completions/mean_length': 173.5, 'completions/min_length': 145.0, 'completions/max_length': 192.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 173.5, 'completions/min_terminated_length': 145.0, 'completions/max_terminated_length': 192.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.25, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 173.5, 'kl': 0.11920107901096344, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.008309628814458847, 'learning_rate': 1e-05, 'num_tokens': 9890.0, 'completions/mean_length': 120.25, 'completions/min_length': 110.0, 'completions/max_length': 135.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 120.25, 'completions/min_terminated_length': 110.0, 'completions/max_terminated_length': 135.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 120.25, 'kl': 0.12965885642915964, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0007473346777260303, 'learning_rate': 1e-05, 'num_tokens': 11196.0, 'completions/mean_length': 185.5, 'completions/min_length': 160.0, 'completions/max_length': 207.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 185.5, 'completions/min_terminated_length': 160.0, 'completions/max_terminated_length': 207.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 185.5, 'kl': 0.05671448074281216, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.6186926364898682, 'learning_rate': 1e-05, 'num_tokens': 12777.0, 'completions/mean_length': 264.25, 'completions/min_length': 156.0, 'completions/max_length': 480.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 264.25, 'completions/min_terminated_length': 156.0, 'completions/max_terminated_length': 480.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 264.25, 'kl': 0.24047676008194685, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0038794903084635735, 'learning_rate': 1e-05, 'num_tokens': 13726.0, 'completions/mean_length': 131.25, 'completions/min_length': 76.0, 'completions/max_length': 168.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 131.25, 'completions/min_terminated_length': 76.0, 'completions/max_terminated_length': 168.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 131.25, 'kl': 0.11375317722558975, 'epoch': 0.0}
{'train_runtime': 56.5524, 'train_samples_per_second': 0.707, 'train_steps_per_second': 0.177, 'train_loss': 0.0001502718725532759, 'epoch': 0.0}
[EP 0124] 2 | reward_mean=1.575 | 
*** stats:  {'episode_reward_mean': 1.575, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.5654700517654419, 'episode_reward_trajectory': [0.5, 1.5, 2.0, 2.0, 1.0, 1.25, 2.0, 2.0, 1.5, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.4625, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.075, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.1125, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.4904700517654419, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.575
All rewards  14.625000000000004
Cumulative rewards  [-38.275, 35.087500000000006, 39.275, -10.8125, -10.65]
Num plays  [10, 59, 37, 10, 9]
Mean rewards  [-3.8274999999999997, 0.5947033898305085, 1.0614864864864864, -1.08125, -1.1833333333333333]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [202.38577025 245.79666393 194.64840097 202.38577025 192.        ]
sampled base index:  4
potentials:  [202.38577025 245.79666393 194.64840097 202.38577025 192.        ]
sampled base index:  4
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:50, 12.27s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:50, 12.27s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:19<01:12,  9.01s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:19<01:12,  9.01s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:27<00:59,  8.55s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:27<00:59,  8.55s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:33<00:46,  7.69s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:33<00:46,  7.69s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:39<00:36,  7.23s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:39<00:36,  7.23s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:43<00:24,  6.18s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:43<00:24,  6.18s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:48<00:16,  5.65s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:48<00:16,  5.65s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:54<00:11,  5.81s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:54<00:11,  5.81s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:00<00:05,  5.75s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:00<00:05,  5.75s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:05<00:00,  5.46s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:05<00:00,  5.46s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:06<00:00,  5.46s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:06<00:00,  6.70s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.575
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.3125
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.575
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_190429-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_190540-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.3457549810409546, 'learning_rate': 1e-07, 'num_tokens': 2139.0, 'completions/mean_length': 368.75, 'completions/min_length': 163.0, 'completions/max_length': 736.0, 'completions/clipped_ratio': 0.25, 'completions/mean_terminated_length': 246.33334350585938, 'completions/min_terminated_length': 163.0, 'completions/max_terminated_length': 296.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 368.75, 'kl': 0.000587397997151129, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.36004310846328735, 'learning_rate': 1e-07, 'num_tokens': 3560.0, 'completions/mean_length': 230.25, 'completions/min_length': 142.0, 'completions/max_length': 360.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 230.25, 'completions/min_terminated_length': 142.0, 'completions/max_terminated_length': 360.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 230.25, 'kl': 0.00038455041067209095, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.4279537498950958, 'learning_rate': 1e-07, 'num_tokens': 5044.0, 'completions/mean_length': 248.0, 'completions/min_length': 164.0, 'completions/max_length': 447.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 248.0, 'completions/min_terminated_length': 164.0, 'completions/max_terminated_length': 447.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.625, 'rewards/check_numbers/std': 1.0307763814926147, 'reward': 0.0, 'reward_std': 0.7071067690849304, 'frac_reward_zero_std': 0.0, 'completion_length': 248.0, 'kl': 0.0004723686943179928, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.3387439548969269, 'learning_rate': 1e-07, 'num_tokens': 6678.0, 'completions/mean_length': 258.5, 'completions/min_length': 201.0, 'completions/max_length': 338.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 258.5, 'completions/min_terminated_length': 201.0, 'completions/max_terminated_length': 338.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.5, 'reward_std': 0.7071067690849304, 'frac_reward_zero_std': 0.0, 'completion_length': 258.5, 'kl': 0.0003881791635649279, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.2768838107585907, 'learning_rate': 1e-07, 'num_tokens': 8466.0, 'completions/mean_length': 291.0, 'completions/min_length': 251.0, 'completions/max_length': 338.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 291.0, 'completions/min_terminated_length': 251.0, 'completions/max_terminated_length': 338.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -2.5, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -2.5, 'reward_std': 1.2247449159622192, 'frac_reward_zero_std': 0.0, 'completion_length': 291.0, 'kl': 0.00033984496621997096, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.45756667852401733, 'learning_rate': 1e-07, 'num_tokens': 9581.0, 'completions/mean_length': 150.75, 'completions/min_length': 114.0, 'completions/max_length': 184.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 150.75, 'completions/min_terminated_length': 114.0, 'completions/max_terminated_length': 184.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.375, 'rewards/check_numbers/std': 0.75, 'reward': -0.625, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 150.75, 'kl': 0.0003128912612737622, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.5088649988174438, 'learning_rate': 1e-07, 'num_tokens': 10837.0, 'completions/mean_length': 175.0, 'completions/min_length': 136.0, 'completions/max_length': 212.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 175.0, 'completions/min_terminated_length': 136.0, 'completions/max_terminated_length': 212.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.0, 'rewards/match_format_approximately/std': 1.2247449159622192, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.25, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': -0.75, 'reward_std': 1.9364917278289795, 'frac_reward_zero_std': 0.0, 'completion_length': 175.0, 'kl': 0.0005522529318113811, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.506949782371521, 'learning_rate': 1e-07, 'num_tokens': 12156.0, 'completions/mean_length': 188.75, 'completions/min_length': 129.0, 'completions/max_length': 319.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 188.75, 'completions/min_terminated_length': 129.0, 'completions/max_terminated_length': 319.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -0.625, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.75, 'rewards/check_numbers/std': 0.8660253882408142, 'reward': 0.125, 'reward_std': 1.4361406564712524, 'frac_reward_zero_std': 0.0, 'completion_length': 188.75, 'kl': 0.0006419936507882085, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.43908610939979553, 'learning_rate': 1e-07, 'num_tokens': 13521.0, 'completions/mean_length': 210.25, 'completions/min_length': 149.0, 'completions/max_length': 286.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 210.25, 'completions/min_terminated_length': 149.0, 'completions/max_terminated_length': 286.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 0.0, 'reward': -1.375, 'reward_std': 0.75, 'frac_reward_zero_std': 0.0, 'completion_length': 210.25, 'kl': 0.00036144907426205464, 'epoch': 0.0}
{'loss': 0.0, 'grad_norm': 0.7541323900222778, 'learning_rate': 1e-07, 'num_tokens': 14655.0, 'completions/mean_length': 177.5, 'completions/min_length': 125.0, 'completions/max_length': 232.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 177.5, 'completions/min_terminated_length': 125.0, 'completions/max_terminated_length': 232.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': -1.375, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.125, 'rewards/check_numbers/std': 0.25, 'reward': -1.5, 'reward_std': 0.7071067690849304, 'frac_reward_zero_std': 0.0, 'completion_length': 177.5, 'kl': 0.0006145027800812386, 'epoch': 0.0}
{'train_runtime': 66.9592, 'train_samples_per_second': 0.597, 'train_steps_per_second': 0.149, 'train_loss': 4.6115418967929144e-07, 'epoch': 0.0}
[EP 0125] 4 | reward_mean=-1.200 | 
*** stats:  {'episode_reward_mean': -1.2, 'episode_reward_last': -1.5, 'episode_reward_std_mean': 1.0193442523479461, 'episode_reward_trajectory': [-2.5, -1.375, 0.0, -1.5, -2.5, -0.625, -0.75, 0.125, -1.375, -1.5], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': -1.375, 'rewards/match_format_approximately/mean/last': -1.375, 'rewards/match_format_approximately/std/mean': 0.8174234747886657, 'rewards/match_format_approximately/std/last': 0.75, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 0.175, 'rewards/check_numbers/mean/last': -0.125, 'rewards/check_numbers/std/mean': 0.4012827157974243, 'rewards/check_numbers/std/last': 0.25}
Curr reward  -1.2
All rewards  13.425000000000004
Cumulative rewards  [-38.275, 35.087500000000006, 39.275, -10.8125, -11.85]
Num plays  [10, 59, 37, 10, 10]
Mean rewards  [-3.8274999999999997, 0.5947033898305085, 1.0614864864864864, -1.08125, -1.185]
Balancing probabilities  [0, 0, 0, 0, 1]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [202.38577025 245.79666393 194.64840097 202.38577025 202.38577025]
sampled base index:  2
potentials:  [202.38577025 245.79666393 194.64840097 202.38577025 202.38577025]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:03,  7.04s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:03,  7.04s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:12<00:49,  6.22s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:12<00:49,  6.22s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:37,  5.40s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:37,  5.40s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:25<00:38,  6.42s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:25<00:38,  6.42s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:32<00:33,  6.61s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:32<00:33,  6.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:36<00:24,  6.02s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:36<00:24,  6.02s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:40<00:15,  5.15s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:40<00:15,  5.15s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:45<00:10,  5.03s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:45<00:10,  5.03s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:53<00:06,  6.01s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:53<00:06,  6.01s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:57<00:00,  5.37s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:57<00:00,  5.37s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:58<00:00,  5.37s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:58<00:00,  5.88s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: 
wandb: Run history:
wandb:      modelselection/base_4_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.575
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.2
wandb:               modelselection/learning_rate 0.0
wandb: modelselection/metalearner_episodic_reward -1.2
wandb:       modelselection/selected_base_learner 4
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_190540-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_190642-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.0014862341340631247, 'learning_rate': 1e-05, 'num_tokens': 1951.0, 'completions/mean_length': 321.75, 'completions/min_length': 288.0, 'completions/max_length': 382.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 321.75, 'completions/min_terminated_length': 288.0, 'completions/max_terminated_length': 382.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': -0.5, 'rewards/check_numbers/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 321.75, 'kl': 0.07187116052955389, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.894730806350708, 'learning_rate': 1e-05, 'num_tokens': 3201.0, 'completions/mean_length': 187.5, 'completions/min_length': 123.0, 'completions/max_length': 285.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 187.5, 'completions/min_terminated_length': 123.0, 'completions/max_terminated_length': 285.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 187.5, 'kl': 0.12166001088917255, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0012529392261058092, 'learning_rate': 1e-05, 'num_tokens': 4313.0, 'completions/mean_length': 155.0, 'completions/min_length': 115.0, 'completions/max_length': 205.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 155.0, 'completions/min_terminated_length': 115.0, 'completions/max_terminated_length': 205.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 155.0, 'kl': 0.08597001899033785, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.5863038301467896, 'learning_rate': 1e-05, 'num_tokens': 6186.0, 'completions/mean_length': 318.25, 'completions/min_length': 207.0, 'completions/max_length': 450.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 318.25, 'completions/min_terminated_length': 207.0, 'completions/max_terminated_length': 450.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 318.25, 'kl': 0.09962381329387426, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.6803832054138184, 'learning_rate': 1e-05, 'num_tokens': 7996.0, 'completions/mean_length': 296.5, 'completions/min_length': 265.0, 'completions/max_length': 375.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 296.5, 'completions/min_terminated_length': 265.0, 'completions/max_terminated_length': 375.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 296.5, 'kl': 0.1133171021938324, 'epoch': 0.0}
{'loss': 0.0006, 'grad_norm': 1.2208434343338013, 'learning_rate': 1e-05, 'num_tokens': 9242.0, 'completions/mean_length': 183.5, 'completions/min_length': 162.0, 'completions/max_length': 232.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 183.5, 'completions/min_terminated_length': 162.0, 'completions/max_terminated_length': 232.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.125, 'rewards/match_format_approximately/std': 0.75, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.125, 'rewards/check_numbers/std': 0.75, 'reward': 1.25, 'reward_std': 1.5, 'frac_reward_zero_std': 0.0, 'completion_length': 183.5, 'kl': 0.5619306517764926, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0030815096106380224, 'learning_rate': 1e-05, 'num_tokens': 10277.0, 'completions/mean_length': 119.75, 'completions/min_length': 113.0, 'completions/max_length': 129.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 119.75, 'completions/min_terminated_length': 113.0, 'completions/max_terminated_length': 129.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 119.75, 'kl': 0.08921424206346273, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0044912295415997505, 'learning_rate': 1e-05, 'num_tokens': 11610.0, 'completions/mean_length': 192.25, 'completions/min_length': 162.0, 'completions/max_length': 224.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 192.25, 'completions/min_terminated_length': 162.0, 'completions/max_terminated_length': 224.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 192.25, 'kl': 0.08918790798634291, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.7393770217895508, 'learning_rate': 1e-05, 'num_tokens': 13129.0, 'completions/mean_length': 248.75, 'completions/min_length': 141.0, 'completions/max_length': 461.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 248.75, 'completions/min_terminated_length': 141.0, 'completions/max_terminated_length': 461.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 248.75, 'kl': 0.3770175101235509, 'epoch': 0.0}
{'loss': 0.002, 'grad_norm': 0.3036009669303894, 'learning_rate': 1e-05, 'num_tokens': 14112.0, 'completions/mean_length': 139.75, 'completions/min_length': 118.0, 'completions/max_length': 169.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 139.75, 'completions/min_terminated_length': 118.0, 'completions/max_terminated_length': 169.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 139.75, 'kl': 1.9946558866649866, 'epoch': 0.0}
{'train_runtime': 58.7571, 'train_samples_per_second': 0.681, 'train_steps_per_second': 0.17, 'train_loss': 0.0003604590929171536, 'epoch': 0.0}
[EP 0126] 2 | reward_mean=1.475 | 
*** stats:  {'episode_reward_mean': 1.475, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.5654700517654419, 'episode_reward_trajectory': [0.0, 1.5, 2.0, 1.5, 1.5, 1.25, 2.0, 2.0, 1.0, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.4625, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.075, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.0125, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.4904700517654419, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.475
All rewards  14.900000000000004
Cumulative rewards  [-38.275, 35.087500000000006, 40.75, -10.8125, -11.85]
Num plays  [10, 59, 38, 10, 10]
Mean rewards  [-3.8274999999999997, 0.5947033898305085, 1.0723684210526316, -1.08125, -1.185]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [202.38577025 245.79666393 197.2612481  202.38577025 202.38577025]
sampled base index:  2
potentials:  [202.38577025 245.79666393 197.2612481  202.38577025 202.38577025]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:06<00:59,  6.63s/it]                                               10%|â–ˆ         | 1/10 [00:06<00:59,  6.63s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:10<00:40,  5.11s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:10<00:40,  5.11s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:33,  4.77s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:15<00:33,  4.77s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:20<00:29,  4.85s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:20<00:29,  4.85s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:25<00:25,  5.07s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:25<00:25,  5.07s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:29<00:19,  4.84s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:29<00:19,  4.84s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:33<00:13,  4.40s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:33<00:13,  4.40s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:37<00:08,  4.26s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:37<00:08,  4.26s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:48<00:06,  6.46s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:48<00:06,  6.46s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:52<00:00,  5.60s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:52<00:00,  5.60s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:53<00:00,  5.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:53<00:00,  5.39s/it]
wandb: updating run metadata
wandb: uploading config.yaml
wandb: uploading console lines 11-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.475
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.2
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.475
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_190642-wdqr6dku/logs
wandb: setting up run wdqr6dku
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_190740-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0002, 'grad_norm': 0.6344402432441711, 'learning_rate': 1e-05, 'num_tokens': 1793.0, 'completions/mean_length': 282.25, 'completions/min_length': 254.0, 'completions/max_length': 352.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 282.25, 'completions/min_terminated_length': 254.0, 'completions/max_terminated_length': 352.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 282.25, 'kl': 0.2170936893671751, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.03204669803380966, 'learning_rate': 1e-05, 'num_tokens': 2969.0, 'completions/mean_length': 169.0, 'completions/min_length': 160.0, 'completions/max_length': 178.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 169.0, 'completions/min_terminated_length': 160.0, 'completions/max_terminated_length': 178.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 169.0, 'kl': 0.2275957791134715, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.002860808279365301, 'learning_rate': 1e-05, 'num_tokens': 4154.0, 'completions/mean_length': 173.25, 'completions/min_length': 143.0, 'completions/max_length': 200.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 173.25, 'completions/min_terminated_length': 143.0, 'completions/max_terminated_length': 200.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 173.25, 'kl': 0.0998003464192152, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 1.0630345344543457, 'learning_rate': 1e-05, 'num_tokens': 5596.0, 'completions/mean_length': 210.5, 'completions/min_length': 176.0, 'completions/max_length': 241.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 210.5, 'completions/min_terminated_length': 176.0, 'completions/max_terminated_length': 241.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 210.5, 'kl': 0.31694107223302126, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.6532463431358337, 'learning_rate': 1e-05, 'num_tokens': 7262.0, 'completions/mean_length': 260.5, 'completions/min_length': 249.0, 'completions/max_length': 272.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 260.5, 'completions/min_terminated_length': 249.0, 'completions/max_terminated_length': 272.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 260.5, 'kl': 0.08755154255777597, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0017474873457103968, 'learning_rate': 1e-05, 'num_tokens': 8475.0, 'completions/mean_length': 175.25, 'completions/min_length': 131.0, 'completions/max_length': 202.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 175.25, 'completions/min_terminated_length': 131.0, 'completions/max_terminated_length': 202.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 175.25, 'kl': 0.05049216141924262, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0015472163213416934, 'learning_rate': 1e-05, 'num_tokens': 9530.0, 'completions/mean_length': 124.75, 'completions/min_length': 120.0, 'completions/max_length': 137.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 124.75, 'completions/min_terminated_length': 120.0, 'completions/max_terminated_length': 137.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 124.75, 'kl': 0.06160365138202906, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.0005777127807959914, 'learning_rate': 1e-05, 'num_tokens': 10723.0, 'completions/mean_length': 157.25, 'completions/min_length': 132.0, 'completions/max_length': 172.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 157.25, 'completions/min_terminated_length': 132.0, 'completions/max_terminated_length': 172.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 157.25, 'kl': 0.05724833533167839, 'epoch': 0.0}
{'loss': 0.0284, 'grad_norm': 46.43976593017578, 'learning_rate': 1e-05, 'num_tokens': 12829.0, 'completions/mean_length': 395.5, 'completions/min_length': 141.0, 'completions/max_length': 686.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 395.5, 'completions/min_terminated_length': 141.0, 'completions/max_terminated_length': 686.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.5, 'rewards/check_numbers/std': 1.154700517654419, 'reward': 1.0, 'reward_std': 1.154700517654419, 'frac_reward_zero_std': 0.0, 'completion_length': 395.5, 'kl': 28.416286340914667, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.003574394853785634, 'learning_rate': 1e-05, 'num_tokens': 13791.0, 'completions/mean_length': 134.5, 'completions/min_length': 116.0, 'completions/max_length': 151.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 134.5, 'completions/min_terminated_length': 116.0, 'completions/max_terminated_length': 151.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 134.5, 'kl': 0.11799038015305996, 'epoch': 0.0}
{'train_runtime': 53.949, 'train_samples_per_second': 0.741, 'train_steps_per_second': 0.185, 'train_loss': 0.002965260861674324, 'epoch': 0.0}
[EP 0127] 2 | reward_mean=1.600 | 
*** stats:  {'episode_reward_mean': 1.6, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.4309401035308838, 'episode_reward_trajectory': [0.5, 2.0, 2.0, 1.0, 1.5, 2.0, 2.0, 2.0, 1.0, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.5, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.1, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.4309401035308838, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.6
All rewards  16.500000000000004
Cumulative rewards  [-38.275, 35.087500000000006, 42.35, -10.8125, -11.85]
Num plays  [10, 59, 39, 10, 10]
Mean rewards  [-3.8274999999999997, 0.5947033898305085, 1.085897435897436, -1.08125, -1.185]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [202.38577025 245.79666393 199.83993595 202.38577025 202.38577025]
sampled base index:  2
potentials:  [202.38577025 245.79666393 199.83993595 202.38577025 202.38577025]
sampled base index:  2
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:07<01:07,  7.46s/it]                                               10%|â–ˆ         | 1/10 [00:07<01:07,  7.46s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:13<00:51,  6.38s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:13<00:51,  6.38s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:39,  5.65s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:17<00:39,  5.65s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:23<00:33,  5.60s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:23<00:33,  5.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:29,  5.83s/it]                                               50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:29<00:29,  5.83s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:34<00:21,  5.36s/it]                                               60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:34<00:21,  5.36s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:37<00:14,  4.75s/it]                                               70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:37<00:14,  4.75s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:42<00:09,  4.67s/it]                                               80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:42<00:09,  4.67s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:48<00:05,  5.20s/it]                                               90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:48<00:05,  5.20s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:52<00:00,  4.86s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:52<00:00,  4.86s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  4.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:54<00:00,  5.42s/it]
wandb: updating run metadata
wandb: uploading summary, console lines 7-7
wandb: uploading console lines 11-19
wandb: 
wandb: Run history:
wandb:      modelselection/base_2_episodic_reward â–
wandb:               modelselection/learning_rate â–
wandb: modelselection/metalearner_episodic_reward â–
wandb:       modelselection/selected_base_learner â–
wandb: 
wandb: Run summary:
wandb:      modelselection/base_0_episodic_reward -4
wandb:      modelselection/base_1_episodic_reward -4
wandb:      modelselection/base_2_episodic_reward 1.6
wandb:      modelselection/base_3_episodic_reward -1
wandb:      modelselection/base_4_episodic_reward -1.2
wandb:               modelselection/learning_rate 1e-05
wandb: modelselection/metalearner_episodic_reward 1.6
wandb:       modelselection/selected_base_learner 2
wandb: 
wandb: ðŸš€ View run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42 at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
wandb: â­ï¸ View project at: https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260226_190740-wdqr6dku/logs
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in /projectnb/modselrl/modsel_posttraining/wandb/run-20260226_190838-wdqr6dku
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run llama3b__BD3RB__learning_rate__M5__G4__T1.0__rank64__seed42
wandb: â­ï¸ View project at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA
wandb: ðŸš€ View run at https://wandb.ai/aidaafshar/Modsel_GRPO_LoRA/runs/wdqr6dku
[accelerate.utils.other|WARNING]Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 10
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4
 "-____-"     Trainable parameters = 97,255,424 of 3,310,005,248 (2.94% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0001, 'grad_norm': 0.6819118857383728, 'learning_rate': 1e-05, 'num_tokens': 1943.0, 'completions/mean_length': 319.75, 'completions/min_length': 258.0, 'completions/max_length': 412.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 319.75, 'completions/min_terminated_length': 258.0, 'completions/max_terminated_length': 412.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 0.0, 'rewards/check_numbers/std': 1.0, 'reward': 0.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 319.75, 'kl': 0.14989705476909876, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 1.3251546621322632, 'learning_rate': 1e-05, 'num_tokens': 3417.0, 'completions/mean_length': 243.5, 'completions/min_length': 205.0, 'completions/max_length': 287.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 243.5, 'completions/min_terminated_length': 205.0, 'completions/max_terminated_length': 287.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 243.5, 'kl': 0.186590526252985, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.016942163929343224, 'learning_rate': 1e-05, 'num_tokens': 4599.0, 'completions/mean_length': 172.5, 'completions/min_length': 150.0, 'completions/max_length': 226.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 172.5, 'completions/min_terminated_length': 150.0, 'completions/max_terminated_length': 226.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 172.5, 'kl': 0.1565258428454399, 'epoch': 0.0}
{'loss': 0.0002, 'grad_norm': 0.03941827267408371, 'learning_rate': 1e-05, 'num_tokens': 6127.0, 'completions/mean_length': 232.0, 'completions/min_length': 196.0, 'completions/max_length': 278.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 232.0, 'completions/min_terminated_length': 196.0, 'completions/max_terminated_length': 278.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 232.0, 'kl': 0.23956843838095665, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.03853462263941765, 'learning_rate': 1e-05, 'num_tokens': 7868.0, 'completions/mean_length': 279.25, 'completions/min_length': 246.0, 'completions/max_length': 325.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 279.25, 'completions/min_terminated_length': 246.0, 'completions/max_terminated_length': 325.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 279.25, 'kl': 0.3646963369101286, 'epoch': 0.0}
{'loss': 0.0008, 'grad_norm': 0.18737156689167023, 'learning_rate': 1e-05, 'num_tokens': 9051.0, 'completions/mean_length': 167.75, 'completions/min_length': 137.0, 'completions/max_length': 206.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 167.75, 'completions/min_terminated_length': 137.0, 'completions/max_terminated_length': 206.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 167.75, 'kl': 0.7833130247890949, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.004970163572579622, 'learning_rate': 1e-05, 'num_tokens': 10131.0, 'completions/mean_length': 131.0, 'completions/min_length': 120.0, 'completions/max_length': 139.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 131.0, 'completions/min_terminated_length': 120.0, 'completions/max_terminated_length': 139.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 131.0, 'kl': 0.1410857867449522, 'epoch': 0.0}
{'loss': 0.0001, 'grad_norm': 0.003316646907478571, 'learning_rate': 1e-05, 'num_tokens': 11423.0, 'completions/mean_length': 182.0, 'completions/min_length': 165.0, 'completions/max_length': 207.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 182.0, 'completions/min_terminated_length': 165.0, 'completions/max_terminated_length': 207.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 182.0, 'kl': 0.12845628149807453, 'epoch': 0.0}
{'loss': 0.0004, 'grad_norm': 0.698483407497406, 'learning_rate': 1e-05, 'num_tokens': 12851.0, 'completions/mean_length': 226.0, 'completions/min_length': 129.0, 'completions/max_length': 339.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 226.0, 'completions/min_terminated_length': 129.0, 'completions/max_terminated_length': 339.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.0, 'rewards/check_numbers/std': 1.0, 'reward': 1.5, 'reward_std': 1.0, 'frac_reward_zero_std': 0.0, 'completion_length': 226.0, 'kl': 0.3577367104589939, 'epoch': 0.0}
{'loss': 0.0003, 'grad_norm': 0.02154579758644104, 'learning_rate': 1e-05, 'num_tokens': 13851.0, 'completions/mean_length': 144.0, 'completions/min_length': 114.0, 'completions/max_length': 180.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 144.0, 'completions/min_terminated_length': 114.0, 'completions/max_terminated_length': 180.0, 'rewards/match_format_exactly/mean': 0.0, 'rewards/match_format_exactly/std': 0.0, 'rewards/match_format_approximately/mean': 0.5, 'rewards/match_format_approximately/std': 0.0, 'rewards/check_answer/mean': 0.0, 'rewards/check_answer/std': 0.0, 'rewards/check_numbers/mean': 1.5, 'rewards/check_numbers/std': 0.0, 'reward': 2.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 144.0, 'kl': 0.26858559995889664, 'epoch': 0.0}
{'train_runtime': 54.2161, 'train_samples_per_second': 0.738, 'train_steps_per_second': 0.184, 'train_loss': 0.0002776439214358106, 'epoch': 0.0}
[EP 0128] 2 | reward_mean=1.750 | 
*** stats:  {'episode_reward_mean': 1.75, 'episode_reward_last': 2.0, 'episode_reward_std_mean': 0.3, 'episode_reward_trajectory': [0.5, 1.5, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.5, 2.0], 'rewards/match_format_exactly/mean/mean': 0.0, 'rewards/match_format_exactly/mean/last': 0.0, 'rewards/match_format_exactly/std/mean': 0.0, 'rewards/match_format_exactly/std/last': 0.0, 'rewards/match_format_approximately/mean/mean': 0.5, 'rewards/match_format_approximately/mean/last': 0.5, 'rewards/match_format_approximately/std/mean': 0.0, 'rewards/match_format_approximately/std/last': 0.0, 'rewards/check_answer/mean/mean': 0.0, 'rewards/check_answer/mean/last': 0.0, 'rewards/check_answer/std/mean': 0.0, 'rewards/check_answer/std/last': 0.0, 'rewards/check_numbers/mean/mean': 1.25, 'rewards/check_numbers/mean/last': 1.5, 'rewards/check_numbers/std/mean': 0.3, 'rewards/check_numbers/std/last': 0.0}
Curr reward  1.75
All rewards  18.250000000000004
Cumulative rewards  [-38.275, 35.087500000000006, 44.1, -10.8125, -11.85]
Num plays  [10, 59, 40, 10, 10]
Mean rewards  [-3.8274999999999997, 0.5947033898305085, 1.1025, -1.08125, -1.185]
Balancing probabilities  [0, 0, 1, 0, 0]
Mis-Specification Test [6, 5, 5, 6, 6]
potentials:  [202.38577025 245.79666393 202.38577025 202.38577025 202.38577025]
sampled base index:  0
potentials:  [202.38577025 245.79666393 202.38577025 202.38577025 202.38577025]
sampled base index:  0
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:12<01:48, 12.09s/it]                                               10%|â–ˆ         | 1/10 [00:12<01:48, 12.09s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.05s/it]                                               20%|â–ˆâ–ˆ        | 2/10 [00:24<01:36, 12.05s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.06s/it]                                               30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:24, 12.06s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.06s/it]                                               40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:48<01:12, 12.06s/it]